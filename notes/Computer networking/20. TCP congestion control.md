<!-- TOC titleSize:1 tabSpaces:2 depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 skip:0 title:1 charForUnorderedList:* -->
# Table of Contents
- [Table of Contents](#table-of-contents)
- [TCP congestion control](#tcp-congestion-control)
  - [TCP congestion control algorithm](#tcp-congestion-control-algorithm)
    - [Slow start](#slow-start)
    - [Congestion avoidance](#congestion-avoidance)
    - [Fast recovery](#fast-recovery)
    - [TCP congestion control - retrospective](#tcp-congestion-control---retrospective)
    - [Macroscopic description of TCP throughput](#macroscopic-description-of-tcp-throughput)
    - [TCP over high-bandwidth paths](#tcp-over-high-bandwidth-paths)
  - [Fairness](#fairness)
    - [Fairness and UDP](#fairness-and-udp)
    - [Fairness and parallel TCP connections](#fairness-and-parallel-tcp-connections)
- [Appendix](#appendix)
  - [Concepts](#concepts)
<!-- /TOC -->

# TCP congestion control
**Idea of TCP congestion control**. Have each sender limit the rate, at which it sends traffic into its connection, as a function of perceived network congestion
* *Explain*.
    * If a TCP sender perceives that there is little congestion on the path between itself and the destination

        $\to$ The TCP sender increases its send rate
    * If the sender perceives that there is congestion along the path

        $\to$ The sender reduces its send rate
* *Questions*.
    * How does a TCP sender limit the rate, at which it sends traffic into its connection
    * How does a TCP sender perceive that there is a congestion on the path between itself and the destination
    * What algorithm should the sender use to change its send rate, as a function of perceived end-to-end congestion

**Limiting the sending rate**. Each side of a TCP connection consists of a receive buffer, a send buffer, and several variables

$\to$ The TCP congestion-control operating at the sender keeps track of an additional variable, i.e. the congestion window
* *Congestion window*. Denoted as `cwnd`, imposes a constraint on the rate, at which a TCP sender can send traffic into the network
    * *Idea*. The amount of unacknowledged data at a sender may not exceed the minimum of `cwnd` and `rwnd`
    * *Formal*. `LastByteSent - LastByteAcked <= min(cwnd, rwnd)`
    * *Consequence*. The amount of unacknowledged data at the sender is limited, thus the sender's send rate is indirectly limited
* *Assumptions for analysis*. To focus on congestion control, we assume that 
    * The TCP receive buffer is so large that `rwnd` can be ignored
        
        $\to$ The amount of unacknowledged data at the sender is soly limited by `crwnd`
    * The sender always has data to send, i.e. all segments in the congestion window are sent
* *Sender rate with congestion window*. Consider a connection, for which loss and packet retransmission delays are negligible
    * *Sender operation* 
        * Roughly, at the beginning of every RTT, `cwnd` permits the sender to send `cwnd` bytes of data into the connection
        * At the end of the RTT, the sender receives acknowledgements for the data
    * *Consequence*. The sender's send rate is roughly `cwnd/RTT` bytes / sec

        $\to$ By adjusting the value of `cwnd`, the sender can adjust its sending rate

**Perceiving congestion on the path between the sender and the destination**.
* *Loss event at a TCP sender*. The occurrence of either a timeout or the receipt of three duplicate ACKs from the receiver
* *Packet loss due to congestion*. When there is excessive congestion, then one or more router buffers along the path overflows
    
    $\to$ This causes a datagram, i.e. containing a TCP segment, to be dropped
* *Consequence*. The packet loss event is taken by the sender to be an indication of congestion on the sender-to-receiver path

**Congestion detection**. 
* *Congestion-free network*. This means that no loss event will occur

    $\to$ Acknowledgements for previously unacknowledged segments will be received at the TCP sender
    * *Self-clocking*. TCP uses acknowledgements to trigger, or clock, its increase in congestion window size 
        * If acknowledgements arrive at a relatively slow rate, e.g. if the end-end path has high delay or contains a low-bandwidth link

            $\to$ The congestion window will be increased at a relatively slow rate
            * *Explain*. TCP takes the arrival of acknowledgements as an indication that everything is well
        * If acknowledgements arrive at a high rate, then the congestion window will be increased more quickly
* *How should a TCP sender determine the desired sending rate*. 
    * *Sending rate effects*.
        * If TCP sender collectively send too fast, then can congest the network
        * If TCP senders are too cautious and send too slowly, they could under utilize the bandwidth in the network
    * *Principles for determining sending rate*.
        * *Principle 1*. A lost segment implies congestion, thus the TCP sender's rate should be decreased when a segment is lost

            $\to$ How the TCP sender should decrease its congestion window size, hence its sending rate
        * *Principle 2*. An acknowledged segment indicates that the network is delivering the sender's segments to the receiver
        
            $\to$ The sender's rate can be increased when an ACK arrives for a previously unacknowledged segment
        * *Principle 3*. 
            * *Idea*. TCP's strategy for adjusting its transmission rate is
                * Increase the sending rate, in response to arriving ACKs, until a loss event occurs
                * When a loss event occurs, the sending rate is decreased
            * *Bandwidth-probing*. The TCP sender increases its transmission rate to probe for the rate, at which congestion onset begins

                $\to$ The TCP sender then backs off from that rate, then begins probing again to see if the congestion onset rate has changed
    
    >**NOTE**. There is no explicit signaling of congestion state by the network, ACKs and loss events serve as implicit signals only

    >**NOTE**. Each TCP sender acts on local information asynchronously from other TCP senders

**TCP congestion-control algorithm components**. Slow start, congestion avoidance, and fast recovery
* *Mandatory components*. Slow start and congestion avoidance
* *Optional component*. Fast recovery

## TCP congestion control algorithm
### Slow start
**Initial value of `cwnd`**. When a TCP connection begins, the value of `cwnd` is typically initialized to a small value of 1 MSS

$\to$ The initial sending rate is roughly $\text{MSS} / \text{RTT}$

**Slow-start state**. 
* *Motivation*. Since the available bandwidth to the TCP sender may be much larger than $\text{MSS} / \text{RTT}$

$\to$ The TCP sender would like to find the amount of available quickly

<div style="text-align:center">
    <img src="https://i.imgur.com/q9FmvaZ.png">
    <figcaption>TCP slow start</figcaption>
</div>

* *Idea*. The value of `cwnd` begins at 1 MSS and increased by 1 MSS every time a transmitted segment is first acknowledged
    * *Example*. The example series of values of `cwnd` would be $1,2,4,\dots,2^n$

        $\to$ TCP send rate starts slow but grow exponentially during the slow start phase
* *Slow start termination*. There are two ways slow start may end
    * *Option 1*. If there is a loss event, i.e. congestion, indicated by a timeout
        * The TCP sender sets the value of `cwnd` to 1 and begins the slow start process anew
        * The TCP sender sets the value of a second state variable `ssthresh` (slow start threshold) to `cwnd/2`, i.e. half of the congestion window when congestion is detected
    * *Option 2*. When the value of `cwnd` reaches `ssthresh`, slow start ends and TCP transitions into congestion avoidance mode

        $\to$ In congestion avoidance mode, `cwnd` is more cautiously increased
    * *Option 3*. If three duplicate ACKs are detected
        
        $\to$ TCP then performs a fast retransmit and enters the fast recovery state

**FSM description of TCP congestion control**.

<div style="text-align:center">
    <img src="https://i.imgur.com/prwqLpm.png">
    <figcaption>FSM description of TCP congestion control</figcaption>
</div>

### Congestion avoidance
**Congestion avoidance**. TCP adopts a more conservative approach and increases the value of `cwnd` by just a single MSS every RTT
* *Reference documentation*. RFC 5681

**Implementations**. TCP sender increases `cwnd` by $\text{MSS} \cdot (\text{MSS}/\text{cwnd})$ whenever a new acknowledgement arrives
* *Example*. If MSS is 1460 bytes and `cwnd` is 14600 bytes, then 10 segments are being sent within an RTT

    $\to$ Each arriving ACK, assuming one ACK per segment, increases the congestion window size by $1/10$ MSS

**Termination**. 
* *Option 1*. When a timeout occurs, 
    * The value of `cwnd` is set to 1 MSS
    * The value of `ssthresh` is updated to half of the value of `cwnd` when the loss event occurred
    * The slow start state is entered
* *Option 2*. When a triple duplicate ACK event occurs
    
    $\to$ The network is continuing to deliver segments from sender to receiver, as indicated by the receipt of duplicate ACKs
    * *Consequences*. 
        * TCP's halves the value of `cwnd` and records the value of `ssthresh` to be half the value of `cwnd` when the triple ACKs were received
        * `cwnd` is increased by 3 MSS, as a good measure to account for the triple duplicate ACKs received
        * The fast-recovery state is entered

### Fast recovery
**Fast recovery**. The value of `cwnd` is increased by 1 MSS for every duplicate ACK received for the missing segment causing TCP to enter the fast-recovery state
* *Termination*. 
    * *Option 1*. When an ACK arrives for the missing segment, TCP enters the congestion-avoidance state after deflating `cwnd` to `ssthresh`
    * *Option 2*. When a timeout occurs,
        * `cwnd` is set to 1 MSS
        * The value of `ssthresh` is set to half the value of `cwnd` when the loss event occurred 
        * Fast recovery transitions to the slow-start state

**Incorportaion of fast recovery**. Fast recover is a recommended, but not required, component of TCP
* *TCP Tahoe*. Unconditionally cut `cwnd` to 1 MSS and enter the slow-start phase after either a timeout-indicated or triple-duplicate-ACK-indicated loss event

    $\to$ In proposed fast-recovery-incorporated TCP, when triple-duplicate-ACK-indicated loss event occurs, TCP enters fast recovery state 
* *TCP Reno*. Incorporate fast recovery

### TCP congestion control - retrospective
**Additive-increase, multiplicative-decrease (AIMD)**. 
* *Assumptions*.
    * Ignore the initial slow-start period when a connection begins
    * Losses are indicated by triple duplicate ACKs rather than timeouts
* *Observation*. TCP's congestion control consists of 
    * Linear (additive) increase in `cwnd` of 1 MSS per RTT
    * Halving (multiplicative decrease) of `cwnd` on a triple duplicate-ACK event
* *Consequence*. TCP congestion control is often referred to as an AIMD form of congestion control
    * *Effects of AIMD*. Give rise to the sawtooth behavior of the congestion window

        <div style="text-align:center">
            <img src="https://i.imgur.com/VYMFOM7.png">
            <figcaption>AIMD congestion control</figcaption>
        </div>
    
**TCP Vegas and variations of TCP Reno**.
* *TCP Vegas*. Attemp to avoid congestion while maintaining good throughput
    * *Idea*.
        * Detect congestion in the routers between the source and destination, before packet loss occurs
        * Lower the rate linearly when imminent packet loss is detected
    * *Detecting imminent packet loss*. By observing the RTT
        * *Explain*. Longer RTT indicates greater congestion in the routers
* *Configuring TCP version in Linux*. Linux supports a number of congestion-control algorithms, including TCP Reno and TCP Vegas, and allows a system adminimstrator to configure which TCP version will be used
    * *Default TCP version in Linux 2.6.18*. TCP CUBIC, a TCP version developed for high-bandwidth applications

### Macroscopic description of TCP throughput
**Average throughput of a long-lived TCP connection without slow-start phases**.
* *TCP transmission rate during a particular round-trip interval*. $w/\text{RTT}$
    * *Notations*.
        * $w$ is the window size in bytes
        * $\text{RTT}$ is the current round-trip time
* *TCP transmission rate range*. From $W/(2\cdot \text{RTT})$ to $W/RTT$
    * *Assumption*.
        * $W$ is the value of $w$ when a loss event occurs
        * $\text{RTT}$ and $W$ are approximately constant over the duration of the connection
    * *TCP transmission rate range*. From $W/(2\cdot \text{RTT})$ to $W/RTT$
* *Macroscopic model for the steady-state behavior of TCP*.
    * *Transmission rate adjustment process*. The following steps repeats over and over again
        1. The network drops a packet from the connection when the rate increases to $W/\text{RTT}$
        2. The rate is then halved, and then increases by $\text{MSS}/\text{RTT}$ every $\text{RTT}$ until it again reaches $W/\text{RTT}$
    * *Average throughput of a connection*. $0.75 \cdot W / \text{RTT}$
        * *Explain*. TCP's throughput increases linearly between the two extreme values

### TCP over high-bandwidth paths
**Evolution of TCP congestion control**. TCP congestion control evolv over years and still evolving
* *Explain*. The need for continued evolution of TCP can be seen in high-speed TCP connections required for grid- and cloud-computing applications

## Fairness
**Bottleneck link**. Consider $K$ TCP connections, each with different end-to-end path, but all passing through a bottleneck link with transmission rate $R$ bps

$\to$ Suppose each connection is transferring a large file, and there is no UDP traffic passing through the bottleneck link
* *"Bottleneck" meaning*. For each connection, 
    * All other links along the connection's path are not congested 
    * All other links have abundant transmission capacity as compared with the transmission capacity of the bottleneck link
* *Fair congestion control mechanism*. Congestion-control algorithms where the average transmission rate of each connection is approximately $R/K$

**Fairness of TCP's AIMD algorithm**. There has been an elegant and intuitive explanation (by Chiu 1989) of why TCP congestion control converges to provide an equal share of a bottleneck link's bandwidth among competing TCP connections

**Simple case of two TCP connections sharing a single link with transmission rate $R$**.

<div style="text-align:center">
    <img src="https://i.imgur.com/b15qRra.png">
    <figcaption>Two TCP connections sharing a single bottleneck link</figcaption>
</div>

* *Assumptions*.
    * The two connections have the same MSS and RTT

        $\to$ If they have the same congestion window size, then they have the same throughput
    * Two connections have a large amount of data to send
    * No other TCP connections or UDP datagrams traverse this shared link
    * The slow-start phase of TCP is ignored, and the TCP connections are operating in CA mode (of AIMD) at all times
* *Throughput realized by the two TCP connections*.

    <div style="text-align:center">
        <img src="https://i.imgur.com/cYrgi0i.png">
        <figcaption>Throughput realized by TCP connections 1 and 2</figcaption>
    </div>

    * *Throughput realization*. If TCP is to share the link bandwidth equally between the two connections

        $\to$ The realized throughput should fall along the 45-degree arrow emanating from the origin
    * *Ideal sum of throughputs*. Should equal $R$
    * *Desired throughput*. Throughputs falling somewhere near the intersection of the equal bandwidth share line, and the full bandwidth utilization line
* *Example TCP congestion control operation*.
    1. Assume that the TCP window sizes are such that, at a given point in time, connections 1 and 2 realize throughputs indicated by point A in the figure

        $\to$ Since the amount of link bandwidth jointly consumed by the connections is less than $R$, no loss will occur
    2. Both connections increase their window by 1 MSS per RTT, as a result of TCP's CA algorithm

        $\to$ The joint throughput of the connctions proceeds along the 45-degree line and reach point B
        * *Consequence*. The link bandwidth jointly consumed by the connection is greater than $R$

            $\to$ Packet loss will occur
    3. Both connections decrease their windows by a factor of two, leading to throughput realized at point C

        $\to$ C is halfway along a vector starting at B and end at the origin
    4. The process repeats
* *Consequence*.The bandwidth realized by the two connections eventually fluctuates along the qual bandwidth share line

    $\to$ This example provides an intuitive feel for why TCP results in an equal sharing of bandwidth among connections

**Realistic example**. In practice, assumptions in the simple case above are typically not met

$\to$ Client-server applications can obtain very unequal portions of link bandwidth
* *Observation from practice*. When multiple connections share a common bottleneck
    
    $\to$ Those sessions with a smaller RTT are able to grab the available bandwidth at that link more quickly, as it becomes free
    * *Consequence*. Smaller RTT results in higher throughput

### Fairness and UDP
**UDP and congestion control**. When running over UDP, applications can pump their audio and video into the network at a constant rate

$\to$ UDP occasionally lose packets, rather than reduce their rates to fair levels at times of congestion and not lose any packets
* *Consequence*. From the perspective of TCP, the multimedia applications running over UDP are not being fair
    * *Explain*. They do not cooperate with the other connections, nor adjust their transmission rates appropriately

        $\to$ UDP sources can crowd out TCP traffic

>**NOTE**. An area of research today is the development of congestion-control mechanisms for the Internet, which prevent UDP traffic from harming the Internet's throughput

### Fairness and parallel TCP connections
**Problem**. There is no way to stop a TCP-based application from using multiple parallel connections
* *Example*. Web browsers often use multiple parallel TCP connections to transfer the multiple objects within a Web page
* *Consequence*. The application gets a larger fraction of bandwidth in a congested link

# Appendix
## Concepts
**TCP splitting - optimizing the performance of cloud services**. For cloud services, e.g. search, e-mail, etc., it is desirable to provide a high-level of responsiveness

$\to$ Ideally, we should give users the illusion that the services are running locally
* *Problems*. Users are often located far away from the data centers, which are responsible for serving the dynamic content associated with the cloud services
    * *Explain*. The RTT will be large, potentially leading to poor response time performance due to TCP slow start
    * *Solution*. 
        * *Option 1*. Deploy front-end servers closer to the users
        * *Option 2*. Utilize TCP splitting by breaking the TCP connection at the front-end server
* *Idea*. 
    * The client establishes a TCP connection to the nearby front-end
    * The front-end maintains a persistent TCP connection to the data center with a very large TCP congestion window
* *Other benefit*. TCP splitting can reduce the TCP retransmission delays caused by losses in access networks

**Why fast recovery is recommended**.

**Relation between a connection's loss rate to the available bandwidth**.