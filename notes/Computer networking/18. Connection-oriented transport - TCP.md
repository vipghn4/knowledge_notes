<!-- TOC titleSize:1 tabSpaces:2 depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 skip:0 title:1 charForUnorderedList:* -->
# Table of Contents
- [Table of Contents](#table-of-contents)
- [Connection-oriented transport - TCP](#connection-oriented-transport---tcp)
  - [The TCP connection](#the-tcp-connection)
  - [TCP segment structure](#tcp-segment-structure)
    - [Sequence numbers and acknowledgement numbers](#sequence-numbers-and-acknowledgement-numbers)
    - [Telnet - A case study for sequence and acknowledgement numbers](#telnet---a-case-study-for-sequence-and-acknowledgement-numbers)
  - [Round-trip time estimation and timeout](#round-trip-time-estimation-and-timeout)
    - [Estimating the RTT](#estimating-the-rtt)
    - [Setting and managing the retransmission timeout interval](#setting-and-managing-the-retransmission-timeout-interval)
  - [Reliable data transfer](#reliable-data-transfer)
    - [A few interesting scenarios](#a-few-interesting-scenarios)
    - [Doubling the timeout interval](#doubling-the-timeout-interval)
    - [Fast retransmit](#fast-retransmit)
    - [Go-Back-N or selective repeat?](#go-back-n-or-selective-repeat)
  - [Flow control](#flow-control)
  - [TCP connection management](#tcp-connection-management)
- [Appendix](#appendix)
  - [Concepts](#concepts)
<!-- /TOC -->

# Connection-oriented transport - TCP
## The TCP connection
**Connection-oriented protocol**. Before one application process can begin to send data to another, the two processes must handshake with each other
* *Explain*. They must send some preliminary segments to each other to establish the parameters of ensuring data transfer

    $\to$ As part of TCP connection establishment, both sides of the connection will initialize many TCP state variables associated with the TCP connection
* *End-end protocols*. TCP connection is not an end-to-end TDM or FDM circuit as in a circuit switched network, nor a virtual circuit as the connection state resides entirely in the two end systems
    * *Explain*. TCP protocol runs only in the end systems, not in the intermediate network elements, i.e. routers and link-layer switches

        $\to$ The intermediate network elements do not maintain TCP connection state
    
    >**NOTE**. The intermediate routers are completely oblivious to TCP connections, i.e. they see datagrams, not connections

**Characteristics**.
* *Full-duplex service*. A TCP connection provides a full-duplex service
    * *Explain*. If there is a TCP connection between process A on one host, and process B on another host

        $\to$ Application layer data can flow from process A to process B at the same time as application data flows from process B to process A
* *Point-to-point connection*. A TCP connection is always point-to-point
    * *Explain*. The connection is only between a single sender and a singler receiver

>**NOTE**. Multicasting is not possible with TCP

**Three-way handshake**.
1. The client application process informs the client transport layer that it wants to establish a connection to a process in the server
2. TCP in the client proceeds to establish a TCP connection with TCP in the server, by sending a special TCP segment
3. The server responds with a second special TCP segment
4. The client responds with a third special segment

>**NOTE**. The first two segments carry no payload, the third one may carry a payload

**Data transfer with TCP**. Once a TCP connection is established, the two application processes can send data to each other

<div style="text-align:center">
    <img src="https://i.imgur.com/cgzYUSL.png">
    <figcaption>TCP send and receive buffers</figcaption>
</div>

1. The client process passes a stream of data through the socket
2. Once the data passes through the socket, the data is in hands of TCP running in the client
3. TCP directs this data to the connection's send buffer, i.e. one of the buffers set aside during the initial three-way handshake
4. From time to time, TCP grabs chunks of data from the send buffer and pass the data to the network layer

**Maximum segment size (MSS)**. The maximum amount of data which can be grabbed and placed in a segment
* *Setting MSS*. The MSS is typically set by
    1. Determine the MTU of the local sending host
    2. Set the MSS to ensure that a TCP segment, when encapsulated in an IP datagram, plus the TCP/IP header length will fit into a single link-layer frame
* *Maximum transmission unit (MTU)*. The length of the largest link-layer frame, which can be sent by the local sending host
* *Typical MSS value*. Both Ethernet and PPP link-layer protocols have an MSS of 1500 bytes

    >**NOTE**. MSS is the maximum amount of application-layer data in the segment, not the maximum size of the TCP segment including headers

**TCP segments**. TCP pairs each chunk of client data with a TCP header, forming TCP segments
* *Segment processing and transfer*.
    1. The segments are passed down to the network layer, where they are separately encapsulated within network-layer IP datagrams
    2. The IP datagrams are sent into the network
    3. When TCP receives a segment at the other end, the segment's data is placed in the TCP connection's receive buffer
    4. The application reads the stream of data from the buffer
* *Observation*. Each side of the connection has its own send buffer and its own receive buffer

## TCP segment structure
**TCP segment structure**. Consist of header fields and a data field 

<div style="text-align:center">
    <img src="https://i.imgur.com/T4Q5uM7.png">
    <figcaption>TCP send and receive buffers</figcaption>
</div>

* *Data field*. Contain a chunk of application data, whose size is limited by the MSS
    * *Transmitting large files*. When TCP sends a large file, e.g. an image as part of a Web page, it typically breaks the file into chunks of size MSS
    * *Transmitting interactive applications' data*. TCP often transmit data chunks smaller than the MSS
* *Header fields*.
    * *Source and destination port numbers*. Used for multiplexing and demultiplexing data from / to upper-layer applications
    * *Checksum field*. Just as UDP
    * *Sequence number field (32 bit) and acknowledgement number field (32 bit)*. Used by the TCP sender and receiver in implementing a reliable data transfer service
    * *16-bit receive window field*. Used for flow control, i.e. indicate the number of bytes which a receiver is willing to accept
    * *4-bit header length field*. Specify the length of the TCP header in 32-bit words
        * *Explain*. The TCP header can be of variable length, due to the TCP options field
    * *Optional and variable-length options field*. Used when a sender and receiver negotiate the MSS, or as a window scaling factor for use in high-speed networks, or a time-stamping option
        * *Reference documentation*. RFC 854 and RFC 1323
    * *Flag field (6 bits)*. 
        * *ACK bit*. Used to indicate that the value carried in the acknowledgement field is valid
            
            $\to$ The segment contains an acknowledgement for a segment, which has been successfully received
            * *"ACK" meaning*. Acknowledgement, i.e. used to acknowledge the successful receipt of a packet
        * *RST, SYN, and FIN bits*. Used for connection setup and teardown
            * *"RST" meaning*. Reset, i.e. sent from the receiver to the sender when a packet is sent to a particular host which was not expecting it
            * *"SYN" meaning*. Synchronization, i.e. used as a first step in establishing a three-way handshake between two hosts
            * *"FIN" meaning*. Finished, i.e. there is no more data from the sender
        * *PSH bit*. Indicate that the receiver should pass the data to the upper layer immediately, rather than waiting in the buffer
            * *"PSH" meaning*. Push
        * *URG bit*. Indicate that there is data in this segment, which the sending-side upper-layer entity has marked as "urgent"

            $\to$ The urgent segment should be prioritized over other segments in the buffer
    * *Urgent data pointer field (16 bits)*. Contain the location of the last byte of this urgent data

        $\to$ TCP must inform the receiving-side upper-layer entity when urgen data exists, and pass it a pointer to the end of the urgent data
        * *Explain*. This pointer indicates how much of the data in the segment, counting from the first byte, is urgent

    >**NOTE**. In practice, PSH, URG, and the urgent data pointer are not used

### Sequence numbers and acknowledgement numbers
**Sequence numbers and acknowledgement numbers**. Two of the most important fields in the TCP segment header
* *Purpose*. Critical for reliable data transfer service

**Sequence number**. TCP views data as an unstructured, but ordered, stream of bytes

$\to$ TCP's use of sequence numbers reflects this view in that sequence numbers are over the stream of transmitted bytes, not over the series of transmitted segments
* *Sequence number for a segment*. The byte-stream number of the first byte in the segment
* *Example*. 

    <div style="text-align:center">
        <img src="https://i.imgur.com/K9bFkNX.png">
        <figcaption>Dividing file data into TCP segments</figcaption>
    </div>

    * *Assumptions*. 
        * A process in host A wants to send a stream of data to a process in host B over a TCP connection
        * The data stream is a file of 500,000 bytes
        * The MSS is 1,000 bytes
        * The first byte of the data stream is numbered 0
    * *Data transfer procedure*.
        1. TCP in host A will implicitly number each byte in the data stream
        2. TCP constructs 500 segments out of the data stream
        3. The first segment has sequence number 0, the second segment has sequence number 1000, the third segment has sequence number 2000, etc.
        4. The sequence numbers are iunserted in the sequence number field in the header of the appropriate TCP segments

**Acknowledgement number**. Recall that TCP is full-duplex, i.e. host A may be receiving data from host B while it sends data to host B, as part of the same TCP connection

$\to$ Each segment arriving from host B has a sequence number for the data flowing from B to A
* *Acknowledgement number put by host A on its segment*. The sequence number of the next byte host A is expecting from host B
    * *Example 1*. Suppose host A has received all bytes from 0 to 535 from B, and it is about to send a segment to host B

        $\to$ Host A puts 536 in the acknowledgement number field of the segment sent to B, i.e. host A is waiting for byte 536
    * *Example 2*. Suppose host A has received one segment from host B containing bytes 0 to 535, and another segment containing bytes 900 to 1000

        $\to$ Host A has not received bytes 536 to 899, thus A's next segment will contain 536 in the acknowledgement number field
    * *Example 3*. Suppose host A has received the third segment, i.e. bytes 900 to 1000, before receiving the second segment, i.e. bytes 536 to 899

        $\to$ The third segment arrived out of order
        * *Problem*. What to do if host A receives out-of-order segments in a TCP connnection

            $\to$ TCP RFCs do not impose any rules here and leave the decision up to the people programming a TCP implementation
        * *Solutions*. There are two options, and the latter is more often used in practice
            * The receiver immediately discards out-or-order segments, i.e. GBN
            * The receiver keeps the out-of-order bytes and waits for the missing bytes to fill the gaps, i.e. selective repetition
* *Cumulative acknowledgements*. TCP only acknowledges bytes up to the first missing byte in the stream

**Initial sequence number**. In practice, both sides of a TCP connection randomly choose an initial sequence number
* *Purpose*. Minimize the possibility that a segment, which is still in the network from an earlier, already-terminated connection between two hosts, is mistaken for a valid segment in a later connection between the same two hosts

### Telnet - A case study for sequence and acknowledgement numbers
**Telnet**. A popular application-layer protocol used for remote login, which runs over TCP and is designed to work between any pair of hosts
* *Reference documentation*. RFC 854

>**NOTE**. Many users now prefer to use SSH protocol rather than Telnet, since data sent in a Telnet connection, including passwords, is not encrypted

**Scenario**.

<div style="text-align:center">
    <img src="https://i.imgur.com/LDMUi4V.png">
    <figcaption>Sequence and acknowledgement numbers for a simple Telnet application over TCP</figcaption>
</div>

* *Assumptions*.Host A initiates a Telnet session with host B

    $\to$ Host A is the client, and host B is the server
* *Interaction procedure*.
    1. Each character typed by the user, at the client, will be sent to the remote host
    2. The remote host will send back a copy of each character, which will be displayed on the Telnet user's screen

        $\to$ This ensures that characters seen by the Telnet user have been received and processed at the remote site
        * *Consequence*. Each character traverses the network twice between the time the user hits the key, and the time the character is displayed on the user's monitor

**Piggybacked acknowledgement**. Acknowledgement for client-to-server data is carried in a segment carrying server-to-client data

## Round-trip time estimation and timeout
**Timing out in TCP**. TCP, like `rdt` protocol in the last section, uses a timeout/retransmit mechanism to receover from lost segments

$\to$ The most obvious question is the length of the timeout intervals
* *Idea*. The timeout should be larger than the connection's round-trip time (RTT)

    $\to$ Otherwise, unncessary retransmissions would be sent

### Estimating the RTT
**Procedure**.
* *Sample RTT*. Denoted as `SampleRTT`, is the amount of time between when the segment is sent, i.e. passed to IP, and when an acknowledgement for the segment is received
    * *Sampling `SampleRTT`*. Most TCP implementations take one `SampleRTT` measurement at a time

    >**NOTE**. TCP never computes a `SampleRTT` for a segment which has been rertransmitted
    >$\to$ It only measures `SampleRTT` for segments which have been transmitted once

* *Fluctuation of `SampleRTT`*. Due to congestion in routers and to the varying load on the end systems
* *Solution to estimate a typical RTT*. Take some sort of average of the `SampleRTT` values

    $\to$ TCP maintains an average, i.e. `EstimatedRTT`, of the `SampleRTT` values
    * *Update formula for `EstimatedRTT`*. `EstimatedRTT = (1 - alpha) * EstimatedRTT + alpha * SampleRTT`
        * *Recommended value for `alpha`*. 0.125
* *Estimate the variability of the RTT*. Denoted as `DevRTT`
    * *Reference documentation*. RFC 6298
    * *Formula*. `DevRTT = (1 - beta) * DevRTT + beta * |SampleRTT - EstimatedRTT|`
        * *Recommended value for `beta`*. 0.25

**Principles in practice**. TCP provides reliable data transfer by using possible acknowledgements and timers in much the same way described in the last section
* *NAK mechanism*. Certain versions of TCP also have an implicit NAK mechanism
    * *Idea*. With TCP's fast retransmit mechanism, the receipt of three duplicate ACKs for a given segment serves as an implicit NAK for the following segment

        $\to$ This NAK triggers retransmission of that segment before timeout

>**NOTE**. TCP cannot tell for certain if a segment, or its ACK, is lost, corrupted, or overly delayed, i.e. it always retransmit the segment in question

### Setting and managing the retransmission timeout interval
**Idea**. The timeout interval should be greater than `EstimatedRTT` by some margin, which is large when there is a lot of fluctuation in the `SampleRTT`, or small otherwise

**Formula for timeout intervals**. `TimeoutInterval = EstimatedRTT + 4 * DevRTT`
* *Initial value of `TimeoutInterval`*. 1 second, as recommended by RFC 6298
* *Update value of `TimeoutInterval`*. 
    * When a timeout occurs, the value of `TimeoutInterval` is doubled to avoid a premature timeout occuring for subsequent segment which will soon be acknowledged
    * As soon as a segment is received and `EstimatedRTT` is updated

        $\to$ The `TimeoutInterval` is computed using the above formula

## Reliable data transfer
**Reliable data transfer via TCP**. TCP creates a reliable data transfer service on top of IP's unreliable best-effort service
* *Purpose*. Ensure that the data stream that a process reads out of its TCP receive buffer is uncorrupted, without gaps, without duplication, and insequence

    $\to$ The byte stream is exactly the same byte stream sent by the end system on the other side of the connection

**Time management**. In earlier development of reliable data transfer techniques

$\to$ It was conceptually easiest to assume that an individual timer is accosiated with each transmitted, but not yet acknowledged segment
* *Problem*. Timer management can require considerable overhead

    $\to$ The recommended TCP timer management procedures use only a single retransmission timer, even if there are multiple transmitted but not yet acknowledged segments
* *Reference documentation*. RFC 6298

**Simplified description of TCP sender using only timeouts to recover from lost segments**.  Support the data is sent in only one direction, from host A to host B, and the transmitted file is large
* *Example code*.

    ```cpp
    /* Assume sender is not constrained by TCP flow or congestion control, that data from above is less
    than MSS in size, and that data transfer is in one direction only. */
    NextSeqNum = InitialSeqNumber
    SendBase = InitialSeqNumber
    
    loop (forever) {
        switch(event)
            event: data received from application above
                create TCP segment with sequence number NextSeqNum
                if (timer currently not running)
                    start timer
                pass segment to IP
                NextSeqNum = NextSeqNum + length(data)
                break;
        
            event: timer timeout
                retransmit not-yet-acknowledged segment with smallest sequence number
                start timer
                break;
            
            event: ACK received, with ACK field value of y
                // SendBase is the largest ACK number received
                if (y > SendBase) {
                    SendBase = y
                    if (there are currently any not-yet-acknowledged segments)
                        start timer
                }
                break;

    } /* end of loop forever */
    ```

* *Data received from above*. Upon the occurrence of this event, TCP receives data from the application, encapulates the data in a segment, and passes the segment to IP
    * *Sequence number*. Each segment includes  a sequence number, which is the byte-stream number of the first data byte in the segment
    * *Timer*. If the timer is already not running for some other segment, TCP starts the timer when the segment is passed to IP

        >**NOTE**. It is helpful to think of the timer as being associated with the oldest unacknowledged segment
    
    * *Expiration interval for the timer*. Indicated bhy `TimeoutInterval`
* *Timeout*. TCP responds to timeout event by retransmitting the segment causing the timeout, then restarting the timer
* *The arrival of an ACK from the receiver*. On the occurrence of this event, TCP compares the ACK value `y` with its variable `SendBase`
    * *`SendBase`*. The sequence number of the oldest unacknowledged byte
    * *Cumulative acknowledgement*. `y` acknowledges the receipt of all bytes before byte number `y`

**More complete description using duplicate acknowledgements in addition to timeouts**. Support the data is sent in only one direction, from host A to host B, and the transmitted file is large

### A few interesting scenarios

### Doubling the timeout interval
**Timeout interval length after a timer expiration**. Whenever the timeout event occurs, TCP retransmites the not-yet-acknowledged segment with the smallest sequence number
* *Timeout interval update*. 
    * *Exponential update*. Each time TCP retransmits, it sets the next timeout interval to twice the previous value, rather than deriving it from `EstimatedRTT` and `DevRTT`

    $\to$ The intervals grow exponentially after each retransmission
    * *Statistical update*. Whenever the timer is started after either of data-received-from-application-above or ACK-received events

        $\to$ The `TimeoutInterval` is derived from the most recent values of `EstimatedRTT` and `DevRTT`

**Congestion control**. TCP with timeout intervals provides a limited form of congestion control
* *Explain*. The timer expiration is most likely caused by the congestion in the network, i.e. too many packets arriving at one or more router queues in the path between the source and the destination

    $\to$ This causes packets to be dropped and / or long queing delays
* *Consequence*. In times of congestion, if the sources continue to retransmit packets persistently, the congestion may get worse

    $\to$ TCP acts more politely, with each sender retransmitting after long and longer intervals

### Fast retransmit
**Long timeout interval**. One of the problems with timeout-triggered retransmission is that the timeout period can be relatively long

$\to$ When a segment is lost, this long timeout period forces the sender to delay resending the lost packet, thus increases the end-to-end delay
* *Solution*. The sender can often detect packet loss well before the timeout event occurs by using duplicate ACKs

**Duplicate ACK**. An ACK which reacknowledges a segment, for which the sender has already received an earlier acknowledgement

<div style="text-align:center">
    <img src="https://i.imgur.com/Un6QfYA.png">
    <figcaption>TCP ACK generation recommendation</figcaption>
</div>

* *Why receiver sends a duplicate ACK*. When a TCP receiver receives a segment with a sequence number, which is larger than the next, expected, in-order sequence number
    1. It detects a gap in the data stream, i.e. missing segments as a result of lost or reordered segments within the network
    2. TCP receiver then reacknowledges, i.e. generates a duplicate ACK for, the last in-order byte of data it has received

        $\to$ If one segment is lost, there will likely be many back-to-back duplicate ACKs, since the sender often sends a large number of segments back to back
    3. If the TCP sender receives three duplicate ACKs for the same data, it takes this an indication that the segment following the acknowledged segment has been lost
    4. The TCP sender then performs a fast retransmit, i.e. transmit the missing segment before that segment's timer expires

>**NOTE**. Many subtle issues arise when a timeout/retransmit mechanism is implemented in an actual protocol such as TCP

**Example code of TCP sender for ACK-received event**.

```cpp
event: ACK received, with ACK field value of y
    if (y > SendBase) {
        SendBase = y
        if (there are currently any not yet acknowledged segments)
            start timer
    }
    else { /* a duplicate ACK for already ACKed segment */
        increment number of duplicate ACKs received for y
        if (number of duplicate ACKS received for y==3)
            /* TCP fast retransmit */
            resend segment with sequence number y
    }
    break;
```

### Go-Back-N or selective repeat?
**TCP repetition method**. TCP acknowledgements are cumulative and correctly-received-but-out-of-order segments are not individually ACKed by the receiver

$\to$ TCP sender need only maintain the smallest sequence number of a transmittted-but-unacknowledged byte, and the sequence number of the next byte to be sent
* *TCP and GBN*. TCP looks a lot like GBN, but many TCP implementations will buffer correctly-received-but-out-of-order segments
    * *Assumptions*.
        * Packets $1,2,\dots,N$ and all of the segments arrive in order without error at the receiver
        * The acknowledgement for packet $n<N$ gets lost, but the remaining $N-1$ acknowledgements arrive at the sender before their timeouts
    * *GBN behavior*. Retransmit packets $n+1,n+2,\dots,N$
    * *TCP behavior*. Retransmit at most one segment, i.e. segment $n$

        >**NOTE**. TCP would not even retransmit segment $n$ if the acknowledgement for segment $n+1$ arrived before the timeout for segment $n$

**Selective acknowledgement**. A proposed modification to TCP in RFC 2018
* *Purpose*. ALlow a TCP receiver to acknowledgement out-of-order segments selectively, rather than just cumulatively acknowledging the last correctly recevied, in-order segment

    $\to$ When combined with selective transmission, TCP looks a lot like the selective repeat protocol
* *Consequence*. TCP's error-recovery mechanism is probably best categorized as a hybrid of GBN and SR protocols

## Flow control
**Packet buffering at receiving end**. Hosts on each sidew of a TCP connection set aside a receive buffer for the connection
* *Idea*. When the TCP connection recevies bytes which are correct and in-order

    $\to$ It places the data in the receive buffer
* *Packet consumption*. The associated application process will read data from the receiving buffer, but not necessarily at the instant the data arrives
    * *Explain*. The receiving application may be busy with some other task, and may not even attempt to read the data until long after it has received
* *Consequence*. If the application is relatively slow at reading the data

    $\to$ The sender can very easily overflow the cnonection's receive buffer by sending too much data too quickly

**Flow-control service**. TCP provdes a flow-control service to its applications to eliminate the possibility of sender overflowing the receiver's buffer
* *A speed-matching service*. Flow control matches the rate, at which the sender is sending, against the rate, at which the receiving application is reading

    >**NOTE**. A TCP sender can also be throttled due to congestion within the IP network, i.e. congestion control

    >**NOTE**. Flow control and congestion control are different

**Flow control implementation**. 
* *Receive window*. TCP provides flow control by having the sender maintain a variable called the receive window
    * *Idea*. Give the sender an idea of how much free buffer space is available at the receiver

        >**NOTE**. Since TCP is full-duplex, the sender at each side of the connection maintains a distinct receive window

* *Scenario*. 
    * Host A is sending a large file to host B over a TCP connection
    * Host B allocates a receive buffer to the connection, whose size is denoted by `RcvBuffer`
    * From time to time, the application process in host B reads from the buffer
    * `LastByteRead` is the number of the last byte in the data stream read from the buffer by the application process in B
    * `LastByteRecvd` is the number of the last byte in the data stream arrived from the network, and has been placed in the receive buffer at B
* *The receive window `rwnd`*. The amount of spare room in the buffer

    <div style="text-align:center">
        <img src="https://i.imgur.com/Qf4aivA.png">
        <figcaption>The receive window and the receive buffer</figcaption>
    </div>

    * *Formula*. `rwnd = RcvBuffer - [LastByteRcvd - LastByteRead]`
    * *Explain*. TCP is not permitted to overflow the allocated buffer

        $\to$ `LastByteRcvd - LastByteRead <= RcvBuffer`
* *Receive window and flow control*. Host B tells host A how much spare room it has in the connection buffer, by placing its current value of `rwnd` in the receive window field of every segment it sends to A
    * *Variables kept track by host A*. `LastByteSent` and `LastByteAcked`
        * *The amount of unacknowledged data*. `LastByteSent - LastByteAcked`
        * *Flow control in host A*. By keeping the amount of unacknowledged data less than the value of `rwnd`
            
            $\to$ Host A is assured that it is not overflowing the receive buffer at host B
            * *Formal*. `LastByteSent - LastByteAcked <= rwnd`
    * *Initial value of `rwnd`*. Host B sets `rwnd = RcvBuffer`

        >**NOTE**. To pull this off, host B must keep track of several connection-specific variables

**Problem with zero `rwnd`**. 
* *Scenario*.
    * Host B's receive buffer becomes full, i.e. `rwnd` is zero
    * After informing zero `rwnd` to host A, suppose host B has nothing to send to A
* *Problem*. As the application process at host B empties the buffer, TCP does not send new segments with new `rwnd` values to host A
    * *Explain*. TCP sends a segment to host A only if it has data to send, or if it has an acknowledgement to send
    * *Consequence*. Host A is never informed that some space has opened up in host B's receive buffer

        $\to$ Host A is blocked and can transmit no more data
* *Solution*. The TCP specification requires host A to continue to send segments with one data byte, when B's receive window is zero

    $\to$ These segments will be acknowledged by the receiver
    * *Consequence*. Eventually, the buffer will begin the empty and the acknowledgements will contain a nonzero `rwnd` value

**Flow control in UDP**. UDP does not provide flow control
* *Explain*. Consider sending a series of UDP segments from a process on host A to a process on host B
    * For a typical UDP implementation, UDP will append the segments in a finite-sized b uffer, which precedes the corresponding socket
    * The process reads one entire segment at a time from the buffer

        $\to$ If the process does not read the segments fast enough from the buffer, the buffer will overflow and segments will get dropped

## TCP connection management
**Why we concern TCP connection establishment and termination**. 
* TCP connection establishment can significantly add to perceived delays, e..g when surfing the Web
* Many of the most common network attacks, including SYN flood attack, exploit vulnerabilities in TCP connection management

**TCP connection establishment steps**. Suppose a process running in one host, i.e. client, wants to initiate a connection with another process in another host, i.e. server

<div style="text-align:center">
    <img src="https://i.imgur.com/4hkhS3J.png">
    <figcaption>TCP three-way handshake - segment exchange</figcaption>
</div>

* *Brief description*.
    1. The client application process informs the client TCP that it wants to establish a connection to a process in the server
    2. The TCP in the client proceeds to establish a TCP connection with the TCP in the server with the following details steps
* *Details steps*.
    1. The client-side TCP firsts sends a special TCP segment to the server-side TCP
        * *Segment content*. Contain no application-layer data, but the SYN bit is set to 1
            * *SYN segment*. Due to the segment content, this segment is called a SYN segment
            * *Why "SYN"*. The SYN flag synchronizes sequence numbers to initiate a TCP connection
        * *Initial sequence number of client*. The client randomly chooses an initial sequence number, i.e. `client_isn`, and puts this number in the sequence number field of the initial TCP SYN segment

            >**NOTE**. There has been considerable interest in properly randomizing the choice of the `client_isn` to avoid certain security attacks

        * *Segment transfer to server*. The segment is encapsulated within an IP datagram, and send to the server
    2. Once the IP datagram containing the TCP SYN segment arrives at the server host

        $\to$ The sender extracts the TCP SYN segment from the datagram, allocates the TCP buffers and variables to the connection, and sends a connection-granted segment to the client TCP

        >**NOTE**. The allocation of these buffers and variables before completing the third step of the handshake makes TCP vulnerable to a denial-of-service attack, known as SYN flooding

        * *Connection-granted segment content*. Contain no application-layer data, but the following bits are set
            * The SYN bit is set to 1
            * The acknowledgement field of the TCP segment header is set to `client_isn + 1`
            * The sequence number field is set to `server_isn`, i.e. the server's initial sequence number
        * *SYN-ACK segment*. The connection-granted segment is referred to as SYN-ACK segment
    3. The client allocates buffers and variables to the connection, then sends the server another segment
        * *Purpose*. Acknowledge the server's connection-granted segment
        * *Segment content*
            * `server_isn + 1` is put in the acknowledgement field of the TCP segment header
            * SYN bit is set to zero, i.e. the connection is established
            * Client-to-server data may be added to the segment payload
* *Future segment exchange*. The client and server hosts can now send segments containing data to each other, with SYN bit set to zero

**Connection termination**. Either of the two processes in a TCP connection can end the connection

$\to$ When a connection ends, the resources, i.e. buffers and variables, in the hosts are deallocated

<div style="text-align:center">
    <img src="https://i.imgur.com/BR0nMiv.png">
    <figcaption>Closing a TCP connection</figcaption>
</div>

* *Connection termination steps*.
    1. The client applicaiton process issues a close command, causing the client TCP to send a special TCP segment to the server
        * *Segment content*. Have the FIN bit in the segment's header set to 1
    2. When the server receives the segment, it sends the client an acknowledgement segment in return
    3. The server then sends its own shutdown segment, having the FIN bit set to 1
    4. The client acknowledges the server's shutdown segment

        $\to$ At this point, all the resources in the two hosts are deallocated

**TCP state**. During the life of a TCP connection, the TCP protocol running in each host makes transitions through various TCP states

<div style="text-align:center">
    <img src="https://i.imgur.com/0y7xgrO.png">
    <figcaption>Typical sequence of TCP states visited by a client TCP</figcaption>
</div>

<div style="text-align:center">
    <img src="https://i.imgur.com/pBzbJdk.png">
    <figcaption>Typical sequence of TCP states visited by a server TCP</figcaption>
</div>

**Communication preparation**. Earlier discussion assumed that both the client and server are prepared to communicate
* *Explain*. The server is listening on the port, to which the client sends its SYN segment
* *Problem*. What if a host receives a TCP segment, whose port numbers or source IP address do not match with any of the ongoing sockets in the host
* *Solution for TCP*. The host will send a special reset segment to the source, with RST flag bit set to 1
    * *Intuition*. The host is telling the source "I do not have a socket for that segment. Please do not resend the segment"
* *Solution for UDP*. The host sends a special ICMP datagram

# Appendix
## Concepts
**The SYN flood attack**. The attacker(s) send a large number of TCP SYN segments, without completing the third handshake step

$\to$ The server's connection resources become exhausted as they are allocated, but never used, for half-open connections
* *SYN cookies*. An effective defense deployed in most major OSes to preventSYN flood attack
    * *Server-side activities*. When the server receives a SYN segment, it does not know if the segment is coming from a legitimate user, or is part of a SYN flood attack
        * *Cookie*. The server creates an initial TCP sequence number called a "cookie"

            $\to$ The server then sends the client a SYN-ACK packet with this special initial sequence number
            * *Formation*. A complicated function, e.g. hash function, of 
                * Source and destination IP addresses 
                * Port numbers of the SYN segment
                * A secret number only known to the server
        * *Memorizing the cookie*. The server does not remember the cookie or any other state information corresponding to the SYN
    * *Client-side activities*.
        * *Legitimate client's activities*. Return an ACK segment, which is then received by the server

            $\to$ The server then verify if the ACK corresponds to some SYN sent earlier to create a fully open connection along with a socket
        * *Attacker's activities*. Do not return an ACK segment, and the original SYN has done no harm at the server
            * *Explain*. The server has not yet allocated any resources in response to the original bogus SYN
* *How SYN cookies prevent SYN flood attacks*.
    * *Ordinary TCP connection establishment*. The TCP server must memorize the connection state of previously coming SYN segments

        $\to$ In case of SYN flood attack, the memory allocated to TCP will be filled with connection states, then be exhausted
    * *SYN cookie*. The TCP server now do not have to memorize the connection state

        $\to$ The memory will not be filled with connection states

**`nmap`**. A port scanning tool
* *Mechanism*. To exploire a specific TCP port, `nmap` will send a TCP SYN segment with the specified destination port to the desired host
* *Possible outcomes*.
    * *The source host receives a TCP SYN-ACK segment from the target host*. This means an application is running with the explored TCP port

        $\to$ `nmap` returns "open"
    * *The source host receives a TCP RST segment from the target host*. This means the SYN segment reached the target host, but the target host is not running an application with the desired port

        $\to$ At least the attacker knows that the segment destination to the host at the explored port are not blocked by any firewall
    * *The source receives nothing*. This likely means that the SYN segment was blocked by an intervening firewall, and never reached the target host