<!-- TOC titleSize:1 tabSpaces:2 depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 skip:0 title:1 charForUnorderedList:* -->
# Table of Contents
- [Table of Contents](#table-of-contents)
- [Streaming stored video](#streaming-stored-video)
  - [UDP streaming](#udp-streaming)
  - [HTTP streaming](#http-streaming)
    - [Prefetching video](#prefetching-video)
    - [Client application buffer and TCP buffers](#client-application-buffer-and-tcp-buffers)
    - [Analysis of video streaming](#analysis-of-video-streaming)
    - [Early termination and repositioning the video](#early-termination-and-repositioning-the-video)
  - [Adaptive streaming and DASH](#adaptive-streaming-and-dash)
  - [Content distribution networks](#content-distribution-networks)
  - [Case studies - Netflix, Youtube, and Kankan](#case-studies---netflix-youtube-and-kankan)
- [Appendix](#appendix)
  - [Discussion](#discussion)
<!-- /TOC -->

# Streaming stored video
**Streaming video systems categories**. UDP streaming, HTTP streaming, and adaptive HTTP streaming
* *Major types*. HTTP streaming and adaptive HTTP streaming

**Data buffering**. A common characteristic of all three forms of video streaming is the extensive use of client-side application buffering
* *Purposes*. 
    * Mitigate the effects of varying end-to-end delays
    * Mitigate the effects of varying bandwidth between server and client
* *Motivation*. For streaming video, both stored and live, users generally can tolerate a small several second initial delay between when the client requests a video, and when video playout begins at the client
* *Idea*.
    * When the video starts to arrive at the client, the client need not immediately begin playout, but build up a reserve of video in an application buffer
    * Once the client has built up a reserve of several seconds of buffered-but-not-played video

        $\to$ The client can begin video playout
* *Benefits*.
    * Client-side buffering can absorb variations in server-to-client delay
        * *Explain*. If a particular piece of video data is delayed, as long as it arrives before the reserve of received-but-not-played video is exhausted

            $\to$ This long delay will not be noticed
    * If the server-to-client bandwidth briefly drop below the video consumption rate

        $\to$ A user can continue to enjoy continuous playback, as long as the client application buffer does not become completely drained

## UDP streaming
**UDP streaming**. The server transmits video at a rate which matches the client's consumption rate by clocking out the video chunks over UDP at a steady state
* *Example*. If the video consumption rate is 2 Mbps, and each UDP packet carries 8000 bits of video

    $\to$ The server would transmit one UDP packet into its socket every $\frac{8000 \text{bits}}{2 \text{Mbps}} = 4\text{msec}$
* *Explain*. UDP does not employ a congestion-control mechanisms

    $\to$ The server can push packets into the network at the consumption rate of the video without the rate-control restrictions of TCP
* *Data buffering*. UDP streaming typically uses a small client-side buffer, big enough to hold less than a second of video

**Packet encapsulation**. Before passing the video chunks to UDP

$\to$ The server will encapsulate the video chunks within transport packets specially designed for transporting video and audio
* *Implementation*. Use Real-Time Transport Protocol (RTP), or a similar (possibly proprietary) scheme

**Client-server connection**.The client and server maintain, in parallel, a separate control connection, over which the client sends commands regarding session state changes
* *Session state changes*. Pause, resume, reposition, etc.

    $\to$ This control connection is in many ways analogous to the FTP control connection

**Significant drawbacks**.
* Due to the unpredictable and varying amount of available bandwidth between server and client

    $\to$ Constant-rate UDP streaming can fail to provide continuousplayout
* UDP stream requires a media control server, e.g. a RTSP server, to process client-to-server interactivity requests, and to track client state for each ongoing client session

    $\to$ This increases the overall cost and complexity of deploying a large-scale video-on-demand system
* Many firewalls are configured to b lock UDP traffic, preventing the users behind these firewalls from receiving UDP video

## HTTP streaming
**HTTP streaming**. The video is simply stored in an HTTP server, as an ordinary file with a specific URL
* *Procedure*. 
    1. When a user wants to see the video
        
        $\to$ The client establishes a TCP connection with the server, and issues an HTTP GET request for the URL
    2. The server sends the video file, within an HTTP response message, as quickly as possible
        * *Explain*. As quickly as TCP congestion control and flow control will allow
    3. On the client side, the bytes are collected in a client application buffer
    4. Once the number of bytes in the buffer exceeds a predetermined threshold

        $\to$ The client application begins playback
        * *Explain*. The client side periodically grabs video frames from the client application buffer, decompresses the frames, and displays them on the user's screen

**Server-to-client transmission rate**. 
* *Congestion control*. Can vary significantly due to TCP's congestion control mechanism

    $\to$ It is not uncommon for the transmission rate to vary in a saw-tooth manner associated with TCP congestion control
* *Retransmission*. Packets can be significantly delayed due to TCP's retransmission mechanism

**Why TCP for video streaming**.
* Due to its characteristics, the conventional wisdom in the 1990s was that video streaming would never work well over TCP
* Over time, designers of streaming video systems learned that TCP's congestion control and reliable-data transfer mechanisms do not necessarily preclude continuous playout
    * *Explain*. Due to client-side buffering and prefetching

**Benefits of using TCP**. Most video streaming applications today is using HTTP streaming over TCP as its underlying streaming protocol
* Allow the video to traverse firewalls and NATs more easily, which are often configured to block most UDP traffic but to allow most HTTP traffic
* Obviate the need for a media control server, e.g. RTSP server

    $\to$ This reduces the cost of a large-scale deployment over the Internet

### Prefetching video

### Client application buffer and TCP buffers

### Analysis of video streaming

### Early termination and repositioning the video

## Adaptive streaming and DASH

## Content distribution networks

## Case studies - Netflix, Youtube, and Kankan

# Appendix
## Discussion
**Why UDP-based video streaming requires RTSP server**.