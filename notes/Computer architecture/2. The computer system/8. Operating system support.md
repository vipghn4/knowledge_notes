<!-- TOC titleSize:1 tabSpaces:2 depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 skip:0 title:1 charForUnorderedList:* -->
# Table of Contents
- [Table of Contents](#table-of-contents)
- [Operating system support](#operating-system-support)
  - [Operating system overview](#operating-system-overview)
    - [Operating system objectives and functions](#operating-system-objectives-and-functions)
      - [The operating system as a user-computer interface](#the-operating-system-as-a-user-computer-interface)
      - [The operating system as resource manager](#the-operating-system-as-resource-manager)
    - [Types of operating systems](#types-of-operating-systems)
      - [Early systems](#early-systems)
      - [Simple batch systems](#simple-batch-systems)
      - [Multiprogrammed batch systems](#multiprogrammed-batch-systems)
      - [Time-sharing systems](#time-sharing-systems)
  - [Scheduling](#scheduling)
    - [Long-term scheduling](#long-term-scheduling)
    - [Medium-term scheduling](#medium-term-scheduling)
    - [Short-term scheduling](#short-term-scheduling)
      - [Process states](#process-states)
      - [Scheduling techniques](#scheduling-techniques)
  - [Memory management](#memory-management)
    - [Swapping](#swapping)
    - [Partitioning](#partitioning)
    - [Paging](#paging)
    - [Virtual memory](#virtual-memory)
      - [Demand paging](#demand-paging)
      - [Page table architecture](#page-table-architecture)
    - [Translation lookaside buffer](#translation-lookaside-buffer)
    - [Segmentation](#segmentation)
  - [Pentium memory mangement](#pentium-memory-mangement)
  - [ARM memory management](#arm-memory-management)
    - [Memory system organization](#memory-system-organization)
    - [Virtual memory address translation](#virtual-memory-address-translation)
    - [Memory-management formats](#memory-management-formats)
    - [Access control](#access-control)
- [Appendix](#appendix)
  - [Concepts](#concepts)
<!-- /TOC -->

# Operating system support
## Operating system overview
### Operating system objectives and functions
**Operating system**. A program controlling the execution of application programs and acting as an interface between applications and the computer hardware
* *Objectives*. 
    * *Convenience*. An OS makes a computer more convenient to use
    * *Efficiency*. An OS allows the computer system resources to be used in an efficient manner

#### The operating system as a user-computer interface
**Hardware and software as a hierarchical organization** The hardware and software used in providing applications to a user can be viewed in a layered or hierarchical fashion

$\to$ The user of those applications, the end user, generally is not concerned with the computer’s architecture

<div style="text-align:center">
    <img src="https://i.imgur.com/Ddvph9v.png">
    <figcaption>Computer hardware and software structure</figcaption>
</div>

* *Explain*. The end user views a computer system in terms of an application

**Application**. Expressed in a programming language and developed by an application programmer
* *Application development*. Developing an application program as a set of processor instructions completely responsible for controlling the computer hardware is a complex task
    
    $\to$ To ease this task, a set of systems programs is provided
* *Utilities*. 
    * *Definition*. Some of these programs implementing frequently used functions that assist in 
        * Program creation
        * Management of files, and
        * Control of I/O devices
    * *Usage*. 
        * A programmer makes use of these facilities in developing an application
        * The application, while it is running, invokes the utilities to perform certain functions

**Operating system**. The most important system program
* *Idea*. Mask the details of the hardware from the programmer and provide the
programmer with a convenient interface for using the system
    
    $\to$ The OS acts as mediator, making it easier for the programmer and for application programs to access and use the facilities and services

**Provided services**.
* *Program creation*. The OS provides a variety of facilities and services, e.g. editors and debuggers, to assist the programmer in creating programs
    * *Utilitiy programs*. Typically, these services are in the form of utility programs
        
        $\to$ These programs are not actually part of the OS but are accessible through the OS
* *Program execution*. 
    * *Required steps for program execution*. A number of steps need to be performed to execute a program, e.g.
        * Instructions and data must be loaded into main memory
        * I/O devices and files must be initialized
        * Resources must be prepared
    * *OS' role*. Handle all of this for the user
* *Access to I/O devices*. Each I/O device requires its own specific set of instructions or control signals for operation
    
    $\to$ The OS takes care of the details so that the programmer can think in terms of simple reads and writes
* *Controlled access to files*. 
    * *File control*. File control must include an understanding of
        * The nature of the I/O device, e.g. disk drive, tape drive, etc.
        * The file format on the storage medium
    * *OS' role*. 
        * Handle the details
        * In the case of a system with multiple simultaneous users
            
            $\to$ the OS can provide protection mechanisms to control access to the files
* *System access*. In the case of a shared or public system, the OS controls access to the system as a whole and to specific system resources
    * *Requirements on the access function*.
        * Must provide protection of resources and data from unauthorized users
        * Must resolve conflicts for resource contention
* *Error detection and response*. A variety of errors can occur while a computer system is running
    * *Types of error*. 
        * Internal and external hardware errors, e.g. a memory error, or a device failure or malfunction
        * Software errors, e.g. arithmetic overflow, attempt to access forbidden memory location, and inability of the OS to grant the request of an application
    * *OS' role*. Make the response that clears the error condition with the least impact on running applications
        * *Example response*. The repsonse may range from
            * Ending the program that caused the error
            * Retrying the operation
            * Reporting the error to the application
* *Accounting*. A good OS collects usage statistics for various resources and monitor performance parameters, e.g. response time
    * *Purposes*. This information is useful in 
        * Anticipating the need for future enhancements
        * Tuning the system to improve performance
        * Billing purposes on a multiuser system

**Key interfaces in a typical computer system**.
* *Instruction set architecture (ISA)*. Define the repertoire of machine language instructions, which a computer can follow
    
    $\to$ This interface is the boundary between hardware and software
    * *Application program's access to ISA* Application programs and utilities may access the ISA directly

        $\to$ For these programs, a subset of the instruction repertoire is available (user ISA)
    * *Additional machine language instructions accessible from the OS*. The OS has access to additional machine language instructions dealing with managing system resources (system ISA)
* *Application binary interface (ABI)*. Define a standard for binary portability across programs
    * *Explain*. The ABI defines the system call interface to 
        * The OS, and
        * The hardware resources and services available in a system through the user ISA
* *Application programming interface (API)*. Give a program access to the hardware resources and services available in a system through the user ISA supplemented with high-level language (HLL) library calls
    * *System calls*. Any system calls are usually performed through libraries
        
        $\to$ Using an API enables application software to be ported easily, through recompilation, to other systems that support the same API

#### The operating system as resource manager
**Computer as a set of resources**. A computer is a set of resources for the movement, storage, and processing of data and for the control of these functions

$\to$ The OS is responsible for managing these resources
* *Control pf data movement, storage, and processing by the OS*. The OS controls the movement, storage, and processing of data
    * *Explain*. By managing the computer’s resources, the OS is in control of the computer’s basic functions
    * *Control mechanism in common sense*.
        * *Idea*.
            * A control mechanism as something external to that, which is controlled, or
            * A control mechanism is something, which is a distinct and separate part of that, which is controlled
        * *Example*. A residential heating system is controlled by a thermostat
            
            $\to$ The thermostat is completely distinct from the heat-generation and heat-distribution apparatus
    * *Control mechanism in OS*. In OS, a control mechanism is unusual in two respects
        * The OS functions in the same way as ordinary computer software
            
            $\to$ It is a program executed by the processor
        * The OS frequently relinquishes control and must depend on the processor to allow it to regain control

**OS as a computer program**. Like other computer programs, the OS provides instructions for the processor
* *Difference from program*. The key is in the intent of the program
    * The OS directs the processor in 
        * The use of the other system resources, and
        * The timing of its execution of other programs
    * For the processor to do any of these things, it must cease executing the OS program and execute other programs, i.e.
        1. The OS relinquishes control for the processor to do some useful work
        2. The OS resumes control long enough to prepare the processor to do the next piece of work

**OS kernel**. A portion of the OS is in main memory, including the kernel and, at a given time, other portions of the OS currently in use

$\to$ The remainder of main memory contains user programs and data

<div style="text-align:center">
    <img src="https://i.imgur.com/d6N1heo.png">
    <figcaption>The OS as resource manager</figcaption>
</div>

* *OS kernel (or nucleus)*. Contain the most frequently used functions in the OS
* *Main memory allocation*. The allocation of main memory is controlled jointly by the OS and memory-management hardware in the processor, i.e.
* *Processor allocation*. The OS decides when an I/O device can be used by a program in execution, and controls access to and use of files
    
    $\to$ The processor itself is a resource, and the OS must determine how much processor time is to be devoted to the execution of a particular user program
    
    >**NOTE**. In the case of a multiple-processor system, this decision must span all of the processors

### Types of operating systems
**Types of operating systems**. Certain key characteristics serve to differentiate various types of operating systems
* *Characteristics dimensions*. Characteristics fall along two independent dimensions
    * Whether the system is batch or interactive
        * *Interactive system*. 
            * The user/programmer interacts directly with the computer, usually through a keyboard/display terminal, to request the execution of a job or to perform a transaction
            * The user may, depending on the nature of the application, communicate with the computer during the execution of the job
        * *Batch system*. The opposite of interactive, i.e.
            * The user’s program is batched together with programs from other users and submitted by a computer operator
                
                $\to$ After the program is completed, results are printed out for the user
            * *Pure batch systems*. Rare today
                
                >**NOTE**. It will be useful to the description of contemporary operating systems to examine batch systems briefly

    * Whether the system employs multiprogramming or not
        * *Multiprogramming system*. The attempt is made to keep the processor as busy as possible, by having it work on more than one program at a time
            * *Idea*. Several programs are loaded into memory, and the processor switches rapidly among them
        * *Uniprogramming system*. Work only one program at a time

#### Early systems
**Early systems**. With the earliest computers, from the late 1940s to the mid-1950s, the programmer interacted directly with the computer hardware

$\to$ There was no OS
* *Interacting with processors*. These processors were run from a console, consisting of display lights, toggle switches, some form of input device, and a printer
* *Programs in early systems*. Programs in processor code were loaded via the input device, e.g. a card reader
    * *Erroneous execution*. If an error halted the program, the error condition was indicated by the lights
        
        $\to$ The programmer could proceed to examine registers and main memory to determine the cause of the error
    * *Successful execution*. If the program proceeded to a normal completion
        
        $\to$ The output appeared on the printer
* *Drawbacks*.
    * *Scheduling*. Most installations used a sign-up sheet to reserve processor time
        * *Idea*. A user could sign up for a block of time in multiples of a half hour or so
        * *Consequences*. 
            * A user might sign up for an hour and finish in 45 minutes
                
                $\to$ This results in wasted computer idle time
            * The user might run into problems, not finish in the allotted time
                
                $\to$ The program is forced to stop before resolving the problem
    * *Setup time*. 
        * *Program setup procedure*. A single program, called a job, could involve 
            1. Loading the compiler plus the high-level language program, i.e. source program, into memory
            2. Saving the compiled program, i.e. object program
            3. Loading and linking together the object program and common functions
        * *Consequences*. Each of these steps could involve mounting or dismounting tapes, or setting up card decks
            
            $\to$ A considerable amount of time was spent just in setting up the program to run
            * *Explain*. If an error occurred, the hapless user typically had to go back to the beginning of the setup sequence

**Serial processing**. This operation mode of early systems, reflecting the fact that users have access to the computer in series
* *Improvement*. Over time, various system software tools were developed to attempt to make serial processing more efficient
    * *Examples*. Libraries of common functions, linkers, loaders, debuggers, and I/O driver routines that were available as common software for all users

#### Simple batch systems
**Simple batch systems**. To improve resource utilization of early systems, simple batch operating systems were developed
* *Idea*. With a monitor, the user no longer has direct access to the processor, i.e.
    1. The user submits the job on cards or tape to a computer operator
    2. The computer operator batches the jobs together sequentially
    3. The computer operator places the entire batch on an input device, for use by the monitor

To understand how this scheme works, let us look at it from two points of
view: that of the monitor and that of the processor. From the point of view of the
monitor, the monitor controls the sequence of events. For this to be so, much of the
monitor must always be in main memory and available for execution (Figure 8.3).
That portion is referred to as the resident monitor. The rest of the monitor consists
of utilities and common functions that are loaded as subroutines to the user program at the beginning of any job that requires them. The monitor reads in jobs one
at a time from the input device (typically a card reader or magnetic tape drive). As it
is read in, the current job is placed in the user program area, and control is passed to
this job. When the job is completed, it returns control to the monitor, which immediately reads in the next job. The results of each job are printed out for delivery to
the user.
Now consider this sequence from the point of view of the processor. At a certain point in time, the processor is executing instructions from the portion of main
memory containing the monitor. These instructions cause the next job to be read
in to another portion of main memory. Once a job has been read in, the processor
will encounter in the monitor a branch instruction that instructs the processor to
continue execution at the start of the user program. The processor will then execute
the instruction in the user’s program until it encounters an ending or error condition. Either event causes the processor to fetch its next instruction from the monitor
program. Thus the phrase “control is passed to a job” simply means that the processor is now fetching and executing instructions in a user program, and “control is
returned to the monitor” means that the processor is now fetching and executing
instructions from the monitor program.
It should be clear that the monitor handles the scheduling problem. A batch of
jobs is queued up, and jobs are executed as rapidly as possible, with no intervening
idle time.
How about the job setup time? The monitor handles this as well. With each
job, instructions are included in a job control language (JCL). This is a special type
of programming language used to provide instructions to the monitor. A simple
example is that of a user submitting a program written in FORTRAN plus some
data to be used by the program. Each FORTRAN instruction and each item of
data is on a separate punched card or a separate record on tape. In addition to
FORTRAN and data lines, the job includes job control instructions, which are
denoted by the beginning “$”. The overall format of the job looks like this:
To execute this job, the monitor reads the $FTN line and loads the appropriate compiler from its mass storage (usually tape). The compiler translates the user’s
program into object code, which is stored in memory or mass storage. If it is stored
in memory, the operation is referred to as “compile, load, and go.” If it is stored
on tape, then the $LOAD instruction is required. This instruction is read by the
monitor, which regains control after the compile operation. The monitor invokes
the loader, which loads the object program into memory in place of the compiler
and transfers control to it. In this manner, a large segment of main memory can
be shared among different subsystems, although only one such subsystem could be
resident and executing at a time.
We see that the monitor, or batch OS, is simply a computer program. It relies
on the ability of the processor to fetch instructions from various portions of main
memory in order to seize and relinquish control alternately. Certain other hardware
features are also desirable:
• Memory protection: While the user program is executing, it must not alter the
memory area containing the monitor. If such an attempt is made, the processor hardware should detect an error and transfer control to the monitor. The
monitor would then abort the job, print out an error message, and load the
next job.
• Timer: A timer is used to prevent a single job from monopolizing the system.
The timer is set at the beginning of each job. If the timer expires, an interrupt
occurs, and control returns to the monitor.
• Privileged instructions: Certain instructions are designated privileged and can
be executed only by the monitor. If the processor encounters such an instruction while executing a user program, an error interrupt occurs. Among the
privileged instructions are I/O instructions, so that the monitor retains control of all I/O devices. This prevents, for example, a user program from accidentally reading job control instructions from the next job. If a user program
wishes to perform I/O, it must request that the monitor perform the operation
for it. If a privileged instruction is encountered by the processor while it is
executing a user program, the processor hardware considers this an error and
transfers control to the monitor.
• Interrupts: Early computer models did not have this capability. This feature
gives the OS more flexibility in relinquishing control to and regaining control
from user programs.
Processor time alternates between execution of user programs and execution
of the monitor. There have been two sacrifices: Some main memory is now given
over to the monitor and some processor time is consumed by the monitor. Both
of these are forms of overhead. Even with this overhead, the simple batch system
improves utilization of the computer.

#### Multiprogrammed batch systems
Even with the automatic job sequencing
provided by a simple batch OS, the processor is often idle. The problem is that
I/O devices are slow compared to the processor. Figure 8.4 details a representative
calculation. The calculation concerns a program that processes a file of records and
performs, on average, 100 processor instructions per record. In this example the
computer spends over 96% of its time waiting for I/O devices to finish transferring
data! Figure 8.5a illustrates this situation. The processor spends a certain amount of time executing, until it reaches an I/O instruction. It must then wait until that I/O
instruction concludes before proceeding.
This inefficiency is not necessary. We know that there must be enough memory to hold the OS (resident monitor) and one user program. Suppose that there
is room for the OS and two user programs. Now, when one job needs to wait for
I/O, the processor can switch to the other job, which likely is not waiting for I/O
(Figure 8.5b). Furthermore, we might expand memory to hold three, four, or more
programs and switch among all of them (Figure 8.5c). This technique is known as multiprogramming, or multitasking.1 It is the central theme of modern operating systems.
As with a simple batch system, a multiprogramming batch system must rely
on certain computer hardware features. The most notable additional feature that
is useful for multiprogramming is the hardware that supports I/O interrupts and
DMA. With interrupt-driven I/O or DMA, the processor can issue an I/O command
for one job and proceed with the execution of another job while the I/O is carried
out by the device controller. When the I/O operation is complete, the processor is
interrupted and control is passed to an interrupt-handling program in the OS. The
OS will then pass control to another job.
Multiprogramming operating systems are fairly sophisticated compared to
single-program, or uniprogramming, systems. To have several jobs ready to run, the
jobs must be kept in main memory, requiring some form of memory management.
In addition, if several jobs are ready to run, the processor must decide which one
to run, which requires some algorithm for scheduling. These concepts are discussed
later in this chapter.

#### Time-sharing systems
With the use of multiprogramming, batch processing
can be quite efficient. However, for many jobs, it is desirable to provide a mode in
which the user interacts directly with the computer. Indeed, for some jobs, such as
transaction processing, an interactive mode is essential.
Today, the requirement for an interactive computing facility can be, and often
is, met by the use of a dedicated microcomputer. That option was not available in the
1960s, when most computers were big and costly. Instead, time sharing was developed.
Just as multiprogramming allows the processor to handle multiple batch jobs
at a time, multiprogramming can be used to handle multiple interactive jobs. In
this latter case, the technique is referred to as time sharing, because the processor’s time is shared among multiple users. In a time-sharing system, multiple users
simultaneously access the system through terminals, with the OS interleaving the
execution of each user program in a short burst or quantum of computation. Thus,
if there are n users actively requesting service at one time, each user will only see
on the average 1/n of the effective computer speed, not counting OS overhead.
However, given the relatively slow human reaction time, the response time on a
properly designed system should be comparable to that on a dedicated computer.
Both batch multiprogramming and time sharing use multiprogramming. The
key differences are listed in Table 8.3.

## Scheduling
**Scheduling**. The key to multiprogramming
* *Types of scheduling*
    * *Long-term scheduling*. The decision to add to the pool of processes to be executed
    * *Medium-term scheduling*. The decision to add to the number of processes, which are partially or fully in main memory
    * *Short-term scheduling*. The decision as to which available process will be executed by the processor
    * *I/O scheduling*. The decision as to which process' pending I/O request shall be handled by an available I/O device

**Process**. This term was first used by the designers of the Multics OS in the 1960s

$\to$ This is a somewhat more general term than job
* *Proposed definitions of process*.
    * *Definition 1*. A program in execution
    * *Definition 2*. The “animated spirit” of a program
    * *Definition 3*. That entity to which a processor is assigned

### Long-term scheduling
**Long-term scheduler**. Determine which programs are admitted to the system for processing

$\to$ Long-term scheduler controls the degree of multiprogramming, i.e. number of processes in memory
* *Idea*. Once admitted, a job or user program becomes a process and is added to the queue for the short-term scheduler
* *Variations*. In some systems, a newly created process begins in a swapped-out condition, i.e. it is added to a queue for the medium-term scheduler
    * *Swap-out*. A method of removing a process from RAM, and adding it to the hard disk
    * *Swap-in*. A method of removing a program from a hard disk, and putting it back into RAM

**Long-term scheduler in a batch system**. In a batch system, or for the batch portion of a general-purpose OS, newly submitted jobs are routed to disk and held in a batch queue

$\to$ The long-term scheduler creates processes from the queue when it can
* *Questions of interest*. There are two decisions involved, i.e.
    * The scheduler must decide that the OS can take on one or more additional processes
    * The scheduler must decide which job or jobs to accept and turn into processes
        
        $\to$ The criteria used may include priority, expected execution time, and I/O requirements

**Long-term scheduler for interactive programs in a time-sharing system**. A process request is generated when a user attempts to connect to the system
* *Idea*. Time-sharing users are not simply queued up and kept waiting until the system can accept them, i.e.
    1. The OS will accept all authorized comers until the system is saturated, using some predefined measure of saturation
    2. After saturation, a connection request is met with a message indicating that the system is full and the user should try again later

### Medium-term scheduling
Medium-term scheduling is part of the swapping function, described in Section 8.3.
Typically, the swapping-in decision is based on the need to manage the degree of
multiprogramming. On a system that does not use virtual memory, memory management is also an issue. Thus, the swapping-in decision will consider the memory
requirements of the swapped-out processes.

### Short-term scheduling
The long-term scheduler executes relatively infrequently and makes the coarsegrained decision of whether or not to take on a new process, and which one to take.
The short-term scheduler, also known as the dispatcher, executes frequently and
makes the fine-grained decision of which job to execute next.

#### Process states
 To understand the operation of the short-term scheduler, we
need to consider the concept of a process state. During the lifetime of a process,
its status will change a number of times. Its status at any point in time is referred to
as a state. The term state is used because it connotes that certain information exists
that defines the status at that point. At minimum, there are five defined states for a
process (Figure 8.7)
• New: A program is admitted by the high-level scheduler but is not yet ready
to execute. The OS will initialize the process, moving it to the ready state.
• Ready: The process is ready to execute and is awaiting access to the processor.
• Running: The process is being executed by the processor.
• Waiting: The process is suspended from execution waiting for some system
resource, such as I/O.
• Halted: The process has terminated and will be destroyed by the OS.
For each process in the system, the OS must maintain information indicating the state of the process and other information necessary for process execution.
For this purpose, each process is represented in the OS by a process control block
(Figure 8.8), which typically contains
• Identifier: Each current process has a unique identifier.
• State: The current state of the process (new, ready, and so on).
• Priority: Relative priority level.
• Program counter: The address of the next instruction in the program to be
executed.
• Memory pointers: The starting and ending locations of the process in memory.
• Context data: These are data that are present in registers in the processor
while the process is executing, and they will be discussed in Part Three. For
now, it is enough to say that these data represent the “context” of the process.
The context data plus the program counter are saved when the process leaves
the running state. They are retrieved by the processor when it resumes execution of the process.
• I/O status information: Includes outstanding I/O requests, I/O devices (e.g., tape
drives) assigned to this process, a list of files assigned to the process, and so on.
• Accounting information: May include the amount of processor time and clock
time used, time limits, account numbers, and so on.
When the scheduler accepts a new job or user request for execution, it creates
a blank process control block and places the associated process in the new state.
After the system has properly filled in the process control block, the process is
transferred to the ready state.

#### Scheduling techniques
To understand how the OS manages the scheduling of the
various jobs in memory, let us begin by considering the simple example in Figure 8.9.
The figure shows how main memory is partitioned at a given point in time. The
kernel of the OS is, of course, always resident. In addition, there are a number of
active processes, including A and B, each of which is allocated a portion of memory
We begin at a point in time when process A is running. The processor is executing instructions from the program contained in A’s memory partition. At some
later point in time, the processor ceases to execute instructions in A and begins
executing instructions in the OS area. This will happen for one of three reasons:
1. Process A issues a service call (e.g., an I/O request) to the OS. Execution of A
is suspended until this call is satisfied by the OS.
2. Process A causes an interrupt. An interrupt is a hardware-generated signal to
the processor. When this signal is detected, the processor ceases to execute A
and transfers to the interrupt handler in the OS. A variety of events related
to A will cause an interrupt. One example is an error, such as attempting to
execute a privileged instruction. Another example is a timeout; to prevent any
one process from monopolizing the processor, each process is only granted the
processor for a short period at a time.
3. Some event unrelated to process A that requires attention causes an interrupt.
An example is the completion of an I/O operation.
In any case, the result is the following. The processor saves the current context
data and the program counter for A in A’s process control block and then begins
executing in the OS. The OS may perform some work, such as initiating an I/O
operation. Then the short-term-scheduler portion of the OS decides which process
should be executed next. In this example, B is chosen. The OS instructs the processor to restore B’s context data and proceed with the execution of B where it left off.
This simple example highlights the basic functioning of the short-term scheduler. Figure 8.10 shows the major elements of the OS involved in the multiprogramming and scheduling of processes. The OS receives control of the processor at the
interrupt handler if an interrupt occurs and at the service-call handler if a service
call occurs. Once the interrupt or service call is handled, the short-term scheduler is
invoked to select a process for execution.
To do its job, the OS maintains a number of queues. Each queue is simply a
waiting list of processes waiting for some resource. The long-term queue is a list of
jobs waiting to use the system. As conditions permit, the high-level scheduler will
allocate memory and create a process for one of the waiting items. The short-term
queue consists of all processes in the ready state. Any one of these processes could
use the processor next. It is up to the short-term scheduler to pick one. Generally,
this is done with a round-robin algorithm, giving each process some time in turn.
Priority levels may also be used. Finally, there is an I/O queue for each I/O device.
More than one process may request the use of the same I/O device. All processes
waiting to use each device are lined up in that device’s queue.
Figure 8.11 suggests how processes progress through the computer under the
control of the OS. Each process request (batch job, user-defined interactive job) is
placed in the long-term queue. As resources become available, a process request
becomes a process and is then placed in the ready state and put in the short-term
queue. The processor alternates between executing OS instructions and executing
user processes. While the OS is in control, it decides which process in the short-term
queue should be executed next. When the OS has finished its immediate tasks, it
turns the processor over to the chosen process.
As was mentioned earlier, a process being executed may be suspended for
a variety of reasons. If it is suspended because the process requests I/O, then it
is placed in the appropriate I/O queue. If it is suspended because of a timeout or
because the OS must attend to pressing business, then it is placed in the ready state
and put into the short-term queue.
Finally, we mention that the OS also manages the I/O queues. When an I/O
operation is completed, the OS removes the satisfied process from that I/O queue
and places it in the short-term queue. It then selects another waiting process (if any)
and signals for the I/O device to satisfy that process’s request.

## Memory management
In a uniprogramming system, main memory is divided into two parts: one part for
the OS (resident monitor) and one part for the program currently being executed.
In a multiprogramming system, the “user” part of memory is subdivided to accommodate multiple processes. The task of subdivision is carried out dynamically by the
OS and is known as memory management.
Effective memory management is vital in a multiprogramming system. If only
a few processes are in memory, then for much of the time all of the processes will be
waiting for I/O and the processor will be idle. Thus, memory needs to be allocated
efficiently to pack as many processes into memory as possible.

### Swapping

### Partitioning

### Paging

### Virtual memory

#### Demand paging

#### Page table architecture

### Translation lookaside buffer

### Segmentation

## Pentium memory mangement

## ARM memory management
**Brief**. ARM provides a versatile virtual memory system architecture that can be tailored to the needs of the embedded system designer

### Memory system organization
**Overview of the memory management hardware in the ARM for virtual memory**.

<div style="text-align:center">
    <img src="https://i.imgur.com/GbMA2n9.png">
    <figcaption>ARM memory system overview</figcaption>
</div>

* *Virtual memory translation hardware*. Use one or two levels of tables for translation from virtual to physical addresses
    * *Translation lookaside buffer (TLB)*. A cache of recent page table entries, i.e. recent translations of virtual memory to physical memory
        * *Idea*. If an entry is available in the TLB
            
            $\to$ The TLB directly sends a physical address to main memory for a read or write operation
            * *Motivation*. Data is exchanged between the processor and main memory via the cache
    * *TLB used with cache address types*.
        * *TLB with logical cache organization*. If a logical cache organization is used
            
            $\to$ The ARM supplies that address directly to the cache, as well as supplying it to the TLB when a cache miss occurs
        * *TLB with physical cache organization*. If a physical cache organization is used
            
            $\to$ The TLB must supply the physical address to the cache
* *Access control bits*. Entries in the translation tables include access control bits
    
    $\to$ This determines whether a given process may access a given portion of memory
    * *Explain*. If access is denied, access control hardware supplies an abort signal to the ARM processor

### Virtual memory address translation
**Brief**. The ARM supports memory access based on either sections or pages, i.e.
* *Supersections (optional)*. Consist of 16-MB blocks of main memory
* *Sections*. Consist of 1-MB blocks of main memory
* *Large pages*. Consist of 64-kB blocks of main memory
* *Small pages*. Consist of 4-kB blocks of main memory

>**NOTE**. Sections and supersections are supported to allow mapping of a large region of memory while using only a single entry in the TLB

**Access control mechanisms**. Extended to 1kB subpages within small pages, and to 16kB subpages within large pages

**Levels of translation table in main memory**.
* *First-level table*. Holds section and supersection translations, and pointers to second-level tables
* *Second-level tables*. Hold both large and small page translations

**Memory-management unit (MMU)**. 
* *Functionality*.
    * Translate virtual addresses generated by the processor into physical addresses to access main memory
    * Derive and checks the access permission
* *TLB miss*. Translations occur as the result of a TLB miss, and start with a first-level fetch
    * A section-mapped access only requires a first-level fetch
    * A page-mapped access also requires a second-level fetch
* *Example*.

    <div style="text-align:center">
        <img src="https://i.imgur.com/73qE6Nv.png">
        <figcaption>ARM virtual memory address translation for small pages</figcaption>
    </div>


    >**NOTE**. A similar two-page lookup procedure is used for large pages
    >
    >* *Explain*. For sections and supersection, only the L1 page table lookup is required

### Memory-management formats
**L1 page table**. Each entry is a descriptor of how its associated 1-MB virtual address range, i.e. a section, is mapped

<div style="text-align:center">
    <img src="https://i.imgur.com/JVeHiHw.png">
    <figcaption>ARMv6 memory-mangement format</figcaption>
</div>

* *Entry format*. Each entry has one of four alternative formats
    * *`Bits [1:0] = 00`*. The associated virtual addresses are unmapped, and attempts to access them generate a translation fault
    * *`Bits [1:0] = 01`*. The entry gives the physical address of an L2 page table, which specifies how the associated virtual address range is mapped
    * *`Bits [1:0] = 01` and `bit 19 = 0`*. The entry is a section descriptor for its associated virtual addresses
    * *`Bits [1:0] = 01` and `bit 19 = 1`*. The entry is a supersection descriptor for its associated virtual addresses
    
    >**NOTE**. Entries with `bits[1:0] = 11` are reserved

**Memory-management formats for memory structured into pages**. A two-level page table access is required
* *Entry format for L1 page table*. `Bits [31:10]` of the L1 page entry contain a pointer to a L2 page table
* *Entry format for L2 page table*. 
    * For small pages, the L2 entry contains a 20-bit pointer to the base address of a 4-kB page in main memory
    * For large pages, the structure is more complex
        * As with virtual addresses for small pages, a virtual address for a large page structure includes 
            * A 12-bit index into the L1 table, and
            * An 8-bit index into the L2 table
        * The page index portion of the virtual address must be 16 bits, i.e. since $64=4\times 2^4$ hence 4 more bits are required
            * *Idea*. To accommodate all of these bits in a 32-bit format
                
                $\to$ There is a 4-bit overlap between the page index field and the L2 table index field
            * *Implementation*. ARM accommodates this overlap by requiring that each page table entry in a L2 page table, which supports large pages, be replicated 16 timesthrough the user ISA
                * *Consequence*. The size of the L2 page table is reduced from 256 entries to 16 entries, if all of the entries refer to large pages

                    $\to$ The L2 table index is reduced from 8 bits to 4 bits, leaving 4 bits for increasing the page index portion of the virtual address from 12 bits to 16 bits, as required
        * A given L2 page can service a mixture of large and small pages
            
            $\to$ We need the replication for large page entries

**Memory-management formats for memory structured into sections**.
* For sections, `bits [31:20]` of the L1 entry contain a 12-bit pointer to the base of the 1-MB section in main memory
* For supersections, `bits [31:24]` of the L1 entry contain an 8-bit pointer to the base of the 16-MB section in main memory
    * *Entry replication*. The L1 table index portion of the virtual address overlaps by 4 bits with the supersection index portion of the virtual address
        
        $\to$ 16 identical L1 page table entries are required
    * *Expansion of the range of physical address space*. The physical address space range can be expanded by up to eight additional address bits, i.e. `bits [23:20]` and `[8:5]`
        * *Explain*. There is no domain for supersections, and the supersection base address field is 4 bit shorter than the section base address field
        * *Choice of number of additional bits*. The number of additional bits is implementation dependent
        * *Usage*. These additional bits can be interpreted as extending the size of physical memory by as much as a factor of $2^8 = 256$
            
            $\to$ Thus, physical memory may in fact be as much as 256 times as large as the memory space available to each individual process

### Access control
**AP access control bits in each table entry**. Control access to a region of memory by a given process
* *Types of access*. 
    * A region of memory can be designated as no access, read only, or read-write
    * The region can be designated as privileged access only, reserved for use by the OS and not by applications

**Domain**. ARM employs the concept of a domain, i.e. a collection of sections and/or pages with particular access permissions

$\to$ This allows multiple processes to use the same translation tables while maintaining some protection from each other
* *Number of supported domains*. The ARM architecture supports 16 domains
* *Domain field in table entry and TLB entry*. Each page table entry and TLB entry contains a field specifying which domain the entry is in
* *Access control for domain*. A 2-bit field in the Domain Access Control Register controls access to each domain
    
    $\to$ Each field allows the access to an entire domain to be enabled and disabled very quickly
    * *Consequence*. Whole memory areas can be swapped in and out of virtual memory very efficiently

**Types of supported domains**.
* *Clients*. Users of domains, i.e. execute programs and access data
    
    $\to$ These userse must observe the access permissions of the individual sections and/or pages making up the domain
* *Managers*. 
    * Control the behavior of the domain, i.e. the current sections and pages in the domain, and the domain access
    * Bypass the access permissions for table entries in that domain
* *Common practice*. One program can be a client of some domains, and a manager of some other domains, and have no access to the remaining domains
    
    $\to$ This allows very flexible memory protection for programs that access different memory resources

# Appendix
## Concepts
**ABI and API**.
* *API*. Define the objects and methods that a module makes available to its clients, at the source-code level
    * *Questions of interest*.
        * How to instantiate its objects?
        * What arguments need to pass to its methods, and what do they return?
    * *Conclusion*. When we want to know what library functions are available and how to use them
        
        $\to$ We are asking about an API
* *ABI*. A lower-level concept defining how the bits and bytes that are passed between a module and its clients
    * *Questions of interest*.
        * What format are they in?
        * Are they pushed onto the stack, passed in registers, or stored elsewhere?
        * Does the stack need to be cleaned up when a function returns, and if so, who's responsible for tending to it?
* *Example*. Consider a function with the following API

    ```cpp
    long long multiply(unsigned int multiplicand, long multiplier);
    ```

    then the corresponding ABI is given as 
    1. Push the return address on the stack as an absolute 64-bit address, in MSB to LSB order
        
        $\to$ The program will continue execution at that address when the function completes
    2. Push a 32-bit value onto the stack in MSB to LSB order
        
        $\to$ It represents the unsigned multiplicand
    3. Store a 64-bit value in the accumulator register, in MSB to LSB order
        
        $\to$ It represents the signed multiplier in two's-complement form.
    4. Jump to address 0xADDADD relative to the beginning of the program to execute the function
    5. Upon completion, take the first 4 bytes on the stack and append the first 4 bytes of the value in the accumulator register to create the signed 64-bit product, in LSB to MSB order, in one's-complement format
    6. The caller must remove the 4 bytes from the stack, and the 4-byte multiplicand and the 8-byte return address, to restore the stack