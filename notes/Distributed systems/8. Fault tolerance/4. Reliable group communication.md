<!-- TOC titleSize:1 tabSpaces:2 depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 skip:0 title:1 charForUnorderedList:* -->
# Table of Contents
- [Table of Contents](#table-of-contents)
- [Reliable group communication](#reliable-group-communication)
  - [Scalability in reliable multicasting](#scalability-in-reliable-multicasting)
  - [Atomic multicast](#atomic-multicast)
    - [Virtual synchrony](#virtual-synchrony)
    - [Message ordering](#message-ordering)
- [Appendix](#appendix)
  - [Discussion](#discussion)
<!-- /TOC -->

# Reliable group communication
**Brief**. 
* *Importance of reliable group communication*. Considering how important process resilience by replication is

    $\to$ It is not surprising that reliable multicast services are important as well
    * *Explain*. Such services guarantee that messages are delivered to all members in a process group
* *Issue*. Reliable multicasting is tricky

**Reliable group communication**.
* *Reliable group communication*. A message sent to a process group should be delivered to each member of that group
* *Receiving versus delivering a message*. If we separate the logic of handling messages from the core functionality of a group member
    
    $\to$ We can make the distinction between receiving messages and delivering messages

    <div style="text-align:center">
        <img src="https://i.imgur.com/dpJFbyH.png">
        <figcaption>Receiving and delivering a message</figcaption>
    </div>

    * *Idea*. A message is received by a message-handling component, which delivers a message to the component containing the core functionality of a group member
        
        $\to$ A message received by process $P$ will also be delivered by $P$
* *Message-handling component*. Responsible for
    * Ensure that messages from the same sender are delivered in the same order as they were sent
    * Provide reliable message-passing, i.e. if not by the underlying OS

**Reliable communication in case of faulty processes**. Group communication is reliable when a message is ensured to be received and delivered by all nonfaulty group members
* *Problem*. Agreement should be reached on what the group looks like before a message can be delivered
    * *Explain*. If a sender intended to have a message delivered by each member of a group $G$, but at the time of delivery we actually have another group $G'\neq G$
        
        $\to$ We should wonder if the message can be delivered or not
    
    >**NOTE**. The situation becomes simpler if we can ignore consensus on group  membership

**Solutions to reliable communication in case of faulty processes**. Consider a sending process with a list of intended recipients
* *Reliable communication with reliable transport-level protocol*. The sender can deploy reliable transport-level protocols, e.g. TCP
    * *Procedure*.
        1. The sender sends its message to each recipient, one by one
        2. If a receiving process fails, the message may be resent later when the process recovers, or ignored altogether, e.g. because the sender had left the group
        3. In case a group member is expected to send a response, even if it is just an acknowledgement
            
            $\to$ Communication can be speeded up by  separating the sending of a request from receiving a response, i.e. overlapping messsage transfers
    * *Drawback*. Most transport layers offer reliable point-to-point channels
        
        $\to$ They rarely offer reliable communication to a group of processes
        * *Explain*. The best they offer is to let a process set up a point-to-point connection to each other process it wants to communicate with
        * *Consequence*. When process groups are relatively small, this approach is straightforward and practical
* *Reliable communication with unreliable transport-level protocol*. Consider a communication system with unreliable multicasting
    
    $\to$ A multicast message may be lost part way and delivered by some, but not all, of the intended receivers
    * *Idea*. The sending process assigns a sequence number to each message it multicasts and stores the message locally in a history buffer, i.e.
        * Assuming that the receivers are known to the sender
            
            $\to$ The sender simply keeps the message in its history buffer until each receiver has returned an acknowledgment
        * A receiver can suspect it is missing a message $m$ with sequence number $s$ when it has received messages with sequence numbers higher than $s$
            
            $\to$ It returns a negative acknowledgement to the sender, requesting for a retransmission of $m$

**Trade-offs**. There are various design trade-offs to be made, e.g. 
* To reduce the number of messages returned to the sender
    
    $\to$ Acknowledgments could possibly be piggybacked with other messages
* Retransmitting a message can be done using point-to-point communication to each requesting process, or using a single multicast message sent to all processes

## Scalability in reliable multicasting
**Brief**. The reliable multicast scheme described above has several problems, i.e.

**Scaling problem**.
* *Problems*.
    * The scheme cannot support large numbers of receivers, i.e. if there are $N$ receivers

        $\to$ The sender must be prepared to accept at least $N$ acknowledgments
    * The receivers may be spread across a wide-area network
* *Feedback implosion*. With many receivers, the sender may be swamped with feedback messages
* *Examples*.
    * When replicating processes for fault tolerance, this situation is not likely to occur as process groups are relatively small
    * When replicating for performance, we have a different case
* *Solution*. * Rather than acknowledging the receipt of a message
    
    $\to$ A receiver returns a feedback message only to inform the sender it is missing a message
    * *Benefits*. The system generally scales better
    * *Drawbacks*. 
        * No hard guarantees can be given that feedback implosions will never happen
        * The sender will, in theory, be forced to keep a message in its history buffer forever
            * *Explain*. The sender can never know if a message has been correctly delivered to all receivers
                
                $\to$ It should always be prepared for a receiver requesting the retransmission of an old message
    * *Improvement*. The sender will remove a message from its history buffer after some time has elapsed to prevent the buffer from overflowing
        
        >**NOTE**. Removing a message is done at the risk of a request for a retransmission not being honored

**Nonhierarchical feedback control**. A representative solution to scalable reliable multicasting
* *Motivation*. The key issue to scalable solutions for  reliable multicasting is to reduce the number of feedback messages returned to the sender
* *Feedback suppression*. A popular model that has been applied to several wide-area
applications
    
    $\to$ This underlies the Scalable Reliable Multicasting (SRM) protocol developed by Floyd et al. in 1997
* *Key idea of SRM*. Receivers never acknowledge the successful delivery of a  multicast message
    
    $\to$ They report only when they are missing a message, i.e. only negative acknowledgments are returned as feedback
    
    >**NOTE**. How message loss is detected is left to the application
    
* *Key idea of feedback suppression*. Whenever a receiver notices that it missed a message, it multicasts its feedback to the rest of the group
    
    $\to$ This allows another group member to suppress its own feedback
    * *Explain*.
        * If several receivers missed message $m$
            
            $\to$ Each of them returns a negative acknowledgment to the sender $S$ for the retransmissions of $m$
        * If we assume that retransmissions are multicast to the entire group
            
            $\to$ Only one request for retransmission reaching $S$ is required
* *Implementation*. 
    1. A receiver $R$, which did not receive message $m$ schedules a feedback message with some random delay
        * *Explain*. The request for retransmission is not sent until some random time has elapsed
    2. If, in the meantime, another request for retransmission for $m$ reaches $R$
        
        $\to$ $R$ will suppress its own feedback, knowing that $m$ will be retransmitted shortly
    3. Only a single feedback message will reach $S$, which in turn subsequently retransmits $m$
* *Usage*. Feedback suppression has shown to scale reasonably well
    
    $\to$ It has been used as the underlying mechanism for some collaborative Internet applications, e.g. a shared whiteboard
* *Drawbacks*.
    * Ensuring that only one request for retransmission is returned to the sender requires a reasonably accurate scheduling of feedback messages at each receiver
        
        $\to$ Otherwise, many receivers will still return their feedback at the same time
        * *Problem*. Setting timers accordingly in a group of processes dispersed across a wide-area network is tricky
    * Multicasting feedback also interrupts processes, to which the message has been successfully delivered
        * *Explain*. Other receivers are forced to receive and process messages, which are useless to them
        * *Solution*. Receivers, which have not received message $m$, join a separate multicast group for $m$
            * *Drawback*. Groups must be managed in a highly efficient manner, which is hard to accomplish in a wide-area system
        * *Improved solution*. Receivers, which tend to miss the same messages, team up and share the same multicast channel for feedback messages and retransmissions
* *Improvement*. To enhance the scalability of SRM, receivers should assist in local recovery
    * *Explain*. If a receiver, to which message $m$ has been successfully delivered, receives a request for retransmission
        
        $\to$ It can decide to multicast $m$, even before the retransmission request reaches the original sender

**Hierarchical feedback control**. Feedback suppression is a nonhierarchical solution. 

$\to$ However, achieving scalability for very large groups of receivers requires hierarchical approaches
* *Idea*. The group of receivers is partitioned into a number of subgroups, which are subsequently organized into a tree
* *Subgroup intra-communication*. Within each subgroup, any reliable multicasting scheme working for small groups can be used
* *Subgroup coordinator*. Each subgroup appoints a local coordinator representing that group in the multicast tree
    
    $\to$ A link in the tree between two nodes corresponds to a reliable connection between the coordinators of the respective subgroups
* *Subgroup inter-communication*. When a process $S$ in group $G$ wants to send a message
    1. It uses the reliable multicast scheme for $G4 to reach all its members, including the group's coordinator $C$
    2. $C$ forwards the message to its neighboring coordinators
    3. A coordinator will forward an incoming message $m$ to all its neighboring coordinators, except the one from which it received $m$
    4. A coordinator will reliably multicast the incoming message to all members of the subgroup it represents
        
        >**NOTE**. The group coordinator also handle retransmissions for the group

* *Hierarchical feedback control in ACK-based scheme*. If coordinator $C$ of group $G$ sends a message $m$ to coordinator $C'$ of another neighboring group $G'$
    
    $\to$ It will keep $m$ in its history buffer at least until $C'$ has sent an acknowledgement
* *Hierarchical feedback control in NACK-based scheme*. Only if $G'$ detects it has missed m
    
    $\to$ It will send a NACK message to $C$
* *Benefits*. A single ACK or NACK message from a coordinator aggregates many feedback control messages from other processes
    
    $\to$ This leads to a much more scalable reliable multicasting scheme
* *Improvement*. Scalability is further improved by 
    * Let a coordinator handle the retransmissions to neighboring coordinators, to which it had forwarded a message
    * Combine with nonhierarchical feedback control to combine relatively large reliable-multicast subgroups into potentially large trees
        
        $\to$ We can support reliable multicasting for very large groups of processes
* *Drawback*. 
    * The construction and management of the tree are sophisticated,, i.e.
        * How are subgroups formed
        * Which processes are appointed to be coordinator
        * How are the subgroups organized in a tree
    * In many cases, a tree needs to be constructed dynamically
        
        $\to$ Traditional network-level solutions provide almost no adequate services for tree management
* *Consequence*. Application-level multicasting solutions have gained popularity

**Gossip-based scalable reliable multicasting**. Consider the push-pull anti-entropy scheme 
* *Idea*. A node $P$ picks another node $Q$ at random, and exchanges updates with $Q$
    * *Explain*. $P$ pushes updates that $Q$ has not seen before to $Q$, and pulls in any updates that $Q$ has, but which were missed by $P$
    * *Consequence*. After the exchange, both processes have the same data
* *Robustness*. This scheme is inherently robust
    * *Explain*. If the communication between $P$ and $Q$ fails, $P$ will pick some other node to exchange updates
* *Drawback*. The speed, by which an update propagates through the system, slows down

    $\to$ This slowdown is considered important for some applications

## Atomic multicast
**Atomic multicast**. A message is delivered to either all group members or to none at all

$\to$ This is often required in a distributed system
* *Causes of problem*. A client communicates with a server, i.e. a group member, which is allowed to cash
* *Consequence*. If a number of group members would execute the update, while others would not

    $\to$ Distribution transparency is at stake, and the client would not know what to make of the situation

### Virtual synchrony
**Brief**. Reliable multicast in case of process failures can be accurately defined in terms of process groups and changes to group membership
* *Assumptions*.
    * Message receiving and delivering are distinct
    * The distributed system consists of message-handling components
    * A received message is locally buffered in this component until it can be delivered to the application, which is logically placed as a group member at a higher layer
* *Idea of atomic multicasting*. A multicast message $m$ is uniquely associated with a list of processes, which should deliver it
    * *Group view*. The delivery list corresponds to a group view, i.e. the view on the set of processes contained in the group, which the sender had at the time the message $m$ was multicast

        $\to$ Each process on the list has the same view, i.e. they should agree that $m$ should be delivered by each of them, and by no other process

**Multicasting while changing group view**.
* *Scenario*.
    * Message $m$ is multicast at the time it sender $P$ ha a group view $G$
    * While the multicast is happening, another process $Q$ joins or leaves the group

        $\to$ This change in group membership is announced to all processes in $G$
* *View change*. Take place by multicasting a message $\text{vc}$ announcing the joining or leaving of $Q$
* *Problem*. There are two multicast messages simultaneously in transit, i.e. $m$ and $\text{vc}$, hence we need to ensure that 
    * $m$ is delivered by all processes in $G$ before anyone executes the view change as specified by $\text{vc}$, or 
    * $m$ is not delivered at all

    >**NOTE**. This requirement is comparable to total-ordered multicasting

**Virtually synchronous reliable multicast**.
* *Reliable multicast protocol in case of view changes*. If $m$ is not delivered by any process, what is the definition of reliable multicast protocol?
* *Failure of delivery of $m$*. Allowed to occur, in principle, only when the group membership change is the result of the sender $P$ of $m$ crashing
    * *Explain*. In this case, either
        * All remaining nonfaulty members of $G$ should deliver $m$ before agreeing $P$ is no longer member of the group, or
        * None should deliver $m$, i.e. $P$ is considered crashed before having a chance to send $m$
* *Consequence*. This stronger form of reliable multicast guarantees that a message multicast to group view $G$ is delivered by each nonfaulty process in $G$

    $\to$ If the sender of the message crashes during the multicast
    * The message is delivered to all remaining processes, or
    * The message is ignored by each of the processes

**Principle of virtual synchrony**. Come from the fact that all multicasts take place between view changes

$\to$ A view change is a barrier, across which no multicast can pass
* *Analogy*. Use a synchronization variable in distributed data stores

    $\to$ All multicasts, which are in transit while a view change takes place, are completed before the view change comes into effect

### Message ordering
**Brief**. Virtual synchrony allows an application developer to think about multicasts as taking place in epochs, which are separated by group membership changes
* *Ordering types of multicasts*.
    * Unordered multicasts
    * FIFO-ordered multicasts
    * Causally ordered multicasts
    * Totally ordered multicast

**Reliable unordered multicast**. A virtually synchronous multicast, in which no guarantees are given concerning the order, in which received messages are delivered by different processes

**Reliable FIFO-ordered multicast**. The message-handling component layer is forced to deliver incoming messages from the same process in the same order as they have been sent
* *Example*. When the communication layer at a process $P$ receives $m_2$ first, which is sent by another process $P_1$

    $\to$ It will wait with delivery to $P$ until it has received and delivered $m_1$

>**NOTE**. There is no constraint regarding the delivery of messages sent by different processes

**Reliable causally ordered multicast**. Deliver messages so that potential causality between different messages is preserved

$\to$ This is implemented using vector timestamps

**Total-ordered delivery**. Regardless of whether message delivery is unordered, FIFO ordered, or causally ordered

$\to$ It is required that when messages are delivered, they are delivered in the same order to all group members
* *Atomic multicasting*. Virtually synchronous reliable multicasting offering total-ordered delivery of messages

**Versions of virtually synchronous reliable multicasting**.

| Multicast | Basic message ordering | TO delivery |
| --- | --- | --- |
| Reliable multicast | None | No |
| FIFO multicast | FIFO-ordered delivery | No |
| Causal multicast | Causal-ordered delivery | No |
| Atomic multicast | None | Yes |
| FIFO atomic multicast | FIFO-ordered delivery | Yes |
| Causal atomic multicast | Causal-ordered delivery | Yes |


# Appendix
## Discussion
**Implementing virtual synchrony**. Consider an implementation of virtually synchronous reliable multicast in Isis, a fault-tolerant distributed system in practical use in industry for several years
* *Reliable point-to-point communication*. Reliable multicasting in Isis uses TCP
    * *Multicasting a message $m$ to a group of processes*. Implemented by reliably sending $m$ to each group member
    * *Consequence*. Although each transmission is guaranteed to succeed
        
        $\to$ There are no guarantees that all group members receive $m$
        * *Explain*. The sender may fail before having transmitted $m$ to each member
* *FIFO multicast*. Isis assumes that messages from the same source are received by a communication layer in the order they were sent by that source
    
    $\to$ This requirement is solved by using TCP connections for point-to-point communication
* *Virtually synchronous reliable multicast*. All messages sent to view $G$ must be delivered to all nonfaulty processes in $G$ before the next group membership change
    * *Issue*. Ensure that each process in $G$ has received all messages sent to $G$
        * *Sender failure issue*. Since the sender of $m$ to $G$ may have failed before completing its multicast
        
            $\to$ Some processes in $G$ may never receive $m$
            * *Consequence*. Since the sender has crashed, these processes should get $m$ from somewhere else
    * *Solution*. Every process in $G$ keep $m$ until it knows for sure that all members in $G$ have received it
        * *Stable message*. If $m$ has been received by all members in $G$, $m$ is considered stable
            
            $\to$ Only stable messages are allowed to be delivered
        * *Ensure stability of $m$*. Select an arbitrary live process in $G$ and request it to send $m$ to all other processes in $G$
    * *Implementation*.
        * *Assumptions*.
            * $G_i$ is the current view, and it is necessary to install the next view $G_{i+1}$
            * $G_i$ and $G_{i+1}$ differ by at most one process
            * A process $P$ notices the view change when it receives a view-change message
        * *View-change message*. 
            * Come from the process wanting to join or leave the group, or 
            * Come from a process, which had detected the failure of a process in $G_i$ that is now to be removed
        * *Procedure*. 
            1. When $P$ receives the view-change message for $G_{i+1}$
                
                $\to$ It forwards a copy of any unstable message from $G_i$ it still has to every process in $G_{i+i}$
            2. $P$ then marks each unstable message sent as being stable
                
                >**NOTE**. Since Isis assumes point-to-point communication is reliable, forwarded messages are never lost

            3.  To indicate that $P$ no longer has any unstable messages and that it is prepared to install $G_{i+1}$ as soon as the other processes can do that as well
                
                $\to$ It multicasts a flush message for $G_{i+1}$
            4. After $P$ has received a flush message for $G_{i+1}$ from each other process

                $\to$ It can safely install the new view
        * *Consequence*. The forwarding guarantees that all messages in $G_i$, which have been received by at least one process, are received by all nonfaulty processes in $G_i$
            * *Variation*. We can elect a coordinator to forward unstable messages
        * *Drawback*. The protocol cannot deal with process failures while a new view change is announced
            * *Explain*. It assumes that until the new view $G_{i+1}$ has been installed by each member in $G_{i+1}$

                $\to$ No process in $G_{i+1}$ will fail, leading to a next view $G_{i+2}$
            * *Solution*. Announce view changes for any view $G_{i+k}$, even while previous changes have not been installed by all processes yet