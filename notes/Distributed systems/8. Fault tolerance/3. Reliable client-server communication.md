<!-- TOC titleSize:1 tabSpaces:2 depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 skip:0 title:1 charForUnorderedList:* -->
# Table of Contents
- [Table of Contents](#table-of-contents)
- [Reliable client-server communication](#reliable-client-server-communication)
  - [Point-to-point communication](#point-to-point-communication)
  - [RPC semantics in the presence of failures](#rpc-semantics-in-the-presence-of-failures)
    - [Client is unable to locate the server](#client-is-unable-to-locate-the-server)
    - [Lost request messages](#lost-request-messages)
    - [Server crashes](#server-crashes)
    - [Lost reply messages](#lost-reply-messages)
    - [Client crashes](#client-crashes)
<!-- /TOC -->

# Reliable client-server communication
**Brief**. We need to consider communication failures
* *Communication failure models*. Most of the failure models given so far apply equally well to communication channels

    $\to$ A communication channel may exhibit crash, omission, timing, and arbitrary failures
    * *Causes of arbitrary failures*. Duplicate messages, resulting from the fact that in a computer network, messages may be buffered for too long

        $\to$ Those messages are reinjected into the network after the original sender has issued a retransmission
* *Communication failure masking*. Focus on masking crash and omission failures

## Point-to-point communication
**Reliable point-to-point communication via TCP**. In many distributed systems, reliable point-to-point communication is established using a reliable transport protocol, e.g. TCP
* *Omission failure masking* TCP masks omission failures, which occur as message lost, using acknowledgements and retransmissions

    $\to$ Omission failures are completely hidden from a TCP client
* *Crash failures of connections masing*. These failures cannot be masked
    * *Crash failures*. Occur when a TCP connection is abruptly broken, hence no more messages can be transmitted via the channel

        $\to$ In most cases, the client is informed that the channel has crashed by raising an exception
    * *Masking crash failures*. The only way is to let the distributed system attempt to automatically set up a new connection, by resending a connection request
        * *Underlying assumption*. The other side is still, or responsive to such requests

## RPC semantics in the presence of failures
**Brief**. This section looks closer at client-server communication when using high-level communication facilities, e.g. RPCs
* *RPC's goal*. Hide communication by making RPCs look like local ones

    $\to$ As long as both client and server are functioning perfectly, RPC does its job well
* *Problem*. When errors occur, the differences between local and remote calls are not always easy to mask

**Classes of RPC failures**.
* The client is unable to locate the server
* The request message from the client to the server is lost
* The server crashes after receiving a request
* The reply message from the server to the client is lost
* The client crashes after sending a request

### Client is unable to locate the server
**Problem of interest**. The client cannot locate a suitable server, due to
* All servers may be down, or
* The client is compiled using a version of the client stub, and the binary is not used for a considerable period of time

    $\to$ Meanwhile, the server evolves and a new version of the interface is installed, i.e. new stubs are generated and put into use
    * *Consequence*. When the client is run, the binder will be unable to match it up with a server, and will report failure

**Exception solution**. One possible solution is to have the error raise an exception

$\to$ Programmers can write special procedures, which are invoked upon such an error
* *Drawback*.
    * Not every language has exceptions or signals
    * Having to write an exception or signal handler destroys the transparency we are trying to achieve
        * *Explain*. Writing an exception handler for "Cannot locate server" would be unusual request in a nondistributed system 
            
            $\to$ It is hard to maintain the illusion that remote procedures are no different from local ones

### Lost request messages
**Brief**. This is the easiest one to deal with

**Solution**. Have the OS or client stub start a timer when sending the request

$\to$ If the timer expires before a reply or acknowledgement comes back, the message is sent again
* *Case 1*. If the message was truly lost, the server will not be able to tell the difference between the retramission and the original
    
    $\to$ Everything will work fine
    * *Drawback*. If too many request messages are lost that the client gives up and falsely concludes that the server is down

        $\to$ The situation goes back to "Cannot locate server"
* *Case 2*. If the request was not lost, the server should be able to detect retransmitted messages

    $\to$ This is not so simple

### Server crashes
**Sequence of events at a server**.
* *Normal sequence*. A request arrives, is carried out, and a reply is sent
* *Pathological sequence due to server crash after execution*. A request arrives and is carried out, but the server crashes before sending the reply

    $\to$ The system has to report failure back to the client, e.g. raise an exception
* *Pathological sequence due to server crash before execution*. A request arrives, but the server crashes before the request can be carried out

    $\to$ The system can retransmit the request

**Problem**. For the last two sequences of events, the OS cannot tell which is which, i.e. all it knows is that its timer has expired
* *Schools of thought for solutions*.
    * *Option1 - At-least-once semantics*. Wait until the server reboots, or let the client's middleware transparently rebind to a new server

        $\to$ The operation is tried again
        * *Idea*. Keep trying until a reply has been received, then give it to the client
    * *Option 2 - At-most-once semantics*. Give up immediately and report back failure

        $\to$ The RPC is carried out at most once, but possibly not at all
    * *Option 3*. Guarantee nothing, i.e. when a server crashes, the client gets no help and no promises about what happened

        $\to$ The RPC may have been carried out anywhere from zero to a large number of times
        * *Advantage*. Easy to implement 

**Ideal scenario - Exactly-one semantics**. There is no way to arrange this
* *Scenario*. Consider a remote operation of processing a document, where
    * The server sends a completion message to the client when the document has been completely processed
    * When a client issues a request, it receives an acknowledgment that the request has been delivered to the server
* *Server's strategy*.
    * *Option 1*. Send a completion message just before actually telling the document processor to do its work
    * *Option 2*. Send a completion message after the document has been processed
* *Issue*. If the server crashes and then recovers, then announces to all clients that it has just crashed but is now up and running again
    
    $\to$ The client does not know whether its request will actually have been carried out
* *Client's strategy*.
    * *Option 1*. The client never reissues a request, i.e. the document may not be processed
    * *Option 2*. The client always reissues  request, leading to the document being processed twice
    * *Option 3*. The client reissues a request only if it did not yet receive an acknowledgment, that its request had been delivered to the server

        $\to$ The client is counting on the fact that the server crashed before the request could be delivered
    * *Option 4*. The client reissues a request only if it has received an acknowledgment for the request
* *Consequence*. There are totally $2\times 4$ combinations to consider for the client and the server
    * *Problem*. No combination is satisfactory, i.e. for any combination either the request is lost forever, or carried out twice

**Why fully transparent server recovery is impossible**.
* *Possible events happen at the server in case of crash*.
    * Send the completion message (M)
    * Complete the processing of the document (P)
    * Crash (C)

    >**NOTE**. Crash during the processing of a document is considered the same as crashing before its completion

* *Different orderings of events*. The parentheses indicate an event, which can no longer happen due to server crashes
    * $M\to P\to C$
    * $M\to C\to P$
    * $P\to M\to C$
    * $P\to C(\to M)$
    * $C(\to P\to M)$
    * $C(\to M\to P)$
* *Strategies to tackle system crashes*.

    <div style="text-align:center">
        <img src="https://i.imgur.com/lBpYGb4.png">
        <figcaption>Different combinations of client and server strategies in case of server crashes</figcaption>
    </div>

* *Consequence*. The possibility of server crashes radically changes the nature of RPC and clearly distinguishes single-processor from distributed ones

### Lost reply messages
**Brief**. Lost replies can be difficult to deal with
* *Naive solution*. Rely on a timer, which has been set by the client's OS

    $\to$ If no reply is coming within a reasonable period, the clietn retransmit the request
    * *Drawback*. The client is not really sure why there was no answer, i.e.
        * *Case 1*. The request or reply get lost
        * *Case 2*. The server is merely slow
* *Idempotent request*. A request, which can safely be repeated as often as needed with no damage being done
    * *Example*. Asking for the first 1024 bytes of a file

**Handling reply message lost for non-idempotent requests**. 
* *Option 1*. Try to structure all the requests in an idempotent way
    * *Drawback*. Many requests, e.g. transferring money, are inherently nonidempotent
* *Option 2*. The client assigns each request a sequence number

    $\to$ The server keeps track of the most recently received sequence number from each client using it
    * *Drawback*. 
        * The server must maintain administration on each client
        * It is not clear how long to maintain the administration
    * *Consequence*. The server can tell the difference between an original request and a retransmission

        $\to$ The server can refuse to carry out any request a second time

        >**NOTE**. The server still have to send a response to the client
    
    * *Improvement*. Have a bit in the message header, which is used to distinguish initial requests from retransmissions

### Client crashes
**Orphan (or computation)**. If a client sends a request to a server to do some work, then crashes before the server replies

$\to$ An unwanted computation, i.e. orphan, is active and no parent is waiting for the result
* *Effects of an orphan computations*. Such computations can cause problems, which can interfere with normal operation of the system, e.g.
    * Processing power is wasted
    * Files can be locked, and valuable resources are tied up
    * If the client reboots and does the RPC again, but reply from the orphan comes back immediately afterward, confusion can result

**Solutions to orphan computations**.
* *Orphan extermination solution*. Before a client stub sends a RPC message, it makes a log entry telling what it is about to do

    $\to$ The log is kept on disk, or some other medium surviving crashes
    * *Idea*. After a reboot, the log is checked and the orphan is explicitly killed off
    * *Drawback*. 
        * The horrendous expense of writing a disk record for every RPC
        * It may not even work, since orphans may do RPCs, hence creating grandorphans or further descendants, which are difficult or impossible to locate
        * The network may be partitioned, e.g. due to a failed gateway, making it impossible to kill them, even if they can be located
* *Reincarnation solution*. Solve all problems of orphan extermination without writing disk records
    * *Idea*. Divide time up to sequentially numbered epochs
        1. When a client reboots, it broadcasts a message to all machines declaring the start of a new epoch
        2. When a broadcast comes in, all remote computations are killed
    * *Drawback*. If the network is partitioned, some orphans may survive

        $\to$ However, when they report bak, their replies will contain an obsolete epoch number, making them easy to detect
* *Gentle reincarnation solution*. A less draconian variant of reincarnation solution
    * *Idea*. When an epoch broadcast comes in
        1. Each machine checks to see if it has any remote computations running locally
        2. If so, the machine tries its best to locate their owners
        3. Only if the owners cannot be located anywhere, is the computation killed
* *Expiration solution*. 
    * *Idea*. Each RPC is given a standard amout of time $T$ to do the job
        * If it cannot finish, it must explicitly ask for another quantum, which is quite nuisance
        * If after a crash, the client waits a time $T$ before rebooting, all orphans are sure to be gone
    * *Issue*. Choosing a reasonable $T$ in the face of RPCs with wildly differing requirements

**Drawback of all solutions**. All of the methods are crude and undesirable, i.e.
* Killing an orphan may have unforeseen consequences, e.g.
    * If an orphan has obtained locks on one or more files or database records

        $\to$ Suddenly killing the orphan will keep the locks remain forever
    * An orphan may already made entries in various remote queues to start up other processes at some future some

        $\to$ Even killing the orphan may not remove all traces of it