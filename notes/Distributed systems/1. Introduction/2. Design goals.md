<!-- TOC titleSize:1 tabSpaces:2 depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 skip:0 title:1 charForUnorderedList:* -->
# Table of Contents
- [Table of Contents](#table-of-contents)
- [Design goals](#design-goals)
  - [Supporting resource sharing](#supporting-resource-sharing)
  - [Making distribution transparent](#making-distribution-transparent)
    - [Types of distribution transparency](#types-of-distribution-transparency)
    - [Degree of distribution transparency](#degree-of-distribution-transparency)
  - [Being open](#being-open)
    - [Interoperability, composability, and extensibility](#interoperability-composability-and-extensibility)
    - [Separating policy from mechanism](#separating-policy-from-mechanism)
  - [Being scalable](#being-scalable)
    - [Scalability dimensions](#scalability-dimensions)
      - [Size scalability](#size-scalability)
      - [Geographical scalability](#geographical-scalability)
      - [Administrative scalability](#administrative-scalability)
    - [Scaling techniques](#scaling-techniques)
      - [Hiding communication latencies](#hiding-communication-latencies)
      - [Partitioning and distribution](#partitioning-and-distribution)
      - [Replication](#replication)
      - [Discussion](#discussion)
  - [Pitfalls](#pitfalls)
- [Appendix](#appendix)
  - [Concepts](#concepts)
  - [Discussions](#discussions)
<!-- /TOC -->

# Design goals
## Supporting resource sharing
**Supporting resource sharing**. Make it easy for users and applications to access and share remote resources
* *Resources*. Can be virtually anything, e.g. peripherals, storage facilities, data, files, services, and networks, etc.
* *Benefits*.
    * More economical distributed system, e.g. it is cheaper to have a single high-end reliable storage facility be shared
    * Connecting users and resources also makes it easier to collaborate and exchange information
* *Successful examples*. File-sharing P2P networks

## Making distribution transparent
**Transparent resource distribution**. An important goal of a distributed system is to hide the fact that its processes and resources are physically distributed across multiple computers, possibly seperated by large distances

$\to$ We try to make the distribution of processes and resources transparent, i.e. invisible, to end users and applications

### Types of distribution transparency
**Access transparency**. Hide differences in data representation and how an object is accessed
* *Basic level*. Hide differences in machine architectures
* *More important level*. Agree on how data is to be represented by different machines, and OSes
* *Example*. A distributed system may have computer systems running different OSes, each having their own file-naming conventions

**Location transparency**. Hide where an object is located physically
* *Naming*. Play an important role in achieving location transparency
    * *Explain*. Location transparency can often be achieved by assigning only logical names to resources
* *Logitcal name*. Names, in which the location of a resource is not secretly encoded
    * *Example*. Use Uniform resource locator (URL)

**Relocation transparency**. Hide that an object may be moved to another location while in use

>**NOTE**. This is becoming increasingly important in the context of cloud computing

**Migration transparency**. Hide that an object may move to another location

$\to$ This is used when the distributed system supports the mobility of processes and resources initiated by users, without affecting ongoing communication and operations
* *Example*. Regardless whether two people are actually moving, mobile phones will allow them to continue their conversation

**Replication transparency**. Hide an object is replicated
* *Requirements*. To hide replication from users, it is necessary that all replicas have the same name

    $\to$ A system supporting replication transparency should generally support location transparency as well
    * *Explain*.It would otherwise be impossible to refer to replicas at different locations

**Concurrency transparency**. Hide that an object may be shared by several independent users
* *Motivation*. An important goal of distributed system is to allow sharing of resources

    $\to$ It is important that each user does not notice that the other is making use of the same resource
* *Resource consistency*. Concurrent accesses to a shared resource should leave that resource in a consistent state
    * *Idea*. By locking mechanism, or to use transactions

    >**NOTE**. It may be difficult to implement transactions in a distributed system, notably when scalability is an issue

**Failure transparency**. Hide the failure and recovery of an object, i.e.
* *Explain*.
    * A user or application does not notice that some piece of the system fails to work properly
    * The system subsequently, and automatically, recovers from failure
* *Masking failures*. One of the hardest issues in distributed systems, and is even impossible when certain apparently realistic assumptions are made
* *Main difficulty*. The inability to distinguish between a dead process and a painfully slowly responding once
    * *Example*. When contacting a busy Web server, a browser will eventually time out and report that the Web page is unavailable

        $\to$ The user cannot tell whether the server is actually down or that the network is badly congested

### Degree of distribution transparency
**Problem**. There are situations, in which attempting to blindly hide all distribution aspects from users is not a good idea
* *Explain*,
    * Some distributed aspects cannot be hidden, due to external reasons, or due to the proper functionality of the system 
    * Due to trade-off between a high degree of transparency and the performance of a system
* *Examples*.
    * *Example 1*. If we request our electronic newspaper to appear in our mailbox before 7 AM local time, when we are living at a different time zone
    * *Example 2*. When we ask for a message to be transmitted from San Francisco to Amsterdam within less than 35 milliseconds
    * *Example 3*. Many Internet applications repeatedly try to contact a server before finally giving up

        $\to$ Attempting to mask a transient server failure may slow down the system as a whole
    * *Example 4*. When we need to guarantee that several replicas located on different continents must be consistent all the time

**Distribution exposure**. As distributed systems are expanding to small devices, where the notion of location and context awareness is very important

$\to$ It may be best to actually expose distribution
* *Example*. Location-based services

**Pseudo distribution transparency**. Full distribution transparency is impossible

$\to$ Is it even wise to pretend that we can achieve it?
* *Idea*. It may be much better to make distribution explicit so that the user and developer are never tricked into believing that there is transparency
* *Consequence*. Users will much better understand the behavior, i.e. sometimes unexpected, of a distributed system

    $\to$ The user can be much better prepared to deal with this behavior

**Conclusion**. Aiming for distribution transparency may be a nice goal when designing and implementing distributed systems

$\to$ But it should be considered together with other issues, e.g. performance and comprehensibility

## Being open
**Openness**. Another important goal of distributed systems

**Open distributed system**. A system that
* Offer components which can easily be used by, or integrated into other systems
* Consist of components originating from elsewhere

### Interoperability, composability, and extensibility
**Interfaces and interface definition language (IDL)**. To be open means that components should adhere to standard rules, which describe the syntax and semantics of what those components have to offer
* *General approach*. Define services through interfaces, using an IDL
    * *Motivation*. Interface definitions written in an IDL nearly always capture only the syntax of services

        $\to$ They specify precisely the names of functions available, together with parameter types, return value types, possible exceptions which can be raised, etc.
    * *Hard part*. Specify precisely what those services do, i.e. the semantics of interfaces

        >**NOTE**. In practice, such specifications are given in an informal way, by means of natural language

* *Benefits of a properly specified interface definition*.
    * Allow an arbitrary process, which needs a certain interface, to talk to another process, which provides that interface
    * Allow two independent parties to build completely different implementations of the interfaces, leading to two separate components operating in exactly the same way

**Completeness and neutrality**. Proper specifications are complete and neutral
* *Completeness*. Everything necessary to make an implementation has been specified

    >**NOTE**. Many interface definitions are not all complete, thus it is necessary for a developer to add implementation-specific details

* *Neutrality*. Specifications do not prescribe what an implementation should look like, i.e. the should be neutral

**Interoperability and portability**. Completeness and neutrality are important for interoperability and portability
* *Interoperability*. Characterize the extent, by which two implementations of systems or components from different manufacturers can co-exist and work together by relying on each other's services as specified by a common standard
* *Portability*. Characterize to what extent an application developed for a distributed A can be executed, without modification, on a different distributed system B, which implements the same interfaces as A

**Other important goals for an open distributed system**.
* *Configurability*. It should be easy to configure the system out of different components, possibly from different developers
* *Extensibility*. It should be easy to add new components or replace existing ones without affecting those components which stay in place

### Separating policy from mechanism
**Replacibility and adaptibility**. To achieve flexibility in open distributed systems, it is crucial that the system be organized as a collection of relatively small and easily replaceable or adaptable components

$\to$ We should provide definitions of both the highest-level interfaces, i..e those seen by users and applications, and the interfaces to internal parts of the system and how those parts interact

>**NOTE**. This approach is relatively new

* *Old approaches*. Many older and even contemporary systems are constructed using a monolithic approach, in which components are only logically separated but implemented as one, huge program
    * *Drawback*. Hard to replace or adapt a component without affecting the entire system
    * *Consequence*. Monolithic systems are tend to be closed instead of open

**The need for changing a distributed system**. Often caused by a component, which does not provide optimal policy for a specific user or application
* *Policy*. Ways to choose which activities to perform
    * *Example*. A process may be granted resources using FIFS policy
* *Mechanism*. Implementations which enforce policies
    * *Example*. FIFS policy may be implemented by using a queue of requests

## Being scalable
**Scalability**. One of the most important design goals for developers for distributed systems

### Scalability dimensions
**Scalability dimensions**. 
* *Size scalability*. A system can be scalable w.r.t its size, i.e. we can easily add more users and resources to the system without any noticeable loss of performance
* *Geographical scalability*. The users and resoures may lie far apart, but the fact that communication delays may be significant is hardly noticed
* *Administrative scalability*. A system which can still be easily managed even if it spans many independent administrative organizations

#### Size scalability
**Limications of centralized servers**. If more users or resources need to be supported, we are often confronted with the limitations of centralized services
* *Traditional implementation of centralized servers*. Many services are centralized by being implemented within a single server running on a specific machine in a distributed system
* *Modern implementation of centralized servers*. Have a group of collaborating servers co-located on a cluster of tightly coupled machines physically placed at the same location
* *Problem with centralized servers*. The server, or group of servers, can simply become a bottleneck when it needs to process an increasing number of requests
    * *Problem roots*.
        * The computational capacity, limited by the CPUs
        * The storage capacity, including the I/O transfer rate
        * The network between the user and the centralized service

**Computational capacity problem**. If a service for computing optimal routes takes real-time traffic information into account

$\to$ This may be primarily a compute-bound service requiring several, i.e. tens of, seconds to complete a request
* *Consequence*. If there is only a single machine available

    $\to$ Even a modern high-end system will eventually run into problems if the number of requests increases beyond a certain point

**Storage capacity problem**. If a service is mainly I/O bound, e.g. a poorly designed centralized search engine
* *Problem with content-based search queries*. We essentially need to match a query against an entire dataset

    $\to$ Even with advanced indexing techniques, we may still face the problem of having to process a huge amount of data exceeding the main-memory capacity of the machine running the service
* *Consequence*. Much of the processing time will be determined by the relatively slow disk accesses and transfer of data between disk and main memory

    >**NOTE**. Simply adding more or higher-speed disks will prove not to be a sustainable solution, as the number of requests continues to increase

**Network capacity problem**. May be the cause of poor scalability
* *Example*. Consider a video-on-demand service needing to stream HQ video to multiple users, where a video stream can easily require a bandwidth of 8 to 10 Mpbs
    * *Consequence*. If a service sets up point-to-point connections with its customers

        $\to$ It may soon hit the limits of the network capacity of its own outgoing transmission lines

#### Geographical scalability
**Scaling distributed systems designed for LANs**. Many of the distributed systems for LANs are based on synchronous communication
* *Synchronous communication*. A party requesting service, i.e. a client, blocks until a reply is sent back from the server implementing the service

    $\to$ This approach generally works fine in LANs where communication between two machines if often at worst a few hundred microseconds
* *Synchronous communication in WANs*. In wide-area system, we need to take into account that interprocess communication may be hundreds of milliseconds

    $\to$ Building applications using synchronous communication in WANs requires a great deal of care, and not just a little patience, notably with a rich interaction pattern between client and server

**Other problems with WANs**. 
* Communication in WANs is inherently much less reilable than in LANs
* The bandwidth is limited, making the solutions developed for LANs cannot always be easily ported to a wide-area system

**Limited facilities for multipoint broadcast mechanisms**. When components lie far apart, the wide-area systems generally have only very limited facilities for multipoint communication

$\to$ This is contrast to LANs, where efficient broadcasting mechanisms are supported
* *Multipoint broadcasting communication*. Extremely useful for discovering components and services, which is essential from a management point of view
* *Solution for wide-area systems*. We need to develop separate services, e.g. naming and directory services, to which queries can be sent

    $\to$ These support services, in turn, need to be scalable as well, and in many cases, no obvious solutions exist

#### Administrative scalability
**Administrative scalability**. A difficult, and in many cases open, question is how to scale a distributed system across multiple, independent administrative domains
* *Major problem*. Conflicting policies w.r.t resource usage and payment, management, and securiyt
* *Illustration*. For many years, scientists have been looking for solutions to share their equipment (often expensive) in what is known as computational grid
    * *Computation grid*. In these grids, a gloabl distributed system is constructed as a federation of local distributed systems

        $\to$ This allows a program running on a computer at organization A to directly access resources at organization B

**Security problem**. Many components of a distributed system residing within a single domain can often be trusted by users operating within that same domain

$\to$ System administration may have tested and certified applications, and may have taken special measures to ensure that components cannot be tampered with
* *Another interpretation*. The users trust their system administrators
* *Problem*. This trust does not expand naturally across domain boundaries
* *Types of security measures for cross-domain distributed systems*.
    * *Measure 1*. The distributed system has to protect it against malicious attacks from the new domain
        
        $\to$ Facilities like expensive image setters or high-performance computers may not be made available to unauthorized users
    * *Measure 2*. The new domain has to protect itself against malicious attacks from the distributed system

### Scaling techniques
**Scaling up and scaling out**.
* *Scaling up (vertical scaling)*. Improve the capacity, e.g. memory CPUs, network modules, etc. of servers and network
* *Scaling out (horizontal scaling)*. Expand the distributed system by deploying more machines
    * *Types of techniques*. 
        * Hiding communication latencies
        * Distribution of work
        * Replication

#### Hiding communication latencies
**Hiding communication latencies**. Applicable in case of geographical scalability
* *Basic idea*. Try to avoid waiting for responses to remote-service requests as much as possible
    * *Example*. We can do other useful work, rather than just waiting for remote response

        $\to$ When a reply comes in, the application is interrupted and a special handler is called to complete the previously issued request
    * *Consequence*. Essentially, this means constructing a requesting application which uses only asynchronous communication
* *Alternative idea*. A new thread of control can be started to perform the request

    $\to$ Although this thread blocks waiting for the reply, other threads in the process can continue

**Asynchronous communication useless cases**. There are many applications which cannot make effective use of asynchronous communication
* *Example*. Interactive applications
    * *Solution*. Reduce the overall communication, e.g. moving part of the computation which is normally done at the server to the client process requesting the service

#### Partitioning and distribution
**Partitioning and distribution**. Take a component, splitting it into smaller parts, and subsequently spread those parts across the system
* *Example usecase*. The Internet DNS, which is organized as a tree architecture

#### Replication
**Replication**. Useful when the scalability problem often appear in the form of performance degradation
* *Idea*. Replicate components across a distributed system to increase availability and balance the load between components leading to better performance

**Caching**. A special form of replication, which makes a copy of a resource, generally in the proximity of the client accessing that resource

**Drawback**. Since we have multiple copies of a resource, modifying one copy makes that copy different from others

$\to$ Caching and replication leads to consistency problems
* *Tolerating inconsistencies with the usage of the resource*. 
    * *Example*. Many Web users find it acceptable that their browser returns a cached document, of which the validity has not been checked for a while
* *Problems with strong consistency requirements*. 
    * An update must be immediately propagated to all other copies
    * If two updates happen concurrently, it is often required that updates are processed in the same order everywhere

        $\to$ This introduces an additional global ordering problem
* *Consequence*. Replication often requires some global synchronization mechanism

    $\to$ Such mechanisms are extremely hard or even impossible to implement in a scalable way

#### Discussion
**Difficulties of scaling problems**.
* *Size scalability*. The least problematic from a technical point of view
    * *Explain*. In many cases, increasing the capacity of a machine will save the day, though perhaps there is a high monetary cost to pay
* *Geographical scalability*. A toucher problem since network latencies are naturally bound from below

    $\to$ We may be forced to copy data to locations close to where clients are, leading to problems of copy consistency
    * *Practical experience*. Practice shows that combining distribution, replication, and caching techniques with different forms of consistency generally leads to acceptable solutions
* *Administrative scalability*. The most difficult problem to solve, partially since we need to deal with nontechnical issues, e.g. politics or organizations and human collaboration

## Pitfalls
**Distributed system and traditional software differences**. Components of a distributed system are dispersed across a network

$\to$ Not taking this dispersion into account during design time is what makes so many systems needlessly complex and results in flaws which need to be patched later on

**Eight common wrong assumptions for distributed systems**.
* The network is reliable
* The network is secure
* The network is homogeneous
* The topology does not change
* Latency is zero
* Bandwidth is infinite
* Transport cost is zero
* There is one administrator

**Affected properties of distributed systems by wrong assumptions**. 
* Reliability, security, heterogeneity, and topology of the network
* Latency and bandwidth
* Transport costs
* Administrative domains

# Appendix
## Concepts
**Groupware**. Software for collaborative editing, teleconferencing, and so on

**Analyzing service capacity**. Size scalability for centralized services can be formally analyzed using queuing theory and making a few simplifying assumptions
* *Conceptual idea*. Model a centralized service as the simple queuing system

    $\to$ Requests are submitted to the service where they are queued until further notice
* *Queue size*. In many cases, we may assume that the queue has an infinite capacity, i.e. there is no restriction on the number of requests which can be accepted for further processing

    $\to$ The arrival rate of requests is not influented by what is currently in the queue or being processed
* *Assumptions*.
    * The queue size is unlimited
    * The arrival rate of requests is $\lambda$ requests per second
    * The processing capacity of the service is $\mu$ requests per second
* *Fraction of time that there are $k$ requests in the system*. 

    $$p_k=(1-\frac{\lambda}{\mu})(\frac{\lambda}{\mu})^k$$

    * *Explain*.
        * Within a second, the proportion of time that a request is being processed in the server is $\frac{\lambda}{\mu}$

* *The utilization $U$ of a service*. The fraction of time which it is busy, i.e.

    $$U=\sum_{k>0}p_k=1=1-p_0=\frac{\lambda}{\mu}$$

    in other words

    $$p_k=(1-U)U^k$$

* *The average number $\bar{N}$ of requests in the system*.

    $$\begin{aligned}
    \bar{N}&=\sum_{k\geq 0} k p_k\\
    &=\sum_{k\geq 0} k (1 - U) U^k\\
    &=(1 - U) \sum_{k\geq 0} k U^k\\
    &=\frac{U}{1 - U}
    \end{aligned}$$

## Discussions
**Against distribution transparency**. Several researchers argued that hiding distribution will only lead to complicating the development of distributed systems
* *Explain*. Full distribution transparency can never be achieved
* *Against RPC*. Access transparency is achieved via RPC

    $\to$ This can lead to poorly understood semantics
    * *Explain*. A RPC may result in unexpected outputs when executed over a faulty communication link
    * *Consequence*. If reliability of communication cannot be guaranteed

        $\to$ It is best to always perform only local executions, leading to copy-before-use principle
* *Copy-before-use principle*. Data can be accessed only after they have been transferred to the machine of the process wanting the data
* *Data modification*. Modifying a data item should not be done, it can only be updated to a new version instead

**Open distribution in practice**. 
* *Practical observations*. Practice shows that 
    * Many distributed systems are not as open as we would like
    * Still a lot of effort is required to put various bits and pieces together to make a distributed system
* *Naive soltuion*. Reveal all the gory details of a component and provide developers with the actual source code

    $\to$ This approach is becoming increasingly popular, leading to open source projects
* *Object source projects*. Projects where large groups of people contribute to improving and debugging systems

**Distributed system concern and networking concern**. Distributed system does not concern about security while networking does