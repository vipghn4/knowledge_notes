<!-- TOC titleSize:1 tabSpaces:2 depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 skip:0 title:1 charForUnorderedList:* -->
# Table of Contents
- [Table of Contents](#table-of-contents)
- [Code migration](#code-migration)
  - [Reasons for migrating code](#reasons-for-migrating-code)
  - [Migration in heterogeneous systems](#migration-in-heterogeneous-systems)
- [Appendix](#appendix)
  - [Concepts](#concepts)
  - [Discussion](#discussion)
<!-- /TOC -->

# Code migration
**Passing information in distributed systems**. There are situations, in which passing programs, sometimes even while they are being executed, simplifies the design of a distributed system

## Reasons for migrating code
**Process migration**. Code migration in distributed systems took place in the form of process migration, in which an entire process was moved from one node to another
* *Motivation*. Moving a running process to a different machine is a costly and intricate task, but the reason is performance
    * *Basic idea*. Overall system performance can be improved if processes are moved from heavily loaded to lightly loaded machines
    * *Load measurement*. CPU queue length, CPU utilization, and other performance indicators

    >**NOTE**. Process migration was no longer a viable option for improving distributed systems

* *Solution*. Instead of offloading machines, code is moved to make sure that a machine is sufficiently loaded
    
    >**NOTE**. Migrating complete VMs with their suite of applications to lightly loaded machines to minimize the total number of nodes being used is common in optimizing energy usage in data centers

    * *VM migration and process migration*. Although migrating VMs may require more resources, VM migration is far less intricate than migrating a process

**Load-distribution algorithms**. Concern the allocation and redistribution of tasks w.r.t a set of machines

$\to$ These algorithms play an important role in compute-intensive systems

>**NOTE**. In many modern distributed systems, optimizing computing capacity is less an issue than minimizing communication

* *Performance improvement through code migration*. Often based on qualitative reasoning, instead of mathematical models
    * *Explain*. Due to the heterogeneity of the underlying platforms and computer networks
* *Examples*. 
    * *Example 1 - Client-to-server code migration*. Consider a client-server system, in which the server manages a huge database

        $\to$ If a client application needs to perform many database operations involving large quantities of data, it may be better to ship part of the client application to the server, sending only the results across the network
        * *Explain*. Otherwise, the network may be swamped with the transfer of data from the server to the client
        * *Conclusion*. Code migration is based on the assumption that it generally makes sense to process data close to where the data reside
    * *Example 2 - Server-to-client code migration*. When searching for information in the Web, it is simple to implement a search query in the form of a small mobile program, i.e. a mobile agent, moving from site to site

        $\to$ By copying several versions of the agent, and sending each off to different sites, we can achieve a linear speed-up compared to using a single agent
        * *Drawbacks of mobile agent*.
            * Mobile agents do not really offer an obvious advantage over other technologies
            * It is virtually impossible to let this type of mobile code operate in a secure way
* *Flexibility improvement through code migration*.
    * *Traditional approach to building distributed applications*. Partition the application into different parts, and decide in advance where each part should be executed

        $\to$ This leads to different multitiered client-server applications
    * *Simple code migration*. If code can move between machines, it is possible to dynamically configure distributed systems
        * *Scenario*. Suppose a server implementing a standardized interface to a file system

            $\to$ To allow remote clients to access the file system, the server makes use of proprietary protocol
        * *Normal approach*. The client-side implementation of the file system interface, which is based on the protocol, would need to be linked with the application

            $\to$ This requires that the software be readily available to the client, at the time the client application is being developed
        * *Alternative approach*. The server provides the client's implementation no sonner than is strictly necessary

            <div style="text-align:center">
                <img src="https://i.imgur.com/brQ8QQA.png">
                <figcaption>THe principle of dynamically configuring a client to communicate with a server</figcaption>
            </div>

            * *Explain*. When the client binds to the server, the client dynamically downloads the implementation, goes through the required initialization steps, and subsequently invokes the server
            * *Requirements*. 
                * The protocol for downloading and initializing code is standardized
                * The downloaded code can be executed on the client's machine

                    $\to$ Scripts running in a VM embedded in, e.g. a Web browser, will do the trick
            * *Usage*. Key to the success of the dynamic Web
            * *Pros and cons*.
                * *Pros*.
                    * Clients need not have all the software preinstalled to talk to servers
                    * As long as interfaces are standardized, we can change the client-server protocol and its implementation as often as we like
                        * *Explain*. Changes will not affect existing client applications relying on the server
                * *Cons*. Security is a problem
                    * *Explain*. Blindly trusting that the downloaded code implements only the advertised interface while accessing our unprotected hard disk and does not send the juiciest parts to heaven-knows-who is not a good idea

## Migration in heterogeneous systems
**Problem**. The assumption that the migrated code can be easily executedx at the target machine does not hold for heterogeneous systems

$\to$ This problem are, in many respects, the same as those of portability, hence having similar solutions

**Process migration**.
* *Simple solution for Pascal*. Generate machine-independent intermediate code for an abstract VM, e.g. Java VM

    $\to$ The VM would need to be implemented on many platforms, allowing Pascal programs to run anywhere
    * *Problem*. This idea never really caught on as the general solution to portability problems for languages, e.g. C
* *Scripting language solution*. Code migration in heterogeneous systems is tackled by scripting languages and higly portable languages like Java
    * *Idea*. Adapt the same approach as done for porting Pascal code
    * *Conclusion*. All solutions above rely on a (process) VM, which either directly interprets source code, or interprets intermediate code generated by a compiler

**Computing environment migration**. Solutions have been proposed to migrate not only processes, but to migrate entire computing environments
* *Idea*. Compartmentallize the overall environment and provide processes in the same part their on view on their computing environment
    * *Realizations*. Such compartmentalization takes place in the form of VMMs running an OS and a suite of applications
* *VM migration*. With VM migration, it is possible to decouple a computing environment from the underlying system and actually migrate it to another machine
    * *Pros*. Processes can remain ignorant of the migration, i.e. they need not be interrupted in their execution, nor should they experience any problems with used resources
        * *Explain*. The resources are either migrating along with a process, or the way a process accesses a resources is left unaffected, at least for that process
* *Real-time migration of virtualized OSes*. Convenient in a cluster of servers, where a tight coupling is achieved through a single, shared LAN
    * *Major migration problems*. Migrating the entire memory image, and migrating bindings to local resources
    * *Options to handle migration*. The following options can be combined
        * *Option 1*. Push memory pages to a new machine, and resend the ones which are later modified during the migration process
        * *Option 2*. Stop the current VM, migrate memory, and start the new VM
            * *Drawback*. This leads to unacceptable downtime if the migrating VM is running a live service
        * *Option 3*. Let the new VM pull in new pages as required, i.e. processes on the new VM immediately and copy memory pages on demand
            * *Drawback*. May extensively prolong the migration period, and also lead to poor performance, since it takes a long time before the working set of the migrated processes has been moved to the new machine
    * *Pre-copy approach proposed by Clark et. al (2015)*. Combine the first option, with a brief stop-and-copy phase as in the second option

        $\to$ This can lead to very low service downtimes
* *Local resources when dealing with a cluster server*. Matters are simplified when dealing with only a cluster server
    * *Explain*.
        * Since there is a single network, the only thing required to be done is to announce the new netweork-to-MAC address binding

            $\to$ Clients can contact the migrated processes at the correct network interface
        * If it can be assumed that storage is provided as a separate tier, the migrating binding to files is similarly simple

# Appendix
## Concepts
**Virtual machine migration**. When a guest simulation of an entire comuter is actually merely a software VM running on a host under a hypervisor

$\to$ Migration, or teleportaion, is the process, by which a running VM is moved from one physical host to another, with little or no disruption in service
* *Objective*. Ideally, the process is completely transparent, resulting in no disrruption of service, i.e. downtime
    * *Practice cases*. There is always sime minor pause in availability, though it may be low enough that only hard real-time systems are affected
* *Idea*. Teleporting requires that a machine is currently running on one host, i.e. the source
    1. The machine on the target is then configured to wait for the source to contact the target
    2. The machine's running state will then be transferred from the source to the target with minimal downtime
* *Requirements*.
    * On the target host, we must configure a VM with exactly the same hardware settings as the source machine
        * *Example*. The target machine must have the same amount of memory and other hardware settings
        
            $\to$ Otherwise teleporting will fail with an error message
    * The two virtual machines on the source and the target must share the same storage, hard disks as well as floppy disks and CD/DVD images
        $\to$ They either use the same iSCSI targets or that the storage resides somewhere on the network and both hosts have access to it using NFS or SMB/CIFS

## Discussion
**Moving away from thin-client computing**.

**Models for code migration**.

**On performace of live VM migration**.