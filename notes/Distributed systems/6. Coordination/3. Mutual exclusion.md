<!-- TOC titleSize:1 tabSpaces:2 depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 skip:0 title:1 charForUnorderedList:* -->
# Table of Contents
- [Table of Contents](#table-of-contents)
- [Mutual exclusion](#mutual-exclusion)
  - [Overview](#overview)
  - [A centralized algorithm](#a-centralized-algorithm)
  - [A distributed algorithm](#a-distributed-algorithm)
  - [A token-ring algorithm](#a-token-ring-algorithm)
  - [A decentralized algorithm](#a-decentralized-algorithm)
<!-- /TOC -->

# Mutual exclusion
## Overview
**Types of mutex algorithms**.
* *Token-based solutions*. Mututal exclusion is achieved by passing a special message, i.e. a token, between the processes
    * *Idea*. This is the only token available
        * Who has the token is allowed to access the shared resource
        * When finished, or if the processing holding the token is not interested in accessing the resource
            
            $\to$ The token is passed onto the next process
    * *Pros*.
        * Depending on how the processes are organized, they can fairly easily ensure that every process will get a chance to access the resource

            $\to$ Starvation is avoided
        * Deadlocks can easily be avoided, contributing to their simplicity
    * *Cons*. If the token is lost, e.g. holding process failure, an intriate distributed procedure needs to be started

        $\to$ To ensure that a new token is created
* *Permission-based approach*. A process wanting to access the resource first requires the permission from other processes

## A centralized algorithm
**Idea**. Simulate how mutex is done in a single-processor system
* *Mutex in single-processor system*. One process is elected as the coordinator

    <div style="text-align:center">
        <img src="https://i.imgur.com/GgCI4WW.png">
        <figcaption>Mutex in single-processor system</figcaption>
    </div>

    1. Whenever a process wants to access a shared resource, it sends a request message to the coordinator
        
        $\to$ The message states which resource it wants to access, and asks for permisison
    2. If no other process is currently accessing the resource, the coordinator sends back a reply, granting permission

        $\to$ Otherwise, the coordinator denies the permission
    3. When the reply arrives, the requester can go ahead

**Permission deny and access grant options**.
* *Option 1*. Send a reply, saying "permission denied"
   * *Access grant*. If an explicit message has been sent denying permission

       $\to$ The process will have to poll for incoming traffic or block later
* *Option 2*. Queue the request from the requesting process, and wait for more messages
   * *Access grant*. 
       1. When the accessing process is finished with the resource, it sends a message to the coordinator, releasing its exclusive access
       2. The coordinator takes the first item off the queue of the deferred requests, and sends that process a grant message
       3. If the process was still blocked, i.e. the message is the first one to it

            $\to$ It unblocks and accesses the resource

**Characteristics**.
* *Mutex guarantee*. 
    * The coordinator lets only one process at a time access the resource
    * The cooridnator is fair, since requests are granted in the order, in which they are received

        $\to$ No process waits forever, i.e. no starvation
* *Pros and cons*.
    * *Pros*. Easy to implement, and require only three messages per use of resource, i.e. `request`, `grant`, `release`

        $\to$ This is an attractive solution for many practical situations
    * *Cons*. 
        * The coordinator is a single point of failure, i.e. if it crashes, the entire system can go down

            $\to$ If processes normally block after making a request, they cannot distinguish a dead coordinator from "permission denied"
        * A single coordinator can become a performance bottleneck

## A distributed algorithm
**Ricart and Agrawala's algorithm**. Using Lamport's logical clock, and inspired by Lamport's original solution for distributed mutex
* *Requirements*. A total ordering of all events in the system
    * *Explain*. For any pair of events, it must be unambiguous which one actually happened first
* *Procedure*. 
    1. When a process wants to access a shared resource, it builds a message containing the resource's name, its process number, and the current logical time
    2. The process sends the message to all other processes, conceptually including itself

        $\to$ The sending messages is assumed to be reliable, i.e. no message is lost
    3. When a process receives a request message from another process, it takes action based on its own state w.r.t. the resource named in the message
        * *Possible cases for message handling*.
            * *Case 1*. If the receiver is not accessing the resource, and does not want to access it

                $\to$ It sends back an `OK` message to the sender
            * *Case 2*. If the receiver has access to the resource, it does not reply, but queues the request
            * *Case 3*. If the receiver wants to access the resource as well, but not yet done so
                1. It compares the timestamp of the incoming message with the one contained in the message it sent
                2. If the incoming message has lower timestamp, the receiver sends back an `OK` message, otherwise it queues the incoming request and sends nothing
    4. The process waits until everyone else has given permission
    5. As soon as all the permissions are in, the process goes ahead
    6. When it is finished, it sends `OK` messages to all processes in its queue, and deletes them all from the queue
* *Starvation and deadlock*. Mutex is guaranteed without deadlock or starvation
* *Communication complexity*. Suppose that the total number of processes is $N$
    * *The number of messages a process needs to send and receive before it can enter its critical section*. $2 \cdot (N-1)$
        * *Explain*. $N-1$ request messages to all other processes, and $N-1$ `OK` messages, one from each other process

**Number of failure points**. $N$ points, i.e. if any process crashes, it will fail to respond to requests

$\to$ This silence can be interpreted incorrectly as denial of permission, hence blocking all subsequent attempts by all processes to enter any of their respective critical regions
* *Solution*. 
    1. When a request comes in, the receiver always sends a reply, either granting or denying permission
    2. When a request or reply is lost, sender times out and keeps trying until a reply comes back, or the sender times out
    3. After a request is denied, the sender blocks, waiting for a subsequent `OK` message

**Communication requirements**. Either a multicase communication primitive must be used, or each process must maintain the group membership list itself, including processes entering the group, leaving the group, and crashing

$\to$ This method works best with small groups of processes, which never change their group memberships

**Processing burden**. All processes are involved in all decisions concerning accessing the shared resource, which may impose a burden on processes running on resource-constrained machines

**Minor improvements**. Getting permission from everyone is overkill, and all we need is a method to prevent two processes from accessing the resource at the same time

$\to$ The algorithm can be modified to grant permission when it has collected permission from a simple majority of the other processes, rather than all of them

## A token-ring algorithm
**Token-ring algorithm**. Construct an overlay network, in the form of a logical ring, in which each process is assigned a position in the ring

$\to$ Each process knows who is next in the line after itself
* *Token*. When the ring is initialized, process $P_o$ is given a token, which circulates around the ring

    $\to$ If there are $N$ processes, the token is passed from process $P_k$ to $P_{(k+1)\mod} N$ in point-to-point messages
* *Shared resource access*. 
    * *Case 1*.
        1. When a process acquires the token, it checks whether it needs to access the shared resource

            $\to$ If so, it goes ahead, does all the desired work, and releases the resources
        2. After it has finished, it passes the token along the ring

            $\to$ It is not permitted to immediately enter the resource again using the same token
    * *Case 2*. If the process is handed the token by its neighbor and is not interested in the resource

        $\to$ It passes the token along, i.e. when no processes need the resource, the token just circulates around the ring

**Problem**. 
* If the token is lost, e.g. due to holder crash or message lost

    $\to$ It must be generated
    * *Token lost detection*. Difficult, i.e. since the amount of time between successive appearances of the token on the nteework is unbounded
* If a process crashes, but recovery is relatively easy
    * *Solution*. Require a process receiving the token to acknowledge receipt, to detect dead processes when their neighbors try to give them the token and fail

        $\to$ Dead processes can be removed, and the token holder can throw the token over the head of the dead one, to the next member down the line
    * *Drawback*. Everyone must maintain the current ring configuration

## A decentralized algorithm