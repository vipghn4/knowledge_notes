<!-- TOC titleSize:1 tabSpaces:2 depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 skip:0 title:1 charForUnorderedList:* -->
# Table of Contents
- [Table of Contents](#table-of-contents)
- [Introduction](#introduction)
- [Clock synchronization](#clock-synchronization)
  - [Physical clocks](#physical-clocks)
  - [Clock synchronization algorithms](#clock-synchronization-algorithms)
    - [Network time protocol](#network-time-protocol)
    - [The Berkeley algorithm](#the-berkeley-algorithm)
    - [Clock synchronization in wireless networks](#clock-synchronization-in-wireless-networks)
- [Appendix](#appendix)
  - [Concepts](#concepts)
<!-- /TOC -->

# Introduction
**Synchornization and coordination**. Two closely related phenomena
* *Process synchronziation*. Make sure that one process waits for another to complete its operation
* *Coordination*. Manage the interactions and dependencies between activities in a distributed system

    $\to$ One could state that coordinate encapsulates synchronization
* *Problem*. Coordination in distributed systems is much more difficult, compared to that in uniprocessor or multiprocessor systems
* *Process coordinator*. A group of processes can appoint one process as coordinator, which can be done by means of electron algorithms

# Clock synchronization
**Timing in centralized and distributed system**. 
* *Centralized system*. In such a system, time is unambiguous
    * *Explain*. When a process wants to know the time, it makes a call to the OS
* *Distributed system*. Achieving agreement on time is not trivial

## Physical clocks
**Timer**. Nearly all computers have a circuit for keeping track of time, i.e. a timer
* *Physical structure*. 
    * *Quartz crystal*. A computer timer is usually a precisely machined quartz crystal
    * *Registers*. Associated with each crystal are two registers, i.e. a counter and a holding register
* *Time ticking*. Each oscillation of the crystal decrements the counter by one

    $\to$ When the counter gets to zero, an interrupt is generated and the counter is reloaded from the holding register
    * *Consequence*. It is possible to program a timer to generate an interrupt 60 times a second, or at any other desired frequency
    * *Clock tick*. Each interrupt is called one clock tick
* *Time initialization*. When the system is booted, it usually asks the user to enter the date and time
    
    $\to$ This time is converted to the number of ticks after some known starting date and stored in memory
* *Automatic time initialization*. Most computers have a special battery-backed up CMOS RAM, so that the date and time need not be entered on subsequent boots
    * *Complementary metal-oxide-semiconductor (CMOS) RAM*. A small memory on PC motherboards, which is used to store BIOS settings
        * *Idea*. CMOS RAM is a non-volatile memory, or NVRAM, i.e. after the system loses power

            $\to$ It retains state by virtue of the CMOS battery
    * *Idea*. At every clock tick, the interrupt service procedure adds one to the time stored in memory

        $\to$ The software clock is kept up to date

**Timing consistency**.
* *Single computer and single clock*. It does not matter much if this clock is off by a small amount
    * *Explain*. All processes on the machine use the same clock, hence they will still be internally consistent, i.e. relative timing order between entities is kept

        $\to$ All that really matters are the relative times
* *Multiple CPUs with a clock for each CPU*. Although the frequency, at which a crystal oscillator runs is fairly stable

    $\to$ It is impossible to guarantee that the crystals in different CPUs all run at exactly the same frequency
    * *Assumptions*.
        * There are $n$ computers in the system
        * There are $n$ corresponding crystals in the system, each runs at slightly different rates
    * *Conclusion*. The software clocks gradually get out of sync and give different values when read out
        * *Clock skew*. The difference in time values
    * *Consequence*. Programs which expect the time associated with a file, object, process, or message to be correct and independent of the machine, on which it was generated, can fail
        * *Example*. When `make` program cannot know exactly the last editted time of every file in the repository

            $\to$ It cannot detect file changes and hence need to re-compile the whole repository for each update 

**External physical clocks**. In some systems, e.g. real-time systems, the actual clock time is important

$\to$ External physical clocks are required
* *Multiple external physical clocks*. Used for reasons of efficiency and redundancy
    * *Problems*.
        * How can we synchronize external clocks with real-world clocks
        * How can we synchronize the clocks with each other
* *Universal coordinated time (UTC)*. The basis for keeping global time, the basis of all modern civil timekeeping, and a worldwide standard
    * *UTC broadcasting*. To provide UTC to people who need precise time

        $\to$ Some 40 shortwave radio stations aroun the world broadcast a short pulse at the start of each UTC second
    * *Radio station accuracy*. About $\pm 1$ msec
    * *Electrical device timing accuracy*. Due to random atmospheric fluctuations, which can affect the length of the signal path

        $\to$ The accuracy is no better than $\pm 10$ msec
    * *Satellite-based UTC service*. Several earth satellites also offer a UTC service
        * *Examples*. The Geostationary Environment Operational Satellite can provide UTC accurately to 0.5 msec
        * *Consequence*. By combining receptions from several satellites, ground time servers can be built offering an accuracy of 50 nsec
    * *UTC receivers*. Commercially available and many computers are equipped with one

## Clock synchronization algorithms
**Clock synchronization scenarios**.
* *Scenario 1*. If one machine has a UTC receiver, the goal becomes keeping all other machines synchronized to it
* *Scenario 2*. If no machines have UTC receivers, each machine keeps track of its own time

    $\to$ The goal is to keep all machines together as well as possible

**Clocks in electrical devices**. All clocks are based on some harmonic oscillator, i.e. an object resonating at a certain frequency, and from which we can subsequently derive time
* *Atom clocks*. Based on the transitions of the cesium 133 atom, which is not only very high, but also very constant
* *Hardware clocks in most computers*. Use a crystal oscillator based on quartz, which is capable of producing a very high, stable frequency, although not as stable as atomic clocks
* *Software clock in a computer*. Derived from the computer's hardware clock
    * *Idea*. The hardware clock is assumed to cause an interrupt $f$ times per second

        $\to$ When this timer goes off, the interrupt handler adds 1 to a counter keeping track of the number of ticks (interrupts) since some ageed-upon time in the past
    * *Notation*. The counter acts as a software clock $C$, resonating at frequency $F$

**Clock synchronization algorithms objective**.
* *Assumptions*.
    * $t$ is the UTC time
    * $C_p(t)$ is the value of the software clock on machine $p$
* *Clock synchronization objective by precision*. Keep the deviation between the respective clocks of any two machines in a distributed system, within a specified bound, known as the precision $\pi$

    $$\forall t,\forall p,q,|C_p(t) - C_q(t)| \leq \pi$$

    * *Internal synchronization*. Keeping the clocks precise
* *Clock synchronization objective by accuracy*. When considering an external reference point, e.g. UTC, we use accuracy $\alpha$

    $$\forall t,\forall p, |C_p(t) - t|\leq \alpha$$

    * *External synchronization*. Keeping the clock accurate
    * *Theorem*. A set of clocks, which are accurate within bound $\alpha$, will be precise within bound $\pi=2\alpha$
* *Perfect world*. $C_p(t) = t$ for all $p$ and $t$, and thus $\alpha = \pi = 0$

**Clock drift**. Hardware clocks, and hence software clocks, are subject to clock drift
* *Clock drift*. Since their frequency is not perfect and affected by external sources, e.g. temperature, clocks on different machines will gradually start showing different values for time
    * *Clock drift rate*. The difference per unit of time from a perfect reference clock
    * *Clock drift rate of a typical quartz-based hardware clock*. $10^{-6}$ seconds per second, i.e. $31.5$ seconds per year
* *Maximum clock drift rate $\rho$*. Included in the specifications of hardware clock
    * *Assumptions*.
        * $F(t)$ is the actual oscillator frequency of the hardware clock at time $t$
        * $F$ is the ideal constant frequency
    * *Conclusion*. The hardware clocks is living up to its specifications if

        $$\forall t, (1-\rho) \leq \frac{F(t)}{F} \leq (1 + \rho)$$
    
    * *Software clock drift rate*.

        $$C_p(t) = frac{1}{F} \int_0^t F(t) dt,\quad \frac{d C_p(t)}{dt} = \frac{F(t)}{F}$$

* *Ultimate goal*. Keep the software clock drift bounded to $\rho$, i.e.

    $$\forall t, (1 - \rho) \leq \frac{d C_p(t)}{dt} \leq (1 + \rho)$$

    <div style="text-align:center">
        <img src="https://i.imgur.com/GmYZ668.png">
        <figcaption>The relation between clock time and UTC when clocks tick at different rates</figcaption>
    </div>

    * *Observations*. If two clocks are drifting from UTC in the opposite direction, at a time $\Delta t$ after they were synchronized

        $\to$ They may be as much as $2\rho\cdot\Delta t$ apart
    * *Consequence*. If the system designers want to guarantee a precision $\pi$

        $\to$ Clocks must be resynchronized in software, at least every $\pi/(2\rho)$ seconds

**Clock synchronization algorithms**. Differ in precisely how the resynchronization is done

### Network time protocol
**Network time protocol**. Let clients contact a time sever, which can accurately provide the current time, i.e. since it is equipped with a UTC receiver or an accurate clock
* *Problem*. When contacting the server, message delays will outdate the reported time
    * *Solution*. Estimate the message delay

**Scenerio and analysis**.

<div style="text-align:center">
    <img src="https://i.imgur.com/aEn8BWm.png">
    <figcaption>Getting the current time from a time server</figcaption>
</div>

* *Scenario*.
    1. A sends a request to B, timestamped with value $T_1$
    2. B records the time of receipt $T_2$, taken from its own local clock, and returns a response timestamped with time $T_3$, piggybacking the previously recorded value $T_2$
    4. A records the time of the response's arrival $T_4$
* *Assumptions*. The propagation delays from A to B is roughly the same as B to A, i.e.

    $$\delta T_\text{req} = T_2 - T_1 \approx T_4 - T_3 = \delta T_\text{res}$$
* *A's time offset relative to B*. Can be estimated by A as

    $$\theta = T_3 + \frac{(T_2 - T_1) + (T_4 - T_3)}{2} - T_4 = \frac{(T_2 - T_1) + (T_3 - T_4)}{2}$$

    * *Ideal case*. When $\delta T_\text{req} = \delta T_\text{res}$ then $\theta = 0$

        $\to$ A has no time offset relative to B
    * *Explain*.
        * We have that

            $$\frac{(T_2 - T_1) + (T_4 - T_3)}{2} &= \frac{(T_4 - T_1) - (T_3 - T_2)}{2}\approx \bar{T}_{AB}$$

            where $\bar{T}_{AB}$ is the average time a message travels between A and B
        * We also have that

            $$T_4 - T_3 \approx \bar{T}_{AB} - \theta$$

            where $\theta$ is given above
        * Hence, we can represent $\theta$ as
            
            $$T_1 + \bar{T}_{AB} + \theta \approx T_2,\quad T_3 - \theta + \bar{T}_{AB} \approx T_4$$

**Time rectification**. If A's clock is fast, i.e. $\theta < 0$, then A should, in principle, set its clock backward

$\to$ This is not allowed, since it may cause severe errors in A
* *Idea*. Rectify time gradually
* *Approach 1*. Suppose that the timer is set to generate 100 interrupts per second

    $\to$ Normally each interrupt would add 10 msec to the time
    * When slowing down, the interrupt routine adds only 9 msec each time until the correction has been made
    * When speeding up, the interrupt routine adds 11 msec each time until the correction has been made

**NTP implementation**. The protocol is set up pairwise between servers
* *Procedure*. 
    1. B probe A for its current time and vice versa
    2. The offset $\theta$ is computed as given above, along with the estimation $\delta$ for the delay

        $$\delta = \frac{(T_4 - T_1) - (T_3 - T_2)}{2}$$
    3. Each pairs of $(\theta,\delta)$ values are buffered
    4. Take the minimal value found for $\delta$ as the best estimation for the delay between A and B

        $\to$ The associated $\theta$ is taken as the most reliable estimation of the offset
* *Symmetric application of NTP*. Allow B to adjust its clock to that of A
    * *Problem*. If B's clock is known to be more accurate, then this modification is not desired
    * *Solution*. NTP divides servers into strata
        * *Stratum-1 servers*. Servers with a reference clock, e.g. UTC receiver or an atomic clock

            $\to$ The clock itself is said to operate at stratum 0
        * *Idea*. When A contacts B, it will adjust its time if its own stratum level is higher than that of B

            $\to$ After synchronization, A's stratum level will be $k+1$, where $k$ is the stratum level of B
        * *Symmetricity of NTP*. If A's stratum level was lower than that of B, then B will adjust itself to A

### The Berkeley algorithm
**The Berkeley algorithm**. Use active time server, rather than passive ones like NTP

<div style="text-align:center">
    <img src="https://i.imgur.com/D1K5sb0.png">
    <figcaption>Execution steps of the time daemon</figcaption>
</div>

* *Idea*. The time server, i.e. time daemon, is active, polling every machine from time to time to ask what time it is there

    $\to$ Based on the answers, it computes an average time and tells all other machines to advance or slow their clocks to the new time
* *Usage*. Suitable when no machine in the system has a UTC receiver
* *Time daemon's time*. Must be set manually by the operator periodically

**Time agreement**. It is sufficient that all machines agree on the same time, not necessarily agree with the real time, e.g. UTC

$\to$ Berkeley algorithm is typically an internal clock synchronization algorithm

### Clock synchronization in wireless networks
**Problems with wireless networks**. 
* It is hard to deploy time servers, as for traditional distributed systems
* Most machines cannot contact each other, preventing effective dissemination of information
* Nodes are resource constrained, and multihop routing is expensive
* It is often important to optimize algorithms for energy consumption

**Reference broadcast synchronization (RBS)**. A clock synchronization protocol
* *Idea*.
    * Relax the assumption that there is a single node with an accurate account of the actual time available
    * Instead of aiming to provide all nodes UTC time, it aims at merely internally synchronizing the clocks, i.e. like Berkeley algorithm
* *Previously discussed solutions*. Bring the sender and receiver into sync, following a two-way protocol

    $\to$ RBG deviates from this pattern by letting only the receivers synchronize, keeping the sender out of the loop
* *Implementation*. A sender broadcasts a reference message, which allows its receivers to adjust their clocks
    * *Key observation*. In a sensor network, the time to propagate a signal to other nodes is roughly constant, provided no multihop routing is assumed

        $\to$ Propagation time can be measured from the moment that a message leaves the network interface of the sender
* *Consequence*. Two important sources for variation in message transfer no longer play a role in estimating delays, i.e.
    * The time spent to construct a message
    * The time spent to access the network

**Analysis of RBS**.

<div style="text-align:center">
    <img src="https://i.imgur.com/JEJjWlU.png">
    <figcaption>The usual crucial path and the one used in RBS in determining network delays</figcaption>
</div>

* *Underlying idea of RBS*. When a node broadcasts a reference message $m$, each node $p$ records the time $T_{p,m}$ that it received $m$

    >**NOTE**. $T_{p,m}$ is read from $p$'s local clock

* *Time relative offset estimation*. Ignoring clock skew, two nodes $p$ and $q$ can exchange each other's delivery times to estimate their mutual, relative offset
    
    $$\text{Offset}(p,q) = \frac{\sum_{k=1}^M (T_{p,k} - T_{q,k})}{M}$$

    where $M$ is the total number of reference messages sent
    * *Consequences*.
        * $p$ knows the value of $q$'s clock relative to its own value
        * If $p$ simply stores these offsets, there is no need to adjust its own clock, saving energy
* *Clock drift*. Cause the simple average offset as above to be useless
    * *Reasons*.
        * The last values sent are less accurate than the first ones
        * As time goes by, the offset will presumably increase
    * *Solution*. Instead of computing an average, we apply standard linear regression to compute the offset as a function

        $$\text{Offset}(p,q,t) = \alpha t + \beta$$

        where $\alpha,\beta$ are computed from the pairs $(T_{p,k}, T_{q,k})$

# Appendix
## Concepts
**Determining real time**.
* *Time determination in mechanical clocks*. Time is measured astronomically
    * *Movement of the sun*. Everyday, the sun appears to rise on the eastern horizon, then climbs to a maxmimum height in the sky, and finally sinks in the west
        * *Transit of the sun*. The event of the sun's reaching its highest apparent point in the sky

            $\to$ This event occurs at about noon each day
        * *Solar day*. The interval between two consecutive transits of the sun
        * *Solar second*. Since there are 24 hours in a day, each containing 36000 seconds

            $\to$ The solar second is $\frac{1}{86400}$ of a solar day
    * *Movement of the earth*. The period of the earth's rotation is not constant, i.e. the earth is slowing down, due to tidal friction and atmospheric drag

        $\to$ Geologists believe that 300 million years ago, there were about 400 days per year
        * *The length of a year*. The time for one trip around the sun
            * *Change in year's length*. Approximately no change, i.e. the day has simply become longer as time goes on
        * *Short-term variations in day's length*. Occur probably due to turbulence deep in the earth's core of molten iron
        * *Day length measurement*. Measure a large number of days and take the average before dividing by $86400$ to obtain mean solar second
* *Atomic clock*. With these clocks, we can measure time much more accurately, and independent of the wiggling and wobbling of the earth
    * *Idea*. Count the transitions of the cesium 133 atom

        $\to$ Physicists took over the job of time keeping from the astronomers
    * *Atomic second*. The time it takes the cesium 133 atom to make exactly 9,192,631,770 transitions
        * *Explain*. 9,192,631,770 is chosen to make the atomic second equal to the mean solar second, in the year of its introduction
    * *Atomic time measurement*. Several laboratories around the world have cesium 133 clocks
        
        $\to$ Periodically, each laboratory tells the Bureau International de l'Heure (BIH) in Paris how many times its clock has ticked
        * *International atomic time (TAI)*. The BIH averages the time of laboratories to obtain TAI
        * *Meaning of TAI*. The number of ticks of the cesium 133 clocks since midnight on Jan. 1, 1958, i.e. the beginning of time, divided by 9,192,631,770
    * *Problem with TAI*. 86,400 TAI seconds is about 3 msec less than a mean solar day, i.e. since the mean solar day is getting longer all the time
        
        $\to$ Using TAI for time keeping means that over the course of the years, noon would get earlier and earlier
        * *Solution*. BIH introduces leap seconds, whenever the discrepancy between TAI and solar time grows to 800 msec
* *UTC*. A time system based on constant TAI seconds but stays in phase with the apparent motion of the sun
* *Electric timer*. Most electric power companies synchronize the timing of their 60-Hz or 50-Hz clocks to UTC

    $\to$ When BIH announces a leap second, the power companies raise their frequency to 61 Hz or 51 Hz for 60 or 50 sec, to advance all the clocks in their distribution area
    * *Consequence*. Since 1 sec is a noticeable interval for a computer, an OS needing to keep accurate time over a period of years must have special software to account for leap seconds as they are announced

**How important is an accurate account of time**.