<!-- TOC titleSize:1 tabSpaces:2 depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 skip:0 title:1 charForUnorderedList:* -->
# Table of Contents
- [Table of Contents](#table-of-contents)
- [Replica management](#replica-management)
  - [Finding the best server location](#finding-the-best-server-location)
  - [Content replication and placement](#content-replication-and-placement)
    - [Permanent replicas](#permanent-replicas)
    - [Server-initiated replicas](#server-initiated-replicas)
    - [Client-initiated replicas](#client-initiated-replicas)
  - [Content distribution](#content-distribution)
    - [State versus operations](#state-versus-operations)
    - [Pull versus push push protocols](#pull-versus-push-push-protocols)
    - [Unicasting versus multicasting](#unicasting-versus-multicasting)
  - [Managing replicated objects](#managing-replicated-objects)
- [Appendix](#appendix)
  - [Concepts](#concepts)
<!-- /TOC -->

# Replica management
**Key issue for any distributed system supporting replication**.
* *Placement problem*. Decide where, when, and by whom replicas should be placed

    $\to$ This problem can be split into two subproblems
    * Problem of placing replica servers, i.e. finding the best locations to the place a server, which can host part of a data store
    * Problem of placing content, i.e. finding the best servers for placing content

        $\to$ This often means that we are looking for the optimal placement of only a single data item

    >**NOTE**. The difference is a subtle one, and the two issues are often not clearly separated

* *Consistency problem*. Which mechanisms to use for keeping the replicas consistent

## Finding the best server location
**Finding the best server location**. 
* Over a decode ago, one could be concerned about where to place an individual server

    $\to$ Matters have changed considerably with the advent of many large-scale data centers located across the Internet
* Connectivity continues to improve, making precisely locating servers less critical

## Content replication and placement
**Types of replicas**. When it comes to content replication and placement

$\to$ Three types of replicas can be distinguished logically

<div style="text-align:center">
    <img src="https://i.imgur.com/M2oofXB.png">
    <figcaption>The logical organization of different kinds of copies of a data store into three concentric rings</figcaption>
</div>

### Permanent replicas
**Permanent replicas**. The initial set of replicas, which constitute a distributed data store
* *Number of permanent replicas*. In many cases, this number is small

**Example**. Distribution of a Web site generally comes in one of several forms
* *Option 1 - Clustering*. The files constituting a site are replicated across a limited number of servers at a single location

    $\to$ Whenever a request comes in, it is forwarded to one of the servers, e.g. using a round-robin strategy
* *Option 2 - Mirroring*. A Web site is copied to a limited number of servers, i.e. mirror sites, which are geographically spread across the Internet

    $\to$ Clients choose one of the various mirror sites from a list offered to them
    * *Similar to cluster-based Web sites*. There are only a few replicas, which are more or less statically configured
* *Option 3 - shared-nothing*. The database is distributed and replicated across a number of servers, which together form a cluster of servers
    * *"Shared-nothing"*. Neither disks nor main memory are shared by processors

    >**NOTE**. Alternatively, a database is distributed and possibly replicated across a number of geographically dispersed sites

### Server-initiated replicas
**Server-initiated replicas**. Copies of a data store, which exist to enhance performance, and created at the initiative of the owner of the data store

**Example**. Consider a Web server placed in NYC

$\to$ Normally this server can handle incoming requets quite easily
* *Problem*. One day, a sudden burst of requests come in from an unexpected location far from the server

    $\to$ It may be worthwhile to install a number of temporary replicas in regions, where requests are coming from

**Web site with server-initiated replication only**. If it can be guaranteed that each data item is hosted by at least one server

$\to$ It may suffice to use only server-initiated replication, and not have any permanent replicas
* *Reason to use permanent replicas*. Useful as a back-up facility, or used as the only replicas allowed to be changed to guarantee consistency

    $\to$ Server-initiated replicas are used for placing read-only copies close to clients

### Client-initiated replicas
**Client-initiated replicas**. More commonly known as client caches
* *Cache*. A local storage facility used by a client to temporarily store a copy of the data it has just requested
    * *Cache management*. In principle, managing the cache is left entirely to the client

        $\to$ The data store, from where the data had been fetched, has nothing to do with keeping the cached data consistent
        * *Exception*. There are many occasions, in which client can rely on participation from the data store to inform it when cached data has become stale
    * *Cache location*. On client's machine, or on a separate machine in the same LAN as the client
* *Usage*. Only to improve access times to data
    * *Explain*. When most operations involve only reading data 
        
        $\to$ Performance can be improved by letting the client store requested data in a nearby cache
        * *Consequence*. The next time that the same data needs to be read

            $\to$ The client can fetch it from this local cache
    * *Drawback*. This scheme works fine if the fetched data have not been modified in the meantime

**Cache life time**. Data are generally kept in a cache for a limited amount of time
* *Purposes*.
    * To prevent extremely stale data from being used, or
    * To make room for other data

**Cache hit**. When a requested data can be fetched from the local cache
* *Improve the number of cache hits*. Caches can be shared between clients
    * *Underlying assumption*. A data requested from client $C_1$ may also be useful for a request from another nearby client $C_2$

        $\to$ This depends very much on the type of data store

## Content distribution
**Content distribution**. Deal with propagation of updated content to the relevant replica servers
* *Trade-off*.
    * State versus operations
    * Pull versus push protocols
    * Unicasting versus multicasting

### State versus operations
**Propagated information**. An important design issue
* *Possibilities*.
    * Propagate only a notification of an update
    * Transfer data from one copy to another
    * Propagate the update operation to other copies

**Notification propagation**. This is what invalidation protocols do
* *Invalidation protocol*. In this protocol, other copies are informed that an update has taken place, and the data they contain are no longer valid
    
    $\to$ The invalidation may specify which part of the data store has been updated, hence that only part of a copy is invalidated
* *Pros*. These protocols use little network bandwidth

    $\to$ This protocol generally work best when there are many update operations compared to read operations
* *Cons*. No more than a notification is propagated
    * *Consequence*. Whenever an operation on an invalidated copy is requested

        $\to$ That copy generally needs to be updated first, depending on the specific supported consistency model

**Data transfer**. Useful when the read-to-write ratio is relatively high

$\to$ The probability that an update will be effective, i.e. the modified data will be read before the next update takes place, is high
* *Saving bandwidth*. 
    * Log the changes and transger only the logs, instead of propagating modified data
    * Transfers are often aggregated, i.e. multiple modifications are packed into a single message, saving communication overhead

**Update operation propagation (active replication)**.
* *Active replication*. Assume that each replica is represented by a process capable of actively keeping its associated data up-to-date by performing operations
* *Pros*. 
    * Provided the size of the parameters associated with an operation are relatively small
      
        $\to$ Updates can often be propagated at minimal bandwidth costs 
    * The operations can be of arbitrary complexity, allowing further improvements in keeping replicas consistent
    * More processing power may be required by each replica, especially in those cases, when operations are relatively complex

### Pull versus push push protocols
**Push-based approach (server-based protocols)**. Updates are propagated to other replicas without those replicas asking for the updates
* *Usage*. Generally applied when strong consistency is required
    * Often used between permanent and server-initiated replicas
    * Also used to push updates to client caches
* *Need for strong consistency*. Related to the fact that permanent and server-initiated replicas, and large shared caches, are often shared by many clients

    $\to$ Those clients will mainly perform read operations, i.e. read-to-update ratio at each replica is high
    * *Consequence*. 
        * Push-based protocols are efficient
            * *Explain*. Every pushed update can be expected to be of use for at least one, but maybe more readers
        * Push-based protocols make consistent data immediately available when asked fore

**Pull-bash approach (client-based protocols)**. A server or client requests another server to send it any updates it has at the moment
* *Usage*. Often used by client caches, i.e. the client polls the server to see whether an update is required
* *Pros*. Efficient when the read-to-update ratio is relatively low, e.g.
    * For nonshared client caches, which have only one client
    * For rarely-shared cached data items, which are shared by many clients
* *Cons*. The response time increases in case of a cache miss

**Comparison between push-based and pull-based solutions**.

| Issue | Push-based | Pull-based |
| --- | --- | --- |
| State at server | List of clietn replicas and caches | None |
| Message sent | Update, and possibly fetch update later | Poll and update |
| Response time at client | Immediate, or fetch-update time | Fetch-update time |

* *Trade-off*. There are a number of trade-offs to be made, e.g. consider a client-server system with a single, nondistributed server, and a number of client processes, each having their own cache
* *State at server*.
    * *Push-based protocols*. The server needs to keep track of all client caches
        * *Pros*. Less fault tolerant
        * *Cons*. Introduce a considerable overhead at the server
    * *Pull-based protocols*. Nothing is kept at the server
* *Message sent*.
    * *Push-based approach*. The only communication is that the server sends updates to each client
        * *Invalidation update*. When updates are only invalidations, additional communication is required by a client to fetch the modified data
    * *Pull-based approach*. A client have to poll the server, and, if required, fetch the modified data

**Hybrid form of update propagation**. Based on leases
* *Lease*. In case of replica management, a lease is a promise by the server, that it will push updates to the client for a specified time
    * *Purpose*. Provide a convenient mechanism for dynamically switching between between a push-based and pull-based strategy
* *Lease expiration*. When a lease expires
    * *Option 1*. The client is forced to poll the server for updates, and pull in the modified data if required
    * *Option 2*. A client requests a new lease for pushing updates when the previous lease expires
* *Types of leases*. Note that in all cases, updates are pushed by the server as long as the lease has not expired
    * *Age-based leases*. Given out on data items depending on the last time the item was modified
        * *Underlying assumption*. Data, which have not been modified for a long time, can be expected to remain unmodified for some time yet to come
            * *Example*. Web-based data and regular files
        * *Idea*. Grant long-lasting leases on data items, which are expected to remain unmodified

            $\to$ The number of update messages can be strongly reduced compared to the case, where all leases have the same expiration time
    * *Renewal-frequency-based leases*. Based on how often a specific client requests its cached copy to be updated
        * *Idea*. 
            * A server will hand out a long-lasting lease to a client, whose cache often needs to be refreshsed
            * A client asking only occasionally for a specific data item will handed a short-term lease for the item
        * *Consequence*. 
            * Server essentially keeps track only of those clients, where its data are popular
            * Those clients are offered a high degree of consistency
    * *State-based lease*. Based on state-space overhead at the server
        * *Idea*. When the server realizes that it is gradually becoming overloaded, it lowers the expiration time of new leases it hands out to clients
        * *Consequence*. The server needs to keep track of fewer clients as leases expire more quickly

            $\to$ The server dynamically switches to a more stateless mode of operation, offloading itself to that it can handle requests more efficiently
        * *Cons*. The client may need to do more work when the read-to-update ratio is high

### Unicasting versus multicasting
**Unicast communication**. A server, which is part of the data store, sends its update to $N$ other servers by sending $N$ separate messages, one to each server
* *Unicasting combined with pull-based approach*. With a pull-based approach, it is generally only one client or server requesting its copy to be updated

    $\to$ Unicasting may be the most efficient solution

**Multicasting**. The underlying etwork takes care of sending a message efficiently to multiple receivers
* *Extreme situation*. When all replicas are located in the same LAN, and hardware broadcasting is available

    $\to$ Broadcasting or multicasting a message is no more expensive than a single point-to-pointmessage
* *Multicasting combined with push-based approach*. These two methods can often be efficiently combined to propagate updates
    * *Idea*. When the two are carefully integrated, a server deciding to push its updates to a number of other server simply use a single multicast group to send its updates

## Managing replicated objects
**Replicated objects and entry consistency**. Data-centric consistency for distributed objects comes naturally in the form of entry consistency

$\to$ In this case, the goal is to group operations on shared data using synchronization variables, e.g. locks
* *Object locking*. Objects naturally combine data and the operations on that data

    $\to$ Locking objects during an invocation serializes access and keeps them consistent

**Locking replicated objects**. Associating a lock with an object is simple, but it may not provide a proper solution when an object is replicated
* *Issues to solve for implementing entry consistency*.
    * *Issue 1*. We need a means to prevent concurrent execution of multiple invocations on the same objects
        
        $\to$ When any method of an object is being executed, no other methods may be executed
        * *Consequence*. This requirement ensures that access to the internal data of an object is serialized

            $\to$ Simply use local locking mechanism will ensure this serialization
    * *Issue 2*. In case of replicated object, we need to ensure that all changes to the replicated state of the object are the same
        
        $\to$ No two independent method invocations take place on different replicas at the same time
        * *Consequence*. We need to order invocations, so that each replica sees all invocations in the same order

**Designing replicated objects**. Done by first designing a single object, possibly protecting it against concurrent access through local locking, then replicate it
* *Middleware's role*. Ensure that if a client invokes a replicated object

    <div style="text-align:center">
        <img src="https://i.imgur.com/Of0fHsf.png">
        <figcaption>Deterministic thread scheduling for replicated object servers</figcaption>
    </div>

    * The invocation is passed to the replicas, and handed to their respective object servers in the same order everywhere
    * All threads in the servers process those requests in the correct order
* *Idea*.
    1. Multithreaded object servers pick up an incoming request, pass it on to an available thread, and wait for the next request to come in
    2. The server's thread scheduler allocates the CPU to runnable threads
* *Total ordering guarantee*. If the middleware has done its best to provide a total ordering for request delivery

    $to$ The thread schedulers should operate in a deterministic fashion to not mix the ordering of method invocations on the same object
    * *Example*. Consider the figure above, then if threads $T_1^1$ and $T_1^2$ handle the same incoming replicated invocation request

        $\to$ They should both be scheduled before $T_2^1$ and $T_2^2$
* *Need for deterministicity*. If we already have total-ordered request delivery

    $\to$ We only need to ensure that all requests for the same replicated object are handled in the order they were delivered
    * *Consequence*. Invocations for different objects can be processed concurrently, without further restrictions from the thread scheduler

    >**NOTE**. Only few existing systems that support such concurrency

# Appendix
## Concepts
**Replica-server placement**. The placement of replica servers is not an intensively studied problem since it is often more of a management and commercial issue than an optimization problem

$\to$ However, analysis of client and network properties are useful to come to informed decisions
* *Computing the best placement of replica servers*. Boil down to an optimization problem, in which the best $K$ out of $N$ locations need to be selected

    $\to$ These problems are known to be computationally complex, and can be solved only through heuristics
* *Qiu et. a. (2001) solution*. Take the distance between clients and locations as their starting point
    * *Idea*. Given that $k$ servers have been placed, i.e. there are $N-k$ locations left 
        
        $\to$ This solution selects one server at a time, so that the average distance between that server and its client is minimal
* *Radoslavov et. al. (2001) solution*. Propose to ignore the position of clients, and only take the topology of the Internet as formed by the autonomous systems (AS)
    * *Idea*. Radoslavov first consider the largest AS and place a server on the router with the largest number of network interfaces, i.e. links

        $\to$ The algorithm repeats with the second largest AS, and so on
    * *Effect*. Under the assumption that clients are uniformly distributed across the Internet, relative to the existing topology
    
        $\to$ Client-unaware server placement turns out to achieve similar results as client-aware placement

        >**NOTE**. To what extent this assumption is true is unclear

* *Szymaniak et. al. (2006) solution*. Developed a method, by which a region for placing replicas can be quickly identified
    * *Problem with previous approaches*. These algorithms are computationally expensive
        * *Explain*. Both the previous algorithms have a complexity, which is higher than $O(N^2)$, where $N$ is the number of locations to inspect
    * *Region*. A collection of nodes accessing the same content, but for which the internode latency is low
    * *Objective*. Select the most demanding regions, i.e. the one with the most nodes

        $\to$ We then let one of the nodes in the region act as replica server
        * *Idea*. Assuming that nodes are positioned in an $m$-dimensional geometric space

            $\to$ We need to identify the $K$ largest clusters and assign a node from each cluster to host replicated
    * *Cluster identification*.
        1. Partition the entire space into cells, i.e. $m$-dimensional hypercubes
        2. The $K$ most dense cells are chosen for placing a replica server
    * *Choosing cell size*.
        * *Effects of cell size*.
            * *Large cells*. Multiple clusters of nodes can be contained in the same cell

                $\to$ Too few replica servers for those clusters would be chosen
            * *Small cells*. A single cluster is spread across a number of cells

                $\to$ Too many replica servers are chosen
        * *Appropriate cell size*. Computed as a function of
            * The average distance between two nodes
            * The number of required replicas
        * *Consequence*. With proper cell size, the algorithm performs as well as the close-to-optimal one described by Qiu et. al., but having a much lower complexity, i.e. $O(N\times \max\{\log N, K\})$

**An example of dynamic Web-content placement**. The problem of dynamically placing replicas has since long been addressed in Web hosting services
* *Web hosting services*. Offer an often relatively static collection of servers spread across the Internet

    $\to$ These servers can maintain and provide access to Web files belonging to third parties
    * *Dynamical file replication*. To provide optimal facilities, those hosting services can dynamically replicate files to servers, where those files are required to enhance performance
        * *Explain*. Files are closer to the demanding groups of clients
* *Deciding where to place content*. Given that the replica servers are already in place

    $\to$ Such decision is not difficult
    * *Rabinovich et. al. (1999)'s solution*. An early case toward dynamica replication of files, in the case of a Web hosting service
        * *Objective*. Designed to support Web pages, for which reason it assumes that updates are relatively rare, compared to read requests
        * *Unit of data*. Files
        * *Issues of interest*.
            * Replication can take place to reduce the load on a server
            * Specific files on a server can be migrated or replicated to servers placed in the promixity of clients issuing many requests for those files

                >**NOTE**. We will focus on this issue
        
        * *File access count*. Each server keeps track of access counts per file, and where access requests come from, i.e.
            * *File access*. When a client $C$ enters the service, it does so via a server close to it
            * *File access count*. If client $C_1$ and $C_2$ share the same closest server $P$

                $\to$ All access requests for file $F$ at server $Q$ from $C_1$ amd $C_2$ are jointly registered at $Q$ as $\text{cnt}_Q(P,F)$
        * *File removal at server*. When the number of requests for a file $F$ at server $S$ drops below a threshold $\text{del}(S,F)$

            $\to$ $F$ can be removed from $S$
            * *Consequence*. The number of replicas of $F$ is reduced, possibly leading to higher work loads at other servers
            * *File existence guarantee*. Special measures are taken to ensure that at least one copy of each file continues to exist
        * *File replication at server*. A replication threshold $\text{rep}(S,F) > \text{del}(S,F)$ is chosen, indicating that the number of requests for $F$ is so high

            $\to$ It may be worthwhile replicating in at $S$
        * *File migration*. If the number of requests lie within $(\text{del}(S,F), \text{rep}(S,F))$, the file is allowed to be only migrated
            * *Explain*. It is important to at least keep the number of replicas for $F$ the same
            * *File migration failure*. Due to the target server is already heavily loaded, or is out of disk space

                $\to$ The source server will attempt to replicate the file on other servers
            * *Migration procedure*. Source server checks all other servers in the Web hosting service, starting with the one farthest away

                $\to$ The first one suitable should hold the file
        * *File replacement reevaluation*. When a server $Q$ decides to reevaluate the placement of the files it stores
            1. $Q$ checks the access count for each file
            2. If the number of access requests for $F$ at $Q$ drops below $\text{del}(Q,F)$
                
                $\to$ $Q$ will delete $F$, unless it is the last copy
            3. If for some server $P$, $\text{cnt}_Q(P,F)$ exceeds mroe than half of the total requests for $F$ at $Q$

                $\to$ $P$ is requested to take over the copy of $F$, i.e. $Q$ will attempt to migrate $F$ to $P$

**Replicated invocations**.