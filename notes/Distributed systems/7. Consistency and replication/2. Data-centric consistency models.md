<!-- TOC titleSize:1 tabSpaces:2 depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 skip:0 title:1 charForUnorderedList:* -->
# Table of Contents
- [Table of Contents](#table-of-contents)
- [Data-centric consistency models](#data-centric-consistency-models)
  - [Continuous consistency](#continuous-consistency)
    - [The notion of a conit](#the-notion-of-a-conit)
  - [Consistent ordering of operations](#consistent-ordering-of-operations)
    - [Sequential consistency](#sequential-consistency)
    - [Causal consistency](#causal-consistency)
    - [Grouping operations - Release consistency](#grouping-operations---release-consistency)
    - [Consistency versus coherence](#consistency-versus-coherence)
  - [Eventual consistency](#eventual-consistency)
- [Appendix](#appendix)
  - [Discussions](#discussions)
<!-- /TOC -->

# Data-centric consistency models
**Data store**. Traditionally, consistency has been discussed in the context of read and write operations on shared data, available by means of distributed shared memory, a distributed shared database, or a distributed file system
* *Data store*. May be physically distributed across multiple machines, with each process having access to the data from the store is assumed to have a local, or nearby, copy available of the entire store

    <div style="text-align:center">
        <img src="https://i.imgur.com/bdh4SRi.png">
        <figcaption>The general organization of a logical data store, physically distributed and replicated across multiple processes</figcaption>
    </div>

    * *Read operation*. Any operation which is not a write operation
    * *Write operation*. Any operation changing the data, i.e. such operation will be propagated to other copies

**Consistency model**. A contract between processes and the data store, i.e. if processes agree to obey certain rules, the store promises to work correctly
* *Expectation*. A process performing a read operation on an data item expects the operation to return a value, which shows the results of the latest write operation on that data
* *Consistency without global clock*. Difficult to precisely define which write operation is the last one
    * *Alternative solution*. Provide other definitions, leading to a range of consistency models, each of which restricts the values, which a read operation on a data item can return
        * *Extent of restriction*. The one with major restrictions are easy to use, whereas those with minor restrictions are generally difficult to use inpractice
        * *Trade-off*. The easy-to-use models do not perform nearly as well as difficult ones

## Continuous consistency
**Choice of consistency model**. Replicating data poses consistency problems, which cannot be solved efficiently in a general way

$\to$ Only if we loosen consistency, can there be hope for attaining efficient solutions

>**NOTE**. There are no general rules for loosening consistency, i.e. what can be tolerated exactly is highly dependent on applications

**Continuous consistency ranges**. Yu and Vahdat take a general approach to specify what inconsistencies they can tolerate, by distinguishing three independent axes for defining inconsistencies, i.e.
* *Axes for defining inconsistency*.
    * Deviation in numerical values between replicas
    * Deviation in staleness between replicas
    * Deviation w.r.t the ordering of update operations

**Deviation in numerical values between replicas**. Measuring inconsistency in terms of numerical deviations can be used by applications, for which the data have numerical semantics, e.g. stock market prices
* *Example*. The replication of records containing stock market prices, i.e. an application may specify that two copies should not deviate more than \$0.02
* *Numerical deviation types*.
    * *Absolute numerical deviation*. For example, an application may specify that two copies should not deviate more than \$0.02
    * *Relative numerial deviation*. For example, an application may specify that two copies should not deviate more than 0.5%
* *Idea*. If the numerical deviation between replicas does not violate the specified threshold, replicas would still be considered to be mutually consistent
* *Alternative interpretation*. Numerical deviation can be understood in terms of the number of updates, which have been applied to a given replica, but have not yet been seen by others
    * *Value weight*. The associated deviation, in this case, in the value is referred to as its weight

**Deviation in staleness between replicas**. Relate to the last time a replica was updated, i.e. for some applications, it can be tolerated that a replica provides old data, as long as it is not too old

$\to$ A server may receive timely updates, but may decide to propagate updates to the replicas only one in a while

**Deviation w.r.t the ordering of update operations**. There are classes of applications, in which the ordering of updates are allowed to be different at the various replicas, as long as the differences remain bounded
* *Example*. The updates are applied tentatively to a local copy, awaiting global agreement from all replicas
    * *Consequence*. Some updates may need to be rolled back and applied in a different order, before becoming permanent

>**NOTE**. Ordering deviations are much harder to grasp than the other two consistency metrics

### The notion of a conit
**Consistency unit (conit)**. Introduced by Yu and Vahdat to define inconsistencies
* *Conit*. Specify the unit, over which consistency is to be measured
    * *Example*. In stock-exchange, a conit could be defined as a record representing a single stock
* *Servers' task*. Keep the conit consistently replicated
    * *Idea*. Each replica server maintains a 2D vector clock 

**Example**. Consider the situation of keeping track of a fleet of cars
* *Problem*. The fleet owner is interested in knowing how much he pays on average for gas

    $\to$ Whenever a driver tanks gasoline, he reports the amount of gasoline which has been tanked, i.e. recorded as `g`, the price paid, i.e. recorded as `p`, and the total distance since the last time he tanked, i.e. recorded by `d`
    * *Conit*. Technically, three variables `g`,`p`, and `d` form a conit, which is replicated across two servers

      $\to$ A driver regularly reports his has usage to one of the servers by separately updating each variable

<div style="text-align:center">
    <img src="https://i.imgur.com/efFbCVG.png">
    <figcaption>An example of keeping track of consistency deviations</figcaption>
</div>

* *Assumptions*.
    * $\langle T,R\rangle$ to express an operation, which was carried out by replica $R$ at its logical time $T$
    * All variables are assumed to have been initialized to 0
* *Commit operations to local store*. When replica A received the operation

    $$\langle 5,B\rangle : g=g+45$$

    from replica B, A has committed this operation to its local store
    * *Explain*. The operation has been made permanent and cannot be rolled back
* *Tentative update*. Replica A has three tentative update operations listed, i.e. $\langle 8,A\rangle, \langle 9,A\rangle, \langle 10,A\rangle$

    $\to$ The fact that A has three tentative operations pending to be committed is referred to as an order deviation, i.e. value 3
* *Vector clock*. A's logical clock value is currently 11, and since the last operation from B, which A had recevied had timestamp 5
    * The vector clock at A would be `(11,5)`, i.e. the first component is for A, and the second is for B
    * Similarly, the logical clock at B is `(0,8)`
* *Numerical deviation at a replica R*. Consist of two components, the number of operations at all other replicas, which have not yet been seen by R, and the sum of corresponding missed values
    * *Example*. 
        * A has not yet seen two operations of B with a total value of $70+412$ units, leading to a numerical deviation of `(2,482)`
        * B is still missing the three tentative operations at A, with a total summed value of 686, leading to B's numerical deviation to `(3,686)`
* *Usage*. Using these notions, it is possible to specify specific consistency schemes
    * *Example*.
        * Restrict order deviation by specifying an acceptable maximal value
        * Restrict two replicas to never numerically deviate by more than 1000 units
    * *Requirement*. Having consistency schemes requires that a replica knows how much it is deviating from other replicas, i.e. we need separate communication to keep replicas informed

        $\to$ The underlying assumption is that such communication is much less expensive than communication to keep replicas synchronized

## Consistent ordering of operations
**Motivation from parallel programming**. In parallel and distributed computing, multiple processes will need to share resources and access these resources simultaneously

$\to$ Researchers have sought to express the semantics of concurrent accesses, when shared resources are replicated
* *Purpose*. Deal with consistently ordering operations on shared, replicated data
* *Idea*. When tentative updates at replicas need to be committed

    $\to$ Replicas will need to reach agreement on a global, i.e. consistent ordering of the update

### Sequential consistency
**Time axis representation of process operations**. Plot the operations of a process along a time axis drawn horizontally, with time increasing from left to right

<div style="text-align:center">
    <img src="https://i.imgur.com/uyp5xnX.png">
    <figcaption>Behavior of two processes operating on the same data item</figcaption>
</div>

* *Notation*. 
    * $W_i(x)a$ denotes that the process $P_i$ writes value to $a$ to data item $x$
    * $R_i(x)b$ denotes that the process $P_i$ reads $x$ and is returned the value $b$
    * Each data item has initial value $\text{NIL}$
    * $W$ and $R$ is used when there is no confusion concerning which process is accessing data
* *Example*. Consider the diagram above
    1. The operation $W_1(x)a$ is performed first on a copy of the data store, which is local to $P_1$
        
        $\to$ Only then it is propagated to the other local copies
    2. $P_2$ later reads the value $\text{NIL}$, and sometime after that $a$, i.e. from its local copy of the store

        $\to$ It took some time to propagate the update of $x$ to $P_2$

**Sequential consistency**. An important data-centric consistency model defined by Lamport in the context of shared memory for multiprocessor systems
* *Sequentially consistent data store*. A data store, which satifies the following condition
    * The result of any execution is the same as if the read and write operations by all processes on the data store were executed in some sequential order
    * The operations of each individual process appear in this sequence in the order specified by its program
* *Interpretation*. When processes run concurrently on possibly different machines, any valid interleaving of read and write operations is acceptable behavior

    $\to$ But all processes see the same interleaving of operations
* *Notes*.
    * Nothing is said about time, i.e. there is no reference to the "most recent" write operation on a data item
    * A process "sees" the writes from all processes, but only through its own reads

**Examples**.

<div style="text-align:center">
    <img src="https://i.imgur.com/qnCgvQ5.png">
    <figcaption>A sequentially consistent data store (a) and an inconsistent data store (b)</figcaption>
</div>

* *Case 1*.
    * *Absolute time request order*.
        1. $P_1$ performs $W_1(x)a$ on $x$
        2. $P_2$ performs $W_2(x)b$ on $x$
        3. Both $P_3$ and $P_4$ read vaule $b$ from $x$
        4. Both $P_3$ and $P_4$ read vaule $a$ from $x$
    * *Conclusion*. $W_2(x)b$ appears to have taken before $W_1(x)a$, but sequential consistency is satisfied
* *Case 2*. Sequential consistency is violated since not all processes see the same interleaving of write operations
    * *Explain*. 
        * To $P_3$, it appears as if the data item has first been changed to $b$, then to $a$
        * To $P_4$, it appears as if the data item has first been changed to $a$, then to $b$

**Dubois' scenario**.

<div style="text-align:center">
    <img src="https://i.imgur.com/9gaAsGK.png">
    <figcaption>Three concurrently executing processes</figcaption>
</div>

* *Assumptions*.
    * Each variable is initialized to 0
    * All statements are assumed to be indivisible
* *Number of possible execution sequences*. 720, i.e. $6!$
* *Observations*. Different valid statement orderings produce a variety of different program results, which are allowed until the assumption of sequential consistency
    * *Contract between processes and the distributed shared data store*. Processes must accept all of these as valid results

### Causal consistency
**Causal consistency**. Represent a weakening of sequential consistency
* *Idea*. Make a distinction between events, which are potentially causally related, and those that are not
* *Concurrent operations*. Operations which are not causally related
* *Causal consistent data store*. A data store, which obeys the following conditions
    * Writes, which are potentially causally related, must be seen by all processes in the same order
    * Concurrent writes may be seen in a different order on different machines
* *Implementation*. Implementing causal consistency requires keeping track of which processes have seen which writes
    * *Explain*. We need a dependency graph of which operation is dependent on which other operations

        $\to$ Such a graph may be pruned at the moment, when dependent data is also locally stored

### Grouping operations - Release consistency
**Models of consistency for elementary-level operations**. Many consistency models are defined at the level of elementary read and write operations

$\to$ This level of granularity is for historical reasons
* *Historical reasons*. These models of have initially have been developed for shared-memory multiprocessor systems, and were actually implemented at the hardware level

**Consistency in applications**. The fine granularity of these consistency models in many cases does not match the granularity as provided by applications

$\to$ In such applications, concurrency between programs sharing data is generally kept under control through synchronization mechanisms for mutual exclusion and transactions
* *Idea*. At the program level, read and write operations are grouped by the pair of operations `ENTER_CS` and `LEAVE_CS`, i.e.
    1. A process, which has successfully executed `ENTER_CS`, will be ensured that all the data in its local store is up to date
    2. At this point, the process can safely execute a series of read and write operations on that store
    3. The process subsequently wrap things up by calling `LEAVE_CS`
* *Critical section*. Data and instructions between `ENTER_CS` and `LEAVE_CS` 
* *Consequence*. Within a program, the data, which are operated on by a series of read and write operations, are protected against concurrent accesses, which would lead to seeing different results than those of executing the series as a whole
    
    $\to$ In other words, grouping operations turns the series of read and write operations into an atomically executed unit, hence raising the level of granularity

**Semantics of `ENTER_CS` and `LEAVE_CS`**. These semantics can be formulated in terms of shared synchronization variables, or simply locks
* *Lock*. A lock has shared data items associated with it, and each share data item is associated with at most one lock
    * *Coarse-grained synchronization*. All shared data items are associated with a single lock
    * *Fine-grained synchronization*. Each shared data item has its own unique lock
* *Enter and leaving critical section*. Entering a CS means acquiring the relevant locks, and leaving a CS means releasing the locks
* *Lock owner*. Each process has a current owner, i.e. the process which last acquired it
    * *Acquiring a lock*. A process not currently owning a lock but wanting to acquire it has to send a message to the current owner, asking for ownership and the current values of the associated data item
* *Types of lock*. 
    * *Exclusive lock*. While having exclusive access to a lock, a process is allowed to perform read and write operations
    * *Nonexclusive lock*. Several processes can simultaneously have nonexclusive access to a lock, i.e. they can read but not write the associated data

        >**NOTE**. Nonexclusive access can be granted if and only if there is no other process having exclusive access

**Demanded criterias for a locking mechanism**. Following these criterias, we are effectively demanding that the usage of locks is linearized, adhering to sequential consistency
* Acquiring a lock can succeed only when all updates to its associated shared data have completed
* Exclusive access to a lock can succeed only if no other process has exclusive or nonexclusive access to that lock
* Nonexclusive access to a lock is allowed only if any previous exclusive access has been completed, including updates on the lock's associated data

**Entry consistency**. A variant of release consistency, i.e. consider the following figure

<div style="text-align:center">
    <img src="https://i.imgur.com/s730Oju.png">
    <figcaption>A valid event sequence for entry consistency</figcaption>
</div>

* *Assumptions*.
    * Each data item is associated with a lock separately
    * $L(x)$ denotes acquiring the lock for $x$, i.e. locking $x$
    * $U(x)$ denotes releasing the lock on $x$, i.e. unlocking $x$
* *Local copy of data items*. Each process has a copy of a variable, but the copy need not be instantly or automatically updated
    * *Local copy update*. When locking or unlocking a variable, a process is explicitly telling the underlying distributed system that the copies of that variable need to be synchronized
* *Proper data-lock association*. One of the programming problems with entry consistency
    * *Approach 1*. Explicitly tell the middleware which data are going to be accessed
    * *Approach 2*. Associate a unique lock with each declared object, effectively serializing invocations to such objects
* *Conclusion*. Under entry consistency, every shared variable is assigned a synchronization variable specific to it
    * *Consequence*. Only when the acquire is to variable $x$, all operations realted to $x$ need to be completed w.r.t the underlying processor

        $\to$ This allows concurrent operations of different critical sections of different shared variables to occur

### Consistency versus coherence
**Consistency versus coherence**. Consider a number of processes executing read and write operations on a set of data items
* *Consistency model*. Describe what can be expected w.r.t that set, when multiple processes concurrently operate on the data

    $\to$ The set is consistent if it adheres to the rules described by the model
* *Coherence model*. Describe what can be expected to hold for only a single data item
    * *Explain*. A data item is replicated
        
        $\to$ It is coherent when the various copies abide to the rules as defined by its associated consistency model
    * *Example*. A popular model is that of sequential consistency applied to only a single data item

        $\to$ In case of concurrent writes, all processes will eventually see the same order of updates taking place

## Eventual consistency
**Eventual consistency**. Consider a large scale distributed and replicated database, which tolerate a relatively high degree of inconsistency
* *Motivation*. To what extent processes actually operate in a concurrent fashion, and to what extent consistency needs to be guaranteed, may vary

    $\to$ There are many examples, in which concurrency appears only in a restricted form
* *Eventual consistency*. If no updates take place for a long time

    $\to$ All replicas will gradually become consistent, i.e. have the same data stored

**Examples**.
* *Example 1*. In many database systems, most processes hardly ever perform update operations, i.e. they mostly read data from the database
    * *Problem*. How fast updates should be made available to only-reading processes
    * *Solution*. In the advent of globally operating CDNs, developers often choose to propagate updates slowly

        $\to$ They implicitly assume that most clients are always redirected to the same replica, and will therefore never experience inconsistencies
* *Example 2*. In virtually all cases, Web pages are updated by a single authority, e.g. a webmaster or the actual owner of the page

    $\to$ There are normally no write-write conflicts to resolve
    * *Web page cache*. To improve efficiency, browsers and Web proxies are often configured to keep a fetched page in a local cache, and to return that page upon the next request
    * *Problem*. Web page cache may return out-dated Web pages, i.e. Web pages of older version compared to the one available at the actual Web server

        $\to$ Many users find this inconsistency acceptable to a certain degree, as long as they have access only to the same cache
        * *Consequence*. Users remain unaware of the fact that an update had taken place
* *Example 3*. Consider the DNS, whose name space is partitioned into domains, each of which is assigned to a naming authority, which acts as owner of the domain

    $\to$ Only that authority is allowed to update its part of the name space
    * *Write-write conflicts*. Conflicts resulting from two operations, which both want to perform an update on the same data, i.e. write-write conflicts, never occur
    * *Read-write conflicts*. One process wants to update a data item, while another is concurrently attempting to read the item

        $\to$ It is often acceptable to propagate an update in a lazy fashion
        * *Explain*. A reading process will see an update, only after some time has passed since the update took place

**Data stores with eventual consistency**. Have the property that, in the absence of write-write conflicts, all replicas will converge toward identical copies of each other
* *Requirements for eventual consistency*. Updates are guaranteed to propagate to all replicas
* *Resolving write-write conflicts*. Easy to solve when assuming that only a small group of processes can perform updates

    $\to$ One specific write operation is globally declared as winner, overwriting the effects of any other conflicting write operation
    * *Consequence*. Eventual consistency is often cheap to implement

# Appendix
## Discussions
**On the granularity of conits**.

**Programming conits**.

**The importance and intricacies of sequential consistency**.

**Making eventual consistency stronger**.