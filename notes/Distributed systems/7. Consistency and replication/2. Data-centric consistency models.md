<!-- TOC titleSize:1 tabSpaces:2 depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 skip:0 title:1 charForUnorderedList:* -->
# Table of Contents
- [Table of Contents](#table-of-contents)
- [Data-centric consistency models](#data-centric-consistency-models)
  - [Continuous consistency](#continuous-consistency)
    - [The notion of a conit](#the-notion-of-a-conit)
  - [Consistent ordering of operations](#consistent-ordering-of-operations)
    - [Sequential consistency](#sequential-consistency)
    - [Causal consistency](#causal-consistency)
    - [Grouping operations](#grouping-operations)
    - [Consistency versus coherence](#consistency-versus-coherence)
  - [Eventual consistency](#eventual-consistency)
- [Appendix](#appendix)
  - [Discussions](#discussions)
<!-- /TOC -->

# Data-centric consistency models
**Data store**. Traditionally, consistency has been discussed in the context of read and write operations on shared data, available by means of distributed shared memory, a distributed shared database, or a distributed file system
* *Data store*. May be physically distributed across multiple machines, with each process having access to the data from the store is assumed to have a local, or nearby, copy available of the entire store

    <div style="text-align:center">
        <img src="https://i.imgur.com/bdh4SRi.png">
        <figcaption>The general organization of a logical data store, physically distributed and replicated across multiple processes</figcaption>
    </div>

    * *Read operation*. Any operation which is not a write operation
    * *Write operation*. Any operation changing the data, i.e. such operation will be propagated to other copies

**Consistency model**. A contract between processes and the data store, i.e. if processes agree to obey certain rules, the store promises to work correctly
* *Expectation*. A process performing a read operation on an data item expects the operation to return a value, which shows the results of the latest write operation on that data
* *Consistency without global clock*. Difficult to precisely define which write operation is the last one
    * *Alternative solution*. Provide other definitions, leading to a range of consistency models, each of which restricts the values, which a read operation on a data item can return
        * *Extent of restriction*. The one with major restrictions are easy to use, whereas those with minor restrictions are generally difficult to use inpractice
        * *Trade-off*. The easy-to-use models do not perform nearly as well as difficult ones

## Continuous consistency
**Choice of consistency model**. Replicating data poses consistency problems, which cannot be solved efficiently in a general way

$\to$ Only if we loosen consistency, can there be hope for attaining efficient solutions

>**NOTE**. There are no general rules for loosening consistency, i.e. what can be tolerated exactly is highly dependent on applications

**Continuous consistency ranges**. Yu and Vahdat take a general approach to specify what inconsistencies they can tolerate, by distinguishing three independent axes for defining inconsistencies, i.e.
* *Axes for defining inconsistency*.
    * Deviation in numerical values between replicas
    * Deviation in staleness between replicas
    * Deviation w.r.t the ordering of update operations

**Deviation in numerical values between replicas**. Measuring inconsistency in terms of numerical deviations can be used by applications, for which the data have numerical semantics, e.g. stock market prices
* *Example*. The replication of records containing stock market prices, i.e. an application may specify that two copies should not deviate more than \$0.02
* *Numerical deviation types*.
    * *Absolute numerical deviation*. For example, an application may specify that two copies should not deviate more than \$0.02
    * *Relative numerial deviation*. For example, an application may specify that two copies should not deviate more than 0.5%
* *Idea*. If the numerical deviation between replicas does not violate the specified threshold, replicas would still be considered to be mutually consistent
* *Alternative interpretation*. Numerical deviation can be understood in terms of the number of updates, which have been applied to a given replica, but have not yet been seen by others
    * *Value weight*. The associated deviation, in this case, in the value is referred to as its weight

**Deviation in staleness between replicas**. Relate to the last time a replica was updated, i.e. for some applications, it can be tolerated that a replica provides old data, as long as it is not too old

$\to$ A server may receive timely updates, but may decide to propagate updates to the replicas only one in a while

**Deviation w.r.t the ordering of update operations**. There are classes of applications, in which the ordering of updates are allowed to be different at the various replicas, as long as the differences remain bounded
* *Example*. The updates are applied tentatively to a local copy, awaiting global agreement from all replicas
    * *Consequence*. Some updates may need to be rolled back and applied in a different order, before becoming permanent

>**NOTE**. Ordering deviations are much harder to grasp than the other two consistency metrics

### The notion of a conit
**Consistency unit (conit)**. Introduced by Yu and Vahdat to define inconsistencies
* *Conit*. Specify the unit, over which consistency is to be measured
    * *Example*. In stock-exchange, a conit could be defined as a record representing a single stock
* *Servers' task*. Keep the conit consistently replicated
    * *Idea*. Each replica server maintains a 2D vector clock 

**Example**. Consider the situation of keeping track of a fleet of cars
* *Problem*. The fleet owner is interested in knowing how much he pays on average for gas

    $\to$ Whenever a driver tanks gasoline, he reports the amount of gasoline which has been tanked, i.e. recorded as `g`, the price paid, i.e. recorded as `p`, and the total distance since the last time he tanked, i.e. recorded by `d`
    * *Conit*. Technically, three variables `g`,`p`, and `d` form a conit, which is replicated across two servers

      $\to$ A driver regularly reports his has usage to one of the servers by separately updating each variable

<div style="text-align:center">
    <img src="https://i.imgur.com/efFbCVG.png">
    <figcaption>An example of keeping track of consistency deviations</figcaption>
</div>

* *Assumptions*.
    * $\langle T,R\rangle$ to express an operation, which was carried out by replica $R$ at its logical time $T$
    * All variables are assumed to have been initialized to 0
* *Commit operations to local store*. When replica A received the operation

    $$\langle 5,B\rangle : g=g+45$$

    from replica B, A has committed this operation to its local store
    * *Explain*. The operation has been made permanent and cannot be rolled back
* *Tentative update*. Replica A has three tentative update operations listed, i.e. $\langle 8,A\rangle, \langle 9,A\rangle, \langle 10,A\rangle$

    $\to$ The fact that A has three tentative operations pending to be committed is referred to as an order deviation, i.e. value 3
* *Vector clock*. A's logical clock value is currently 11, and since the last operation from B, which A had recevied had timestamp 5
    * The vector clock at A would be `(11,5)`, i.e. the first component is for A, and the second is for B
    * Similarly, the logical clock at B is `(0,8)`
* *Numerical deviation at a replica R*. Consist of two components, the number of operations at all other replicas, which have not yet been seen by R, and the sum of corresponding missed values
    * *Example*. 
        * A has not yet seen two operations of B with a total value of $70+412$ units, leading to a numerical deviation of `(2,482)`
        * B is still missing the three tentative operations at A, with a total summed value of 686, leading to B's numerical deviation to `(3,686)`
* *Usage*. Using these notions, it is possible to specify specific consistency schemes
    * *Example*.
        * Restrict order deviation by specifying an acceptable maximal value
        * Restrict two replicas to never numerically deviate by more than 1000 units
    * *Requirement*. Having consistency schemes requires that a replica knows how much it is deviating from other replicas, i.e. we need separate communication to keep replicas informed

        $\to$ The underlying assumption is that such communication is much less expensive than communication to keep replicas synchronized

## Consistent ordering of operations
**Motivation from parallel programming**. In parallel and distributed computing, multiple processes will need to share resources and access these resources simultaneously

$\to$ Researchers have sought to express the semantics of concurrent accesses, when shared resources are replicated
* *Purpose*. Deal with consistently ordering operations on shared, replicated data
* *Idea*. When tentative updates at replicas need to be committed

    $\to$ Replicas will need to reach agreement on a global, i.e. consistent ordering of the update

### Sequential consistency

### Causal consistency

### Grouping operations

### Consistency versus coherence

## Eventual consistency

# Appendix
## Discussions
**On the granularity of conits**.

**Programming conits**.