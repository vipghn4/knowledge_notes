<!-- TOC titleSize:1 tabSpaces:2 depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 skip:0 title:1 charForUnorderedList:* -->
# Table of Contents
- [Table of Contents](#table-of-contents)
- [Variants of Turing machines](#variants-of-turing-machines)
  - [Multitape Turing machines](#multitape-turing-machines)
  - [Nondeterministic Turing machines](#nondeterministic-turing-machines)
  - [Enumerators](#enumerators)
  - [Equivalence with other models](#equivalence-with-other-models)
<!-- /TOC -->

# Variants of Turing machines
**Variants of the TM model**. Alternative definitions of TMs, e.g. multiple tapes or nondeterminism

$\to$ The original TM model and its reasonable variants have the same power, i.e. they recognize the same class of languages
* *Robustness of TMs*. The invariance to certain changes in the definition of TMs

    $\to$ Both finite automata and pushdown automata are robust models, but TMs have an astonishing degree of robustness

## Multitape Turing machines
**Multitape Turing machines**. Similar to an ordinary TM with several tapes, each of which has its own head for reading and writing
* *Initial tapes' content*. The input appears on tape 1, and the others start out blank
* *Transition function*. Changed to allow for reading, writing, and moving the heads on some or all of the tapes simultaneously, i.e.

    $$\delta:Q\times\Gamma^k\to Q\times\Gamma^k\times\{L,R,S\}^k$$

    * *Interpretation*. $\delta(q_i,a_1,\dots,a_k)=(q_j,b_1,\dots,b_k,L,R,\dots,L)$ means that if the machine is in state $q_i$ and heads $1$ through $k$ are reading symbols $a_1,\dots,a_k$

        $\to$ The machine goes to state $q_j$, writes symbols $b_1,\dots,b_k$, and directs each head to move left or right, or to stay put

**Equivalence to ordinary TMs**. Every multitape TM has an equivalent single-tape TM
* *Proof*. Easy to prove, i.e. the ordinary TM can be constructed by concatenating all tapes of the multitape TM and separating them by `#`

    $\to$ The location of each head in the multitape TM can be represented by marking corresponding squares
* *Consequence*. A language is Turing-recognizable if and only if some multitape TM recognizes it

## Nondeterministic Turing machines
**Nondeterministic Turing machines**. At any point in a computation, the machine may proceed according to several possibilities
* *Transition function*. Have the form

    $$\delta:Q\times\Gamma\to\mathcal{P}(Q\times\Gamma\times\{L,R\})$$

* *Machine behavior*. A tree, whose branches correspond to different possibilities of the machine
    
    $\to$ If some branch of the computation leads to the accept state, the machine accepts its input

**Equivalence to ordinary TMs**. Every nondeterministic TM has an equivalent deterministic TM
* *Proof*. Easy to prove
* *Consequence*. 
    * A language is Turing-recognizable if and only if some nondeterministic TM recognizes it
    * A language is decidable if and only if some NTM decides it

**Decider**. A NTM is a decider if all branches halt on all inputs

## Enumerators
**Brief**. Recursively enumerable language is a term used for Turing-recognizable language, which originates from enumerator

**Enumerator**. A type of TM, with an attached printer

$\to$ The TM can use the printer as an output device to print strings
* *Idea*. Everytime the TM wants to add a string to the list, it sends the string to the printer

    $\to$ If the enumerator does not halt, it may print an infinite list of strings
* *Initial tape content*. A blank input tape
* *Language enumerated by an enumerator*. The collection of all strings, which the enumerator eventually prints out

    >**NOTE**. The enumerator may generate the strings of the language in any order, possibly with repetitions

**Theorem**. A language is Turing-recognizable if and only if some enumerator enumerates it
* *Proof*. Easy to prove

## Equivalence with other models
**Brief**. Many other models of general-purpose computation have been proposed

$\to$ Some of these models are similar to TMs, but others are not
* *Shared essential feature of other models and TMs*. These models all have unrestricted access to unlimited memory

    $\to$ This distinguishes them from weaker models, e.g. finite automata and pushdown automata
* *Equivalence between models*. All models with the shared feature above are equivalent in power, so long as they satisfy reasonable requirements

**Example**. Consider the analogous situation for programming languages, i.e. there are many such languages

$\to$ However, algorithms can be programmed in all of them
* *Conclusion*. Any two computational models satisfying certain reasonable requirements can simulate one another, hence are equivalent in power

**Philosophical corollary of model equivalence**. Even though we can imagine many different computational models, the class of algorithms they describe remains the same

$\to$ This has had profound implications for mathematics