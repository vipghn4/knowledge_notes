---
title: 12. Concurrency
tags: Coding manner
---

# Table of Contents
[toc]

# 12. Concurrency
## Concurrency
**Concurrency**. A decoupling strategy which decouples "what gets done" from "when it gets done"
* *Consequence*. Improve throughput and structures of an application 
    * *Structural benefits*. Look like many little collaborating computers rather than one big main loop)
    
        $\to$ This makes the system easier to understand and offers some powerful ways to separate concerns
    * *Throughput benefits*. Some systems have response time and throughput constraints which require hand-coded concurrent solutions (i.e. parallel computations)

**Difficulties**. Programmers have to be very aware, and very careful, to make sure their concurrent programs are correct

## Myths and misconceptions
**Common myths and misconceptions**.
* *Concurrency always improve performance*. Concurrency can sometimes (not always) improve performance
    * *Explain*. Only when there's a lot of wait time which can be shared between multiple threads or multiple processors
* *Design doesn't change when writing concurrent programs*. The design of a concurrent algorithm can be remarkably different from the design of a single-threaded system
* *Understanding concurrency issues isn't important when working with a container*. We'd better know just what the container is doing and how to guard against the issues of concurrent update and deadlock described
    * *Container (example)*. Flask `app` with `threaded=True`

### Drawbacks of concurrency
* Concurrency incurs some overhead, both in performance and writing additional code
* Correct concurrency is complex, even for simple problems
* Concurrency bugs aren't usually repeatable

    $\to$ They are often ignored as something, which happens only once, instead of the true defects they are

    * *Explain*. Bugs in threaded code might exhibit their symptoms once in a thousand, or a million, executions

* Concurrency often requires a fundamental change in design strategy

## Challenges
**Challenges**. We have to manage both "what gets done" and "when it gets done"

## Concurrency defense principles
### Single responsibility principle
**Principle**. A given method / class / component should have a single reason to change (i.e. responsibility)

**Observations**. Concurrency design is complex enough to be a reason to change in its own right

$\to$ Concurrency deserves to be separated from the rest of the code

**Tricks**.
* Concurrency-related code has its own life cycle of development, change, and tuning
* Concurrency-related code has its own challenges, which are different from, and often more difficult than non-concurrency-related code
* The number of ways, in which miswritten concurrency-based code can fail, makes it challenging enough without the added burden of surrounding application code

### Corollary: limit the scope of data
**Principle**. Take data encapsulation to heart, severely limit the access of any data which maybe shared

**Tricks**.
* Two threads modifying the same field of a shared object can interfere with each other, causing unexpected behavior

    $\to$ We should use synchronization to protect a critical section in the code which uses the shared object
* We should restrict the number of critical sections
    * *Explain*. The more places shared data can get updated,
        * We will forget to protect one or more of those places
        * There will be duplication of effort required to make sure everything is effectively guarded
        * It will be difficult to determine the source of failures, which are already hard enough to find

### Corollary: use copies of data
**Principle**. A good way to avoid shared data is to avoid sharing the data in the first place
* *Solution*. 
    * *Approach 1*. Copy objects and treat them as read-only
    * *Approach 2*. Copy objects, collect results from multiple threads in these copies, then merge the result in a single thread

**The cost of extra object creations**. It's worth experimenting to find out if this is in fact a problem

### Corollary: threads should be as independent as possible
**Principle**. Attempt to partition data into independent subsets which can be operated on by independent threads, possibly in different processors
* *Ideal case*. Each thread exists in its own world, sharing no data with any other thread

## Know our library
**Principle**. Learn the basic algorithms (three belows) and understand their solutions

**Things to consider when writing threaded code**.
* Use the provided thread-safe collections
* Use the executor framework for executing unrelated tasks
* Use non-blocking solutions when possible
* Several library classes which aren't thread safe

### Thread-safe collections
**Principle**. Review the classes available to us

## Know our execution models
**Different ways to partition behavior in a concurrent application**.
* *Bound resources*. Resources of a fixed size of number used in a concurrent environment
* *Mutual exclusion*. Only one thread can access shared data or shared resource at a time

**Possible bugs**.
* *Starvation*. One or a group of threads is prohibited from proceeding for an excessively long time or forever
    * *Example*. Always letting fast-running threads run first can prevent longer running threads if there's no end to the fast-running threads
* *Deadlock*. Two or more threads waiting for each other to finish
    * *Explain*. Each thread has a resource which the other requires and neither can finish until it gets the other's resource
* *Livelock*. Similar to deadlock, except that the states of the processes involved in the livelock constantly change with regard to the other
    * *Real-life example*. Two people meet in a narrow corridor, each tries to be polite by moving aside to let other pass
    
        $\to$ They end up swaying from side to side, without making any progress
    * *Explain*. Threads aren't blocked, they are too busy responding to each other to resume work

### Producer - consumer
**Idea**.
* *Producer threads*. Create some work and place it in a buffer or queue
* *Consumer threads*. Acquire the work from the queue and complete it

**Bound resource**. The queue between the producers and the consumers
* *Solution*. 
    * Producers must wait for free space in the queue before writing
    * Consumers must wait until there is something in the queue to consume

### Readers - writers
**Idea**. Have a shared resource which primarily serves as a source of information of readers, but is occasionally updated by writers

**Starvation**. Throughput is an issue
* *Explain*. Reads must not read something a writer is updating and vice versa is a tough balancing art

    $\to$ Writers tend to block many readers for a long period of time
* *Simple approach*. Writers wait until there are no readers before writing
    * *Drawbacks*. 
        * If there are continuous readers, the writers will be starved
        * If there are frequent writers with high priority, throughput will suffer

### Dining philosophers
**Idea**. use semaphores

## Beware dependencies between synchronized methods
**Principle**. Avoid using more than one method on a shared object
* *Explain*. Dependencies between synchronized methods cause bugs in concurrent code

**Tricks**.
* *Client-based locking*. Have the client lock the server before calling the first method and release the lock after the finishing works
* *Server-based locking*. Create a method locking the server inside the server and the clients will call this method
* *Adapter server*. Create an intermediary which performs the locking

## Keep synchronized sections small
**Principle**. Keep our synchronized sections as small as possible

**Observations**. Locks are expensive since they create delays and add overhead

$\to$ We want to design our code with as few critical section as possible
* *Naive programmers*. Try to achieve this by making their critical sections very large

## Writing correct shut-down code is hard
**Principle**. Think about shut-down early and get it working early

**Temporal threads**. Writing a system, which is meant to stay live and run forever, is different from writing something which works for awhile and then shuts down gracefully
* *Consequence of bad shut-down*. A parent thread maybe in deadlock (i.e. cannot terminate) if some of its children threads doesn't shut down correctly

>**NOTE**. If we must write concurrent code which involves shutting down gracefully
>$\to$ Expect to spend much of your time getting the shut-down to happen correctly

## Testing threaded code
**Principle**. 
* *Step 1*. Write tests which have the potential to expose problems 
* *Step 2*. Run tests frequently, with different configurations and load
* *Step 3*. If tests fail, track down the failure

>**NOTE**. Don't ignore the failure just because the tests pass on a subsequent run

### Treat spurious failures as candidate threading issues
**Principle**. Don't ignore system failures as one-offs

**Observations**.
* Bugs in threaded code might exhibit their symptoms once in a thousand, or a million, executions

    $\to$ Attempts to repeat the systems can be frustratingly
* From above, developers often treat these failures as one-off (something which happens only once)

### Get our non-threaded code working first
**Principle**. Don't try to chase down non-threading bugs and threading bugs at the same time

$\to$ Make sure our code works outside of threads

### Make our threaded code pluggable
**Principle**. Write the concurrency-supporting code so that it can be urn in several configurations
* One thread, several threads, etc.
* Threaded code interacts with something which can be both real or a test double
* Execute with test doubles which run quickly, slowly, etc.
* Configure tests so that they can run for a number of iterations

### Make our code tunable
**Principle**. Find ways to time the performance of our system under different configurations
* *Explain*. Getting the right balance of threads typically requires trial and error

**Tricks**.
* Allow the number of threads to be easily tuned, even while the system is running
* Allow self-tuning based on throughput and system utilization

### Run with more threads than processors
**Principle**. Run more threads than processors or cores to encourage task swapping
* *Explain*. The more frequently we swap tasks, the more likely we encounter code which is missing a critical section or causes deadlock

### Run on different platforms
**Principle**. Run our threaded code on all target platforms early and often

### Instrument our code to try and force failures
**Principle**. Instruction our code, and force it to run in different orderings by adding calls to methods like `wait()`, `sleep()`, etc.
* *Explain*. Calling these methods can affect the order of execution

    $\to$ Increasing the odds of detecting flaws

**Frequency of threaded bugs**. It's normal for flaws in concurrent code to hide, simple tests often don't expose them
* *Explain*. A very few pathways out of many thousands of possible pathways through a vulnerable section actually fail

    $\to$ Failures might show up once every few hours, or days, or weeks

# Appendix
## Tricks and advices
**Small tricks**.
* Proving that code is correct is impractical, and testing doesn't guarantee correctness
    * *Good testing*. help minimize risk
* *Test double*. An object that can stand in for a real object in a test
    * *Intuition*. Similar to how a stunt double stands in for an actor in a movi