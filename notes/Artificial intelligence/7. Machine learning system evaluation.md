<!-- TOC titleSize:1 tabSpaces:2 depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 skip:0 title:1 charForUnorderedList:* -->
# Table of Contents
- [Table of Contents](#table-of-contents)
- [Evaluation methods](#evaluation-methods)
  - [Hold-out](#hold-out)
  - [Stratified sampling](#stratified-sampling)
  - [Repeated hold-out](#repeated-hold-out)
  - [Cross validation](#cross-validation)
  - [Leave-one-out cross-validation](#leave-one-out-cross-validation)
  - [Bootstrap sampling](#bootstrap-sampling)
  - [Validation set](#validation-set)
- [Evaluation criteria](#evaluation-criteria)
<!-- /TOC -->

# Evaluation methods
## Hold-out
**Idea**: split the dataset $D$ into two disjoint datasets $D_\text{train}$ and $D_\text{test}$ (for training and testing)

**Requirements**:
* No example in $D_\text{test}$ is used for training
* No example in $D_\text{train}$ is used for evaluation
* Examples in $D_\text{test}$ results in an unbiased evaluation

## Stratified sampling
**Target**: class distribution in the training set is approximately the same as class distribution in the test set

## Repeated hold-out
**Idea**: repeatedly evaluate the model using hold-out method

**Drawback**: some examples appear many times in the test sets

## Cross validation
**Target**: avoid the problem of examples appearing in multiple test sets

**$k$-fold cross validation**:
* Step 1: split the dataset into $k$ disjoint datasets
* Step 2: at iteration $i$ (from $1$ to $k$), choose a different to be the test set

**Sampling examples in $k$ sub-datasets**: use stratified sampling

## Leave-one-out cross-validation
**Idea**: carry out cross-validation with unit-size sub-datasets (i.e. the number of sub-datasets equals dataset size)

**Drawback**:
* No random sampling
* Cannot apply stratification
* High computational cost
* Appropriate for very small dataset

## Bootstrap sampling
**Idea** the same as cross-validation but use sampling with replacement

## Validation set

# Evaluation criteria
**Accuracy**

**Efficiency**

**Robustness**

**Scalability**

**Interpretability**

**Complexity**