<!-- TOC titleSize:1 tabSpaces:2 depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 skip:0 title:1 charForUnorderedList:* -->
# Table of Contents
- [Table of Contents](#table-of-contents)
- [Games](#games)
  - [Introduction](#introduction)
  - [Adversarial search - minimax strategy](#adversarial-search---minimax-strategy)
  - [Variations of minimax](#variations-of-minimax)
<!-- /TOC -->

# Games
## Introduction
**Types of games**:
* Deterministic and Non-deterministic:
    * Deterministic: given an input of an action, there is a fixed output
    * Non-deterministic: given an input of an action, there is a random output
* Perfect and imperfect information:
    * Perfect information: players know each other perfectly
    * Imperfect information: players know each other imperfectly

**Why we learn about game**:
* The opponents are unpredictable

$\hspace{1.0cm} \rightarrow$ We must respond to every possible opponent reply
* The time for each turn is limited

$\hspace{1.0cm} \rightarrow$ There's a trade-off between speed and accuracy
* Games have been a key driver of new techniques in CS and AI

## Adversarial search - minimax strategy
**Minimax strategy**:
* Assumptions:
    * There are 2 players $MAX$ and $MIN$ take turns taking action
    * $MAX$ tries to maximize his score
    * Player $MIN$ tries to minimize $MAX$'s score
    * Each player knows perfectly the state of the other but don't know his future action
* Goal: help $MAX$ win the game, given that he plays first

>**NOTE**: it doesn't matter who play first

* Utility function: $U(u) = \begin{cases} 1 && MAX \text{wins at state} u \\ 0 && \text{Two players draw at state } u \\ -1 && MIN \text{wins at state } u \end{cases}$
* Strategy:
    * Step 1: build a game tree satisfying:
        * Each node represents a possible state
        * If state $A$ can leads to state $B$ then there is an edge $A \to B$
    * Step 2: determine the utility of each leaf node
    * Step 3: propagate the utility values upward
        * If the depth of a node is odd (i.e. $MAX$'s turn)
        
        $\hspace{1.0cm} \rightarrow$ Set the utility value of that node to the maximum utility values of its direct children
        * If the depth of a node is even (i.e. $MIN$'s turn)
        
        $\hspace{1.0cm} \rightarrow$ Set the utility value of that node to the minimum utility values of its direct children
    * Step 4: at the root node, use minimax decision to select the move with the 

>**NOTE**: the algorithm is implemented in DFS manner

* Evaluation:
    * Complete: yes
    * Time complexity: $O(b^m)$
    * Space complexity: $O(b m)$
    * Optimal: yes

**Certainty in minimax strategy**: given that we've run the minimax strategy throughout a game tree
* The utility of a $MAX$ node is the minimum score that $MAX$ is assured to get if he arrives at that node and plays optimally in that branch of that node
    * Explain: since we assumes that $MIN$ plays optimally
* The utility of a $MIN$ node is the maximum score that $MAX$ can get if $MIN$ arrives at that node and plays optimally in that branch of that node
    * Explain: since we assumes $MAX$ plays optimally

**Evaluation function**: decide the quality of each move of $MAX$

>**NOTE**: there's a trade-off between the goodness of the evaluation function and time complexity

## Variations of minimax
**Bounded minimax**: limit the maximum depth of the game tree to reduce time complexity

**Pruning**:
* Idea: if we see some move which is too bad

$\hspace{1.0cm} \rightarrow$ We can skip considering this move and continue searching
* alpha-beta pruning:
    * Goal: remove branches which are unnecessary for evaluating a node (i.e. such branches won't be selected)
    * Idea: 
        * alpha: the minimum score that $MAX$ is assured of
        * beta: the maximum score that $MIN$ is assured of
    * Pseudo-code:
    
        ```python
        ALPHA-BETA(node, depth, alpha, beta, player):
            if depth = 0 or node is a leaf node:
                return eval(node)
            if player is MAX:
                value = -inf
                for each child of node:
                    value = max(value, ALPHA-BETA(child, depth-1, alpha, beta, MIN))
                    alpha = max(alpha, value)
                    if alpha >= beta:
                        break
                return value
            if player is MIN:
                value = inf
                for each child of node:
                    value = min(value, ALPHA-BETA(child, depth-1, alpha, beta, MAX))
                    beta = min(beta, value)
                    if alpha >= beta:
                        break
                    return value
        
        ALPHA-BETA(root, depth, -inf, inf, MAX)
        ```
    
    * Intuition: 
        * Assume that both players play optimally and the game tree is traversed DFS order
            * alpha can be seen as the current best score of $MAX$, given the traversed nodes
            * beta can be seen as the current best score of $MIN$, given the traversed nodes
        * At $MAX$'s turn, if $MAX$ evaluates a node, updates alpha and explore that alpha $\geq$ beta at some child of that node
            * $MIN$, given the traversed nodes, knows that his best result is now beta, thus why he consider alpha (i.e. the result of $MAX$'s current node), which is worse than beta ?
            
            $\hspace{1.0cm} \rightarrow$ We can prune the branch without affecting the final result of the algorithm
        * At $MIN$'s turn, if $MIN$ evaluates a node, updates beta and explore that alpha $\geq$ beta at some child of that node
            * $MAX$, given the traversed nodes, knows that his best result is now alpha, thus why he consider beta (i.e. the result of $MIN$'s current node), which is worse than alpha ?
            
            $\hspace{1.0cm} \rightarrow$ We can prune the branch without affecting the final result of the algorithm
        * In fact, we can prune the whole useless branch, but having an additional procedure to go back and prune the traversed sub-branches of that branch is not a good choice
        
        $\hspace{1.0cm} \rightarrow$ We only prune the sub-branches of that branch, which aren't traversed
    * Effect: alpha-beta pruning doesn't affect the final result
    
    $\hspace{1.0cm} \rightarrow$ It only affects the searching time (not the complexity)
    * Efficiency: the order of nodes affects much on the efficiency of alpha-beta pruning