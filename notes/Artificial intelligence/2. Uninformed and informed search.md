<!-- TOC titleSize:1 tabSpaces:2 depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 skip:0 title:1 charForUnorderedList:* -->
# Table of Contents
- [Table of Contents](#table-of-contents)
- [Uninformed search](#uninformed-search)
- [Informed (heuristic) search](#informed-heuristic-search)
  - [Introduction](#introduction)
  - [Heuristic strategies](#heuristic-strategies)
    - [Greedy strategies](#greedy-strategies)
    - [$A^*$ search](#a-search)
    - [Weighted $A^*$ search](#weighted-a-search)
- [BONUS](#bonus)
- [NEW WORD](#new-word)
<!-- /TOC -->

# Uninformed search
**BFS**:
* Completeness: yes if the maximum branching factor of the search tree is finite
* Time complexity: $O(b^d)$
    * $b$ is the maximum branching factor of the search tree
    * $d$ is the depth of the least-cost solution
* Space complexity: $O(b^d)$ (since we have to save the children of all nodes at the level we're traveling)
* Optimality: yes if the transition cost between states are uniform

**DFS**:
* Completeness: yes if the state space is finite
* Time complexity: $O(b^m)$ where $m$ is the maximum depth of the search tree (maybe infinity)
* Space complexity: $O(b m)$ (since we only have to save the children of nodes along the path we're traveling)
* Optimality: no

**Depth-limited search (DLS)**: DFS with depth limit $l$
* Completeness: yes if $l$ is chosen appropriately
* Optimal: no

**Iterative deepening search (IDS)**: combine the best of BFS and DFS
* Pseudo-code:

    ```python
    IDS(start, goal, max_depth):
        for limit = 0 to max_depth:
            if DLS(start, goal, limit):
                return true
        return false
    ```

* Completeness: yes
* Time complexity: $O(b^d)$
* Space complexity: $O(b^d)$
* Optimality: yes if the transition cost between states are uniform

**Uniform-cost search**:
* Data: for each node in "frontier" (implemented using priority queue ordered path path cost)

$\hspace{1.0cm} \rightarrow$ Save the total cost of the path from the start state to that node
* Idea: expand the frontier node with the lowest path cost

$\hspace{1.0cm} \rightarrow$ This is equivalent to Dijkstra's algorithm in general
* Evaluation:
    * Complete: yes is the step cost is positive (see Dijkstra's algorithm intuition)
    * Optimal: yes

# Informed (heuristic) search
## Introduction
**Drawback of uniform search**: ineffective in most of problems
* Solution: exploit prior knowledge
* Idea: use an evaluation function to encode prior knowledge

**Heuristics**: criteria, methods or principles for deciding which among several alternative courses of action promises to be the most effective in order to achieve some goal

**Evaluation (heuristic) function $h(u)$**: a measure to evaluate the distance of state $u$ from the goal (i.e. $h(u) = 0$ if $u$ is the goal state)

>**NOTE**: evaluation functions are problem specific functions

* Choosing evaluation function: there are plenty of available evaluation functions, many of them can be suboptimal

>**NOTE**: choosing right evaluation function has a strong effect on the result of the searching algorithm

**Heuristic search problem-solving procedure**:
* Step 1: model the problem in terms of states, operators, etc.
* Step 2: build the evaluation function
* Step 3: design a strategy for the algorithm to act at each step

## Heuristic strategies
### Greedy strategies
**Best first search**:
* Idea: equivalent to BFS combined with evaluation function
* Different from BFS: at each step, start with the node in the frontier set which optimizes the evaluation function
* Evaluation:
    * Complete: no (i.e. the algorithm may get stuck in loops)
    
    $\hspace{1.0cm} \rightarrow$ We can mark the visited nodes to prevent this
    * Time complexity: $O(b^m)$
    * Space complexity: $O(b^m)$
    * Optimal: no
* Tips: a right evaluation function can help to reduce time and space complexity significantly

**Beam search**:
* Idea: similar to best first search but only choose $k$ nodes in the frontier set to expand (i.e. not expand all)
* Advantage: reduce time and space complexity
* Disadvantage: reduce optimality

**Hill-climbing search**:
* Idea: equivalent to DFS combined with evaluation function
* Different from DFS: at each step, choose the most potential node (in terms of evaluation function) to move on

### $A^*$ search
**Idea**: preserve efficiency of Greedy search but avoid expanding path that are already expensive

**Evaluation function**: $f(n) = g(n) + h(n)$
* $g(n)$ is the cost from the start state to state $n$
* $h(n)$ is the estimated cost of cheapest path from state $n$ to the goal state
* $f(n)$ is the estimated total cost of the cheapest solution through state $n$

**$A^*$ search and other strategies**:
* Best first search: choose the node with lowest $h(n)$

$\hspace{1.0cm} \rightarrow$ Efficient but not optimal
* Uniform-cost search: choose the node with lowest $g(n)$

$\hspace{1.0cm} \rightarrow$ Optimal but not efficient

**Pseudo-code**:
* Version 1:

    <div style="text-align:center">
        <img src="https://i.imgur.com/mx0X084.png">
        <figcaption>A-star algorithm</figcaption>
    </div>

* Version 2:

    ```python
    L = [start_state]
    while true:
        if len(L) = 0:
            return failure
        u = L.pop()
        if u is goal_state:
            return true
        for v in u.neighbors:
            g(v) = g(u) + cost(u, v)
            h(v) = compute_h(v)
            f(v) = g(v) + h(v)
            L += [v]
            L.sort_by_f()
    ```

>**NOTE**: `compute_h` can be done using many ways (e.g. Manhattan, Diagonal and Euclidean heuristics)

**Composite heuristic functions**:
* Assumptions:
    * $h_1, ..., h_m$ are admissible heuristics for a given task
        * Explain: $h_i(n)$ doesn't exceed the true distance from state $n$ to the goal state
    * $h(n) = \max[h_1(n), ..., h_m(n)]$
* Conclusion:
    * $h$ is admissible
    * $h$ dominates $h_1, ..., h_m$

**Evaluation**:
* Complete: yes if $h(n)$ doesn't exceed the true distance from state $n$ to the goal state
* Time complexity: exponential
* Space complexity: keep all nodes in memory
* Optimal: yes if $h(n)$ doesn't exceed the true distance from state $n$ to the goal state

### Weighted $A^*$ search
**Idea**: use $f(n) = g(n) + \eta h(n)$ where $\eta > 0$ instead of $f(n) = g(n) + h(n)$
* $\eta$ indicates the importance of the distance from the current state to the goal state

>**NOTE**: in this note, we don't impose the constraint $\eta > 1$ (as in the original version of weighted $A^*$)

**Effects of $\eta$**:
* $\eta > 1$: the distance to goal is considered more important than the traversed distance

$\hspace{1.0cm} \rightarrow$ The algorithm will bias toward unvisited states which are closer to the goal state
* $\eta < 1$: the distance to goal is considered less important than the traversed distance

$\hspace{1.0cm} \rightarrow$ The algorithm will bias toward unvisited states which are closer to the start state

**$\eta$-sub-optimality**:
* Assumptions:
    * $s^*$ is the optimal solution
    * $s$ is a solution
    * $c(\cdot)$ is the cost function
* Conclusion: $s$ is $\eta$-sub-optimality if $c(s) \leq \eta c(s^*)$

**Performance**:
* Trade-off optimality for speed
* Be orders of magnitude faster than $A^*$ (in many domains)
* Be $\eta$-sub-optimal (i.e. the worst case is when $g(n) = \eta h(n)$, weighted $A^*$ will back to $A^*$ search)

---

# BONUS
* Branching factor of (graph theory): the number of children at each node

>**NOTE**: if this value isn't uniform

$\hspace{1.0cm} \rightarrow$ An average branching factor can be calculated
* Dominance: $h_1$ dominates $h_2$ if $h_1(n) \geq h_2(n)$ for all $n$

>**NOTE**: $h_1$ is better for $A^*$ search than $h_2$
* Explain: we wants a heuristic function which doesn't overestimate the distance from any node to the goal state

# NEW WORD
* Beam (n): chùm tia
* At the expense of something: với chi phí là cái gì đó
* Inflate (v): thổi phồng