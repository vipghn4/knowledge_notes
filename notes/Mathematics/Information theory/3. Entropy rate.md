<!-- TOC titleSize:1 tabSpaces:2 depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 skip:0 title:1 charForUnorderedList:* -->
# Table of Contents
- [Table of Contents](#table-of-contents)
- [Statistical thermodynamics background](#statistical-thermodynamics-background)
  - [Systems and surroundings](#systems-and-surroundings)
  - [The first law of thermodynamics](#the-first-law-of-thermodynamics)
  - [Entropy and the second law of thermodynamics](#entropy-and-the-second-law-of-thermodynamics)
- [NEW WORD](#new-word)
- [Stochastic process](#stochastic-process)
  - [Stochastic process](#stochastic-process-1)
  - [Markov process](#markov-process)
  - [Stochastic matrix](#stochastic-matrix)
- [Bayesian network](#bayesian-network)
  - [Introduction](#introduction)
  - [Graphical model](#graphical-model)
  - [Properties](#properties)
  - [Inference and learning](#inference-and-learning)
- [Entropy rate](#entropy-rate)
  - [Entropy rate (source information rate) of a stochastic process](#entropy-rate-source-information-rate-of-a-stochastic-process)
  - [Redundancy (information theory)](#redundancy-information-theory)
- [BONUS](#bonus)
<!-- /TOC -->

# Statistical thermodynamics background
## Systems and surroundings
**Thermodynamics**: the study of energy transfers that occur in molecules or collections of molecules

**Definitions**:
* System: the particular item or collection of items that we're interested in
* Surroundings: every that's not included in the system
* Universe: include the systems and their surroundings

**Types of system**:
* Open systems: systems which can exchange both energy and matter with its surroundings
* Closed system: systems which can exchange only energy with its surroundings
* Isolated system: systems which can exchange neither energy and matter with its surroundings

## The first law of thermodynamics
**The first law of thermodynamics**: energy cannot be created or destroyed. It can only be converted from one form to another

## Entropy and the second law of thermodynamics
**Entropy**:
* Informal definition: the disorder of a system
  
  >**NOTE**: "disorder" in terms of entropy is not about messy room and clean room
  * Right understanding of entropy: the number states a system can take on
    * State (or configuration) of a system:
      * Assumptions:
        * We have a container with some molecules bouncing around inside it
      * Conclusion:
        * A state of a system: a particular way to arrange the molecules inside the container
* Formal definition: $S = -k_B \sum_i p_i \ln p_i$
  * $p_i$ is the probability that microstate $i$ occurs during the system's fluctuations
  * $k_B$ is the Boltzmann's constant, which, like the entropy, has units of heat capacity
* The second law of thermodynamics (briefly): the entropy in the universe is constantly increasing

**The second law of thermodynamics**:
* Observation: energy cannot be created or destroyed, but it can change from more-useful forms into less-useful forms
  * Explain: in every real-world energy transfer or transformation, some amount of energy is converted to a form that’s unusable (unavailable to do work)

  >**NOTE**: in most cases, this unusable energy takes the form of heat, in the sense that heat cannot be turned into other types of energy with 100\% efficiency
* The role of heat: 
  * Role: increase the randomness (disorder) of the universe

  $\hspace{1.0cm} \rightarrow$ The system tend to move towards a more disordered configuration
  * Explain (via example):
    * Given two objects at different temperatures
    * The molecules are partitioned by speed, with those in the cooler object moving slowly and those in the hotter object moving quickly
    * If heat flows from the hotter object into the cooler object
    
    $\hspace{1.0cm} \rightarrow$ The molecules of the hot object slow down, and the molecules of the cool object speed up, until all the molecules are moving at the same average speed
    * Now, rather than having a partition of between fast and slow molecules, 
    
    $\hspace{1.0cm} \rightarrow$ We simply have one big pool of molecules going about the same speed – a less ordered situation than our starting point
* The second law of thermodynamics: every energy transfer that takes place will increase the entropy of the universe and reduce the amount of usable energy available to do work

---

# NEW WORD
* Molecule (n): phân tử
* Matter (n): vật chất
* Fluctuation (n): biến động

# Stochastic process
## Stochastic process
**Stochastic process**: a mathematical object usually defined as a collection of random variables

**Stationary stochastic process (strict form)**: $\{X_i\}$ is stationary if and only if for every $n$, $l$ and $(x_1, ..., x_n) \in \cal{X}^n$
  
$\hspace{1.0cm} P(X_i = x_i$ $\forall i \in [1, n]) = P(X_{i+l} = x_i$ $\forall i \in [1, n])$
  
  * Intuition: the distribution of the time-series is exactly the same through time

## Markov process
**Markov process** $\{X_i\}$ is a Markov process if and only if for every $n$, $i$ and $(x_1, ..., x_n) \in \cal{X}^n$
  
$\hspace{3.0cm} P(X_i = x_i|X_j = x_j$ $\forall j \in [1, n]) = P(X_i = x_i|X_{i-1} = x_{i-1})$

* Intuition: $X_i$ only depends on $X_{i-1}$

**State properties**:
* Accessibility: state $j$ is accessible from state $i$ if $\text{Pr}(X_{n_{ij}} = j|X_0 = i) = p_{ij}^{(n_{ij})} > 0$ for some $n_{ij} \geq 0$

  * Notation: $i \to j$
* Communication: state $i$ communicates with state $j$ if $i \to j$ and $j \to i$
  * Notation: $i \leftrightarrow j$
* Essential (or final) state: $i$ is final if $i \to j$ implies $j \to i$
  * Informal: a state is final if its communication class is closed
* Period: 
  * Definition: state $i$ has period $k$ if any return to state $i$ must occur in multiples of $k$ time steps
    * Formal: $k = \text{gcd } \{n > 0|\text{Pr}(X_n = i|X_0 = i) > 0\}$
  * Aperiodic state: state $i$ is aperiodic if $k = 1$
  * Aperiodic Markov chain: a Markov chain is aperiodic if all of its states are aperiodic
* Transience and recurrence:
  * Transience: state $i$ is transience if there's a non-zero probability that we'll never return to $i$
  * Recurrence (or persistent): state $i$ is recurrence if it's not transience 
    * Mean recurrence time: $M_i = E(T_i)$
      * $T_i$ is the first return time to state $i$
        * Formal: $T_i = \inf \{n \geq 1:X_n = i|X_0 = i\}$
    * Positive recurrence: state $i$ is positive recurrence if $M_i < \infty$
    * Null recurrent: state $i$ is null recurrence if $M_i \to \infty$

**Chain properties**:
* Time-invariance: a Markov process $\{X_i\}$ is time-invariant if and only if for every $\alpha, \beta \in \cal{X}$ and $n = 1, 2, ...$

$\hspace{1.0cm} P(X_n = \beta|X_{n-1} = \alpha) = P(X_2 = \beta|X_1 = \alpha)$
* Reducibility: a Markov process $\{X_i\}$ is irreducible if its state space is a single communicating class
  * Another interpretation: it's possible to get to any state from any state

## Stochastic matrix
**Other names**:
* Probability transition matrix
* Substitution matrix
* Markov matrix

**Definitions**: 
* Stochastic matrix: a square matrix used to describe the transitions of Markov chain
* Stochastic vector (or probability vector): a vector $p$ that
  * $p_i \geq 0$ $\forall i$
  * $\sum_i p_i = 1$

**Types of stochastic matrices**:
* Assumptions:
  * $P$ is a stochastic matrix
* Conclusion:
  * Right stochastic matrix: $\sum_j P_{ij} = 1$ $\forall i$
  * Left stochastic matrix: $\sum_i P_{ij} = 1$ $\forall j$
  * Doubly stochastic matrix: $\sum_j P_{ij} = 1$ $\forall i$ and $\sum_i P_{ij} = 1$ $\forall j$

>**NOTE**: in convention, row stochastic vectors and right stochastic matrices are more commonly used

# Bayesian network
## Introduction
**Other names**: 
* Bayes network
* Belief network
* Decision network
* Bayesian model
* Probabilistic directed acyclic graphical (DAG) model (a type of statistical model)

**Definition**: a probabilistic graphical model that represents a set of variables and their conditional dependencies via a DAG

**Use**: Bayesian models are ideal for 
* Taking an event that occurred 
* Predicting the likelihood that any one of several possible known causes was the contributing factor
    * Example: represent the probabilistic relationships between diseases and symptoms

**Dynamic Bayesian networks**: Bayesian networks that model sequences of variances (e.g. speech signals, protein sequences)

## Graphical model
**Bayesian network node**: represent a variable in Bayesian sense (i.e. observable quantities, latent variables, unknown parameters or hypotheses)
* Node data: each node is associated with a probability distribution
    * Input: a particular set of values for node's parent variables
    * Output: the conditional probability distribution of the variable represented by the node

**Edge**: represent a conditional dependencies 
* Explain: nodes that are connected (no path connects one node to another) represent variables that are conditionally independent

## Properties
**Considered Bayesian model**:
* $\{X_i\}_{i = 1}^N$ is a set of nodes in the Bayesian model
* ${\cal{X}}_i$ is the set of parent nodes of $i$

**Joint probability function for Bayesian model**: $P(X_1, ..., X_N) = \prod_i P(X_i|{\cal{X}}_i)$
* Usage: key component of a Bayesian model, which is used to carry out inference and learning

**Conditional independence**: each variable is conditionally independent of all its non-descendants in the graph, given the value of all its parents
* Cascade case: $Z \to Y \to X$
    * $P(X, Y, Z) = P(Z) P(Y|Z) P(X|Y)$
    
    $\hspace{1.0cm} \rightarrow P(X, Y|Z) = P(Y|Z) P(X|Y)$
    * From above, $P(X|Y, Z) = P(X|Y)$
    
    $\hspace{1.0cm} \rightarrow P(X, Z|Y) = P(X|Y, Z) P(Z|Y) = P(X|Y) P(Z|Y)$
    * From above, $Z$ and $X$ are conditionally independent given $Y$
* Common parent case: $P(X, Z, Y) = P(X|Y) P(Z|Y) P(Y)$

$\hspace{1.0cm} \rightarrow P(X, Z|Y) = P(X|Y) P(Z|Y)$ (i.e. $Z$ and $X$ are conditionally independent given $Y$)

**d-separation**:
* Definition: $X$ and $Z$ are d-separated given a set of evidence variables $E$ if every path from $X$ to $Z$ is blocked by nodes in $E$
* Consequence: if $X$ and $Z$ are d-separated given $E$

$\hspace{1.0cm} \rightarrow X$ and $Z$ are conditionally independent given $E$ (i.e. $P(X, Z|E) = P(X|E) P(Z|E)$)

## Inference and learning
**Main tasks of Bayesian networks**:
* Inferring unobserved variables
* Parameter learning
* Structure learning

# Entropy rate
## Entropy rate (source information rate) of a stochastic process
**Definitions**:
* Entropy rate: $H({\cal{X}}) = \lim_{n \to \infty} \frac{1}{n} H(X_1, ..., X_n)$ (if the limit exists)
  * Intuition: the average entropy rate per source symbol
* Entropy rate given past: $H'({\cal{X}}) = \lim_{n \to \infty} H(X_n|X_{n-1}, ..., X_1)$ (if the limit exists)
  * Intuition: the entropy rate of the last random variable given all random variables in the past

>**NOTE**: entropy rate is just another name of entropy

**Theorem**: for a stationary process, $H(X_n|X_{n-1}, ..., X_1)$ is non-increasing in $n$ and has a limit $H'(\cal{X})$

**Cesáro mean**: if $a_n \to a$ and $b_n = \frac{1}{n} \sum_{i=1}^n a_i$ then $b_n \to a$

**Theorems**:
* Statement: if $\{X_i\}$ is a stationary process
  
$\hspace{1.0cm} \rightarrow H({\cal{X}}) \approx H'({\cal{X}})$
* Explain: apply Cesáro mean with $a_n = H(X_n|X_{n-1}, ..., X_1)$
* Intuition: 
  * $H(X_1, ..., X_n) = H(X_1) + H(X_2|X_1) + ... + H(X_n|X_{n-1}, ..., X_1)$
  * As $n \to \infty$, $H(X_n|X_{n-1}, ..., X_1) \to H'({\cal{X}})$
  
  $\hspace{1.0cm} \rightarrow$ The sequence of $H(X_n|X_{n-1}, ..., X_1)$ will add up to $n H'({\cal{X}})$ approximately
  * From above, $H'({\cal{X}}) \to H({\cal{X}})$

**Entropy rate of Markov chains**:
* Entropy rate of Markov chains:
  * Assumptions:
    * ${\cal{X}} = \{X_i\}$ is a stationary Markov chain
  * Conclusion:
    * The entropy rate of $\{X_i\}$: $H({\cal{X}}) \approx H'({\cal{X}}) = \lim H(X_n|X_{n-1}, ..., X_1) = \lim H(X_n|X_{n-1}) = H(X_2|X_1)$
      * $H(X_2|X_1)$ is computed using the given stationary distribution

* Function of Markov chain:
  * Assumptions:
    * $X_1, X_2, ...$ is a stationary Markov chain with entropy rate $H(\cal{X})$
    * $Y_1, Y_2, ...$ is a stochastic process with entropy rate $H(\cal{Y})$ where $Y_i = \phi(X_i)$
  * Bayesian model interpretation: see the book Elements of information theory
  * Task: how to compute $H(\cal{Y})$
  * Observations: $X_1, X_2, ...$ is a stationary process
    
  $\hspace{1.0cm} \rightarrow Y_1, Y_2, ...$ is a stationary process
  * Solutions: 
    * Solution 1: compute $H(Y_n|Y_{n-1}, ..., Y_1)$ for each $n$ and find $\lim_{n \to \infty} H(Y_n|Y_{n-1}, ..., Y_1)$
    
    >**NOTE**: since the convergence maybe arbitrarily slow
    
    $\hspace{1.0cm} \rightarrow$ We cannot know how close we are to the limit of $H(Y_n|Y_{n-1}, ..., Y_1)$
    
    * Solution 2 (computationally cheaper): have upper and lower bounds converging to $H(\cal{Y})$ from above and below
      * Upper bound: $H(Y_n|Y_{n-1}, ..., Y_1) \to H(\cal{Y})^+$
        * Explain: $H(Y_n|Y_{n-1}, ..., Y_1)$ is a non-increasing function of $n$ that converges to $H(\cal{Y})$
      * Lower bound: 
        * Observations: 
          * $X_1$ contains all information needed from $X_0, X_{-1}, ...$ for the process $\cal{Y}$ to move on to the next state
          
          $\hspace{1.0cm} \rightarrow X_1$ contains all information needed from $Y_1, Y_0, ...$ (since $Y_i$ is a function of $X_i$) for $\cal{Y}$ to move on to the next state (i.e. $H(Y_n|Y_{n-1}, ..., Y_1, X_1) = H(Y_n|Y_{n-1}, ..., Y_1, X_1, X_0, ...)$)
          * Since each value of $X_i$ is mapped to only one value of $Y_i$
          
          $\hspace{1.0cm} \rightarrow H(Y_n|Y_{n-1}, ..., Y_1, X_1) = H(Y_n|Y_{n-1}, ..., Y_1, X_1, X_0, Y_0, ...) \leq H({\cal{Y}})$
        * Conclusion: we can use $H(Y_n|Y_{n-1}, ..., Y_1, X_1)$
  * Theorem: 
    * $H(Y_n|Y_{n-1}, ..., Y_1) \geq H({\cal{Y}}) \geq H(Y_n|Y_{n=1}, ..., Y_1, X_1)$
    * $\lim_{n \to \infty} H(Y_n|Y_{n-1}, ..., Y_1) = H({\cal{Y}}) = \lim_{n \to \infty} H(Y_n|Y_{n=1}, ..., Y_1, X_1)$

## Redundancy (information theory)
**Application**: measures the fractional difference between $H(X)$ and its maximum possible value $\log(|\cal{A}_X|)$
* $\cal{A}_X$ is the set of possible values of $X$

**Formal definition**:
* Absolute rate of a source: $R = \log |M|$ where $M$ is the message space
* Absolute redundancy of a source: $D = R - r$
  * $R$ is the absolute rate of the source
  * $r$ is the entropy rate of the source
* Relative redundancy: $\frac{D}{R}$
  * Intuition: the maximum possible data compression ratio, when expressed as the percentage by which a file size can be decreased
* Efficiency: $\frac{r}{R}$

**Informal definition**: the amount of wasted space used to transmit certain data
* Explain: in practice, we don't know the exact distribution of possible messages

$\hspace{1.0cm} \rightarrow$ We assume that the messages are equally likely and use $\log |M|$ symbols to represent each possible message

**Reduce redundancy**: use data compression

---

# BONUS
* Communicating class: $C = \{(i, j)|i \leftrightarrow j\}$
  * Closed communicating class: $C$ is closed if the probability of leaving $C$ is zero
* Ergodic process:
  * Informal definition: a stochastic process is ergodic if its statistical properties can be deduced from a single, sufficient long, random sample of process
    * Reasoning: any collection of random samples from a process must represent the average statistical properties of the entire process
  * Example: a stochastic process is ergodic in mean if $\mu_X \to E(X)$ (in squared mean), as $N \to \infty$
    * $\mu_X = \frac{1}{N} \sum_{n=1}^N X[n]$
* Stationary distribution of a Markov chain: a probability distribution that remains unchanged in the Markov chain as time progresses
  * Formal: $\pi = \textbf{P} \pi$
    * $\pi$ is the column vector representing the distribution
    * $\textbf{P}$ is the transition matrix
* Absorbing Markov chain: a Markov chain where every state can reach an absorbing state
  * Absorbing state: a state that, once entered, cannot be left