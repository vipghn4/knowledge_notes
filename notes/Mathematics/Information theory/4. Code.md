<!-- TOC titleSize:1 tabSpaces:2 depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 skip:0 title:1 charForUnorderedList:* -->
# Table of Contents
- [Table of Contents](#table-of-contents)
- [Basic definitions](#basic-definitions)
  - [Source code](#source-code)
  - [Types of code](#types-of-code)
- [Kraft inequality](#kraft-inequality)
  - [Kraft inequality](#kraft-inequality-1)
  - [McMillan inequality](#mcmillan-inequality)
- [Optimal codes](#optimal-codes)
- [Bounds on optimal code length](#bounds-on-optimal-code-length)
- [BONUS](#bonus)
<!-- /TOC -->

# Basic definitions
## Source code
**Source code**
  * Assumptions:
    * $X$ is a random variable with p.m.f $p(x)$ defined on $\cal{X}$
    * $\cal{D}^*$ is the set of finite-length strings of symbols from a $D$-ary alphabet
  * Conclusion:
    * Source code $C$ for $X$: a mapping $\cal{X} \to \cal{D}^*$
    * Notations:
      * $C(x)$ is corresponding codeword of $x$
      * $l(x)$ is the length of $C(x)$
  
**Expected length of $C(x)$**: $L(C) = \sum_{x \in \cal{X}} p(x) l(x)$

## Types of code
**Non-singular code**: if $x_1 \neq x_2$ implies $C(x_1) \neq C(x_2)$

$\hspace{1.0cm} \rightarrow C$ is non-singular

**Code extension**: a mapping from finite-length strings of $\cal{X}$ to finite-length strings of $\cal{D}$ defined by

$\hspace{1.0cm} C(x_1 x_2 ... x_n) = C(x_1) C(x_2) ... C(x_n)$ where $x_1 x_2 ... x_n$ denotes concatenation

* Notation: $C^*$


**Uniquely decodable code**: $C$ is uniquiely decodable if $C^*$ is non-singular
* Intuition: $C$ is uniquiely decodable if $C$ is a one-to-one mapping


**Prefix code (or instantaneous code)**: if no codeword is the prefix of any other codeword

**Relationships between types of code**: all codes $\supseteq$ non-singular codes $\supseteq$ uniquiely decodable codes $\supseteq$ instantaneous codes

# Kraft inequality
## Kraft inequality
* Assumptions:
  * $C$ is an instantaneous code over an alphabet of size $D$
  * $l_1, l_2, ... l_m$ are codeword lengths under $C$
* Conclusion:
  * $\sum_i D^{-l_i} \leq 1$
  * Given a set of codeword lengths satisfying the inequality above

  $\hspace{1.0cm} \rightarrow$ There exists an instantaneous code with those word lengths
* Explain:
    * Inequality:
        * Consider a complete $D$-ary tree $T$ with height $h$ and a prefix code with the set of codewords $\{c_i\}$
        * Each codeword $c_i$ can be represented as a node $v_i \in T$ so that $v_i$ and $v_j$ share no leaf node for any $i \neq j$
        * Consider $A_i$ as the set of leaf nodes rooted by $v_i$
        
        $\hspace{1.0cm} \rightarrow \sum_i |A_i| = \sum_i D^{h - l_i} \leq D^h$ where $l_i$ is the height of node $v_i$ (i.e. the length of $c_i$)
    * Equality: when we achieve the maximum number of codewords which can be represented by $T$
    
    $\hspace{1.0cm} \rightarrow \sum_i D^{h - l_i} = D^h$
    * Violation: when we achieve the maximum number of codewords which can be represented by $T$ and there's some $i \neq j$ that $c_i$ is some prefix of $c_j$
    
    $\hspace{1.0cm} \rightarrow \sum_i D^{h - l_i} > D^h$
* Usage: gives a necessary and sufficient condition for the existence of a prefix code (in Leon G. Kraft's version) or a uniquely decodable code (in Brockway McMillan's version) for a given set of codeword lengths

## McMillan inequality
* Statement: Kraft inequality also holds for any uniquely decodable code

# Optimal codes
**Problem statement**: find the prefix code with minimum expected length

**Formal**:

$\hspace{1.0cm} \text{minimize } L = \sum_i p_i l_i$

$\hspace{1.0cm} \text{subject to } \sum_i D^{-l_i} \leq 1$

**Theorem**:
  * Assumptions:
    * $X$ is a random variable
    * $H_D(X)$ is the entropy of $X$ with base $D$
      * Formal: $H_D(X) = \sum_i p_i \log_D \frac{1}{p_i}$
    * $L$ is the expected length of any instantaneous $D$-ary code for $X$
  * Conclusion:
    * $L \geq H_D(X)$ with equality if and only if $D^{-l_i} = p_i$
  * Explain: see the explaination of Kraft inequality
  * Intuition: 
    * Representing codewords by $l_1, ..., l_n$ is equivalent to introducing a prior that codeword $i$ has probability $\frac{D^{-l_i}}{\sum_j D^{-l_j}}$ to be sent
    * According to the definition of KL divergence, representing a distribution by any other distribution may lead to extra cost of representation
    
    $\hspace{1.0cm} \rightarrow$ The minimum expected cost is $H(X)$ and will be achieved whenever $\frac{D^{-l_i}}{\sum_j D^{-l_j}} = p_i$ (or equivalently $D^{-l_i} = p_i$)

**$D$-adic distributions**:
  * Assumptions:
    * $p(X)$ is a probability distribution
  * Conclusion:
    * $p$ is $D$-adic if for all $x$, there exists some integer $n$ that $p(x) = D^{-n}$
    * $L = H_D(X)$ if $p(X)$ is $D$-adic

# Bounds on optimal code length
**Expected length of optimal codes**:
* Assumptions:
    * $p$ is a source distribution
    * $A$ is a $D$-ary alphabet
    * $l^*_1, l^*_2, ..., l^*_m$ are optimal codeword lengths for $p$ and $A$
    * $L^*$ is the associated expected length of an optimal code
    
    $\hspace{1.0cm} L^* = \sum_i p_i l^*_i$
* Conclusion:
    * $H_D(X) \leq L^* < H_D(X) + 1$
* Explain: $l_i = \lceil \log \frac{1}{p_i} \rceil$

**The minimum expected codeword length per symbol**: 
* Assumptions:
  * $l(x_1, ..., x_n)$ is the length of codeword associated with $(x_1, ..., x_n)$ 
  * $L_n = \frac{1}{n} \sum p(x_1, ..., x_n) l(x_1, ..., x_n) = \frac{1}{n} E[l(X_1, ..., X_n)]$ is the expected codeword length per input symbol
  * $L^*_n$ is the optimal $L_n$
* Conclusion:
    * $\frac{H(X_1, ..., X_n)}{n} \leq L^*_n \leq \frac{H(X_1, ..., X_n)}{n} + \frac{1}{n}$
    * If $X_1, ..., X_n$ is a stationary process then $L^*_n \to H(\cal{X})$

**Wrong code**:
* Assumptions:
    * $X$ is a random variable with p.m.f $p$
    * $l(x) = \lceil \log \frac{1}{q(x)} \rceil$
* Conclusion:
    * $H(p) + D(p\|q) \leq E_p(l(X)) \leq H(p) + D(p\|q) + 1$

---

# BONUS
* Non-singular in information theory and linear algebra:
  * Linear algebra: $A$ is non-singular if each column of $A$ belongs to a distinct dimension of $\text{col } A$
  * Information theory: $C$ is non-singular if each value of $x$ corresponds to a distinct code under $C$
