<!-- TOC titleSize:1 tabSpaces:2 depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 skip:0 title:1 charForUnorderedList:* -->
# Table of Contents
- [Table of Contents](#table-of-contents)
- [The perturbed problem](#the-perturbed-problem)
- [A global inequality](#a-global-inequality)
- [Local sensitivity analysis](#local-sensitivity-analysis)
<!-- /TOC -->

# The perturbed problem
**The perturbed problem**:
* Assumptions:
    * $x \in \textbf{R}^n$
    * Problem 1:
    
    $\hspace{1.0cm} \text{minimize}$ $f_0(x)$
    
    $\hspace{1.0cm} \text{subject to}$ $f_i(x) \leq 0$ $\forall i \in [1, m]$
    
    $\hspace{3.0cm} h_i(x) = 0$ $\forall i \in [1, p]$
* A perturbed problem:

$\hspace{1.0cm} \text{minimize}$ $f_0(x)$

$\hspace{1.0cm} \text{subject to}$ $f_i(x) \leq u_i$ $\forall i \in [1, m]$

$\hspace{3.0cm} h_i(x) = v_i$ $\forall i \in [1, p]$

**Optimal value of the perturbed problem**: $p^*(u, v) = \inf \{f_0(x):\exists x \in \cal{D}, f_i(x) \leq u_i$ $\forall i \in [1, m], h_i(x) = v_i$ $\forall i \in [1, p]\}$
* The values of $p^*(u, v)$:
    * $p^*(u, v) = \infty$: perturbations of the constraints result in infeasibility
    * $p^*(0, 0)$ is the optimal value of the unperturbed problem
* Optimal value of the perturbed problem as a function: we can treat $p^*$ as a function of $u$ and $v$, i.e. $p^*: \textbf{R}^m \times \textbf{R}^p \rightarrow \textbf{R}$)

$\hspace{1.0cm} \rightarrow p^*$ gives the optimal value of the problem, as a function of perturbations to the RHS of the constraints

**Constraint relaxation**:
* Relaxed constraints: when $u_i > 0$,

$\hspace{1.0cm} \rightarrow$ The $i$-th inequality constraint is relaxed
* Tightened constraint: when $u_i < 0$,

$\hspace{1.0cm} \rightarrow$ The $i$-th inequality constraint is tightened

**Methods of perturbation**:
* Tighten or relax each inequality constraint by $u_i$
* Change the right hand side (RHS) of the equality constraint by $v_i$

# A global inequality
**A global inequality**:
* Assumptions:
    * Strong duality holds
    * The dual optimum is attained (i.e. there exists some dual optimal solution)
        * Explain: the original problem is convex, and Slater's condition is satisfied
    * $(\lambda^*, \nu^*)$ is a dual optimal of the unperturbed problem
* Conclusion: $p^*(u, v) \geq p^*(0, 0) - {\lambda^*}^T u - {\nu^*}^T v$
* Prove: direct prove
    * Let $A = \{(u, v, t):\exists x \in {\cal{D}},f_i(x) \leq u_i,i = 1,\dots,m, h_i(x) = v_i, i = 1,\dots,p, f_0(x) \leq t\}$
    * As proven in the last section, $\{(u, v, t):(\lambda^*, \nu^*, 1)^T (u, v, t) = p^*(0, 0)\}$ is the supporting hyperplane of $A$ at $(0, 0, p^*(0, 0))$
    * As proven in the last section, $A$ is a convex set

    $\hspace{1.0cm} \rightarrow \forall (u, v, t) \in A, p^*(u, v) + \lambda^{*T} u + \nu^{*T} v \geq p^*(0, 0)$
* Intuition: based on the intuition of strong duality via set of values
    * Explain: $(\lambda^*, \nu^*, 1)^T (u, v, p^*(u, v)) \geq (\lambda^*, \nu^*, 1)^T (0, 0, p^*(0, 0))$

**Sensitivity interpretations**:
* Formal: 
    * $p^*(u, v) - p^*(0, 0) \geq (\lambda^*, \nu^*, 1)^T (-u, -v, 0)$ 
    * (or) $p^*(0, 0) - p^*(u, v) \leq (\lambda^*, \nu^*, 1)^T (u, v, 0)$
* The values of $\lambda^*$:
    * Large $\lambda^*$ and $u_i < 0$ (tightening): $p^(u, v)$ is guaranteed to increase greatly
    * Small $\lambda^*$ and $u_i > 0$ (relaxing): $p^*(u, v)$ won't decrease too much
* The values of $\nu^*$:
    * $\nu^*_i$ is large and $\nu^*_i v_i < 0$: $p^(u, v)$ is guaranteed to increase greatly
    * $\nu^*_i$ is small and $\nu^*_i v_i > 0$: $p^*(u, v)$ won't decrease too much

# Local sensitivity analysis
**Theorem**:
* Assumptions:
    * $p^*(u, v)$ is differentiable at $(0, 0)$
    * $(\lambda^*, \nu^*)$ is the optimal dual variables related to the unperturbed problem
* Conclusion: if strong duality holds,
    * $\lambda^*_i = -\frac{\partial p^*(0, 0)}{\partial u_i}$
    * $\nu^*_i = -\frac{\partial p^*(0, 0)}{\partial v_i}$
* Prove: direct prove
    * Let $A = \{(u, v, t):\exists x \in {\cal{D}},f_i(x) \leq u_i,i = 1,\dots,m, h_i(x) = v_i, i = 1,\dots,p, f_0(x) \leq t\}$
    * As proven in the last section, $\{(u, v, t):(\lambda^*, \nu^*, 1)^T (u, v, t) = p^*(0, 0)\}$ is the supporting hyperplane of $A$ at $(0, 0, p^*(0, 0))$

    $\hspace{1.0cm} \rightarrow p^*(u, v)$, where $(u, v) \to (0, 0)$, can be approximated by $p^*(u, v) = p^*(0, 0) - \lambda^{*T} u - \nu^{*T} v$
    * From above, $\frac{\partial p^*(0, 0)}{\partial u_i} \approx -\lambda^*_i$ and $\frac{\partial p^*(0, 0)}{\partial v_i} \approx -\nu^*_i$
* Another interpretation: when $p^*(0, 0)$ is differentiable at $(0, 0)$ and strong duality holds

$\hspace{1.0cm} \rightarrow (\lambda^*, \nu^*)$ are exactly the local sensitivities of $p^*$ w.r.t constraint perturbation
* Intuition: use the intuition of Lagrange dual function as perturbation function

**Sensitivity analysis**:
* $u_i$ is small and negative: $p^*$ increases approximately by $-\lambda^*_i u_i$
* $u_i$ is small and positive: $p^*$ decreases approximately by $\lambda^*_i u_i$

**Application**: give a quantitative measure of how active a constraint is at the optimum $x^*$