<!-- TOC titleSize:1 tabSpaces:2 depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 skip:0 title:1 charForUnorderedList:* -->
# Table of Contents
- [Table of Contents](#table-of-contents)
- [Definitions](#definitions)
- [Making dual constraints explicit](#making-dual-constraints-explicit)
  - [Example](#example)
- [Weak duality](#weak-duality)
- [Strong duality and Slater's constraint qualification](#strong-duality-and-slaters-constraint-qualification)
  - [Slater's condition](#slaters-condition)
- [Mixed strategies for matrix games](#mixed-strategies-for-matrix-games)
  - [Zero-sum matrix games](#zero-sum-matrix-games)
  - [Analysis](#analysis)
- [BONUS](#bonus)
<!-- /TOC -->

# Definitions
**Motivation**:
* Assumptions:
    * Problem 1:
    
    $\hspace{1.0cm} \text{minimize}$ $f_0(x)$
    
    $\hspace{1.0cm} \text{subject to}$ $f_i(x) \leq 0$ $\forall i \in [1, m]$
    
    $\hspace{3.0cm} h_i(x) = 0$ $\forall i \in [1, p]$
    * $x \in \textbf{R}^n$
    * The problem domain: $\cal{D} = \bigcap_{i = 0}^m \textbf{dom}$ $f_i \cap \bigcap_{i = 1}^p \textbf{dom}$ $h_i$
        * $\cal{D} \neq \emptyset$
    * $p^*$ is the optimal value of problem 1
* Task: $g(\lambda, \nu)$ gives a lower bound for $p^*$ for each $(\lambda, \nu)$ with $\lambda \succeq 0$

$\hspace{1.0cm} \rightarrow$ Find the best lower bound among them

**The Lagrange dual problem**:
* The primal problem: problem 1
* The Lagrange dual problem associated with problem 1:

$\hspace{1.0cm} \text{maximize}$ $g(\lambda, \nu)$

$\hspace{1.0cm} \text{subject to}$ $\lambda \succeq 0$

**Dual feasible**: a pair $(\lambda, \nu)$ with $\lambda \succeq 0$ and $g(\lambda, \nu) > -\infty$

**Dual optimal**: $(\lambda^*, \nu^*) = \arg \max_{\lambda \succeq 0} g(\lambda, \nu)$
* Other name: optimal Lagrange multipliers

**Convexity of the Lagrange dual problem**: we want to maximize a concave function $g(\lambda, \nu)$ s.t. convex constraints

# Making dual constraints explicit
**Idea**:
* Observations: $\textbf{dom } g = \{(\lambda, \nu)|g(\lambda, \nu) > -\infty\}$

    $\hspace{1.0cm} \rightarrow \dim (\textbf{dom } g) < m + p$ (commonly)
* Conclusion: In many cases, we can identify $\textbf{aff } (\textbf{dom } g)$ via a set of linear equality constraints
* Consequence: we can form an equivalent problem, in which $\textbf{dom } g$ is expressed as a set of linear equality constraints

## Example
**Lagrange dual of standard form LP**:
* Primal problem:

$\hspace{1.0cm} \text{minimize}$ $c^T x$

$\hspace{1.0cm} \text{subject to}$ $A x = b$

$\hspace{3.0cm} x \succeq 0$
* Lagrange dual function: $g(\lambda, \nu) = \begin{cases} -b^T \nu && A^T \nu - \lambda + c = 0 \\ -\infty && \text{otherwise} \end{cases}$
* Equivalent problem with explicit constraints:

$\hspace{1.0cm} \text{maximize}$ $-b^T v$

$\hspace{1.0cm} \text{subject to}$ $A^T \nu - \lambda + c = 0$

# Weak duality
**Weak duality**: 
* Formal: $d^* \leq p^*$
    * $d^*$ is the best lowest bound on $p^*$, which can be obtained from the Lagrange dual function
* Weak duality for infinite $p^*$ and $d^*$:
    * If $d^* = \infty$ then $p^* = \infty$
    * If $p^* = -\infty$ then $d^* = -\infty$

**Optimal duality gap of the original problem**: $p^* - d^*$
* Usage: find a lower bound on $p^*$ when the primal problem is difficult to solve
    * Explain: the dual problem is always convex

# Strong duality and Slater's constraint qualification
**Strong duality**: $d^* = p^*$

**Existence of strong duality**: strong duality doesn't, in general, hold
* Convex optimization: for convex primal problems

$\hspace{1.0cm} \rightarrow$ Strong duality usually (but not always) holds
* Constraint qualifications: conditions on the primal problem, under which strong duality holds

## Slater's condition
**Strict feasible point**: a point $x$ that
* $f_i(x) < 0$ $\forall i \in [1, m]$
* $h_i(x) = 0$ $\forall i \in [1, p]$

**Original condition**: strong duality holds if:
* The primal problem is convex, i.e.
    * $f_i(x)$ is convex for $i \in [0, m]$
    * The problem is of the form:

    $\hspace{1.0cm} \text{minimize}$ $f_0(x)$

    $\hspace{1.0cm} \text{subject to}$ $f_i(x) \leq 0$ $\forall i \in [1, m]$

    $\hspace{3.0cm} A x = b$
* There exists an strictly feasible $x \in \textbf{relint } D$

**Refined condition**
* Assumptions:
    * $f_1, ..., f_k$ are affine
* Conclusion: strong duality holds if
    * The primal problem is convex 
    * There exists an $x \in \textbf{relint } D$ that:
        * $f_i(x) \leq 0$ $\forall i \in [1, k]$
        * $f_i(x) < 0$ $\forall i \in [k+1, m]$
        * $A x = b$

**Implication of Slater's condition**:
* Strong duality for convex problems
* There exists a dual feasible $(\lambda^*, \nu^*)$ with $g(\lambda^*, \nu^*) = d^* = p^*$

# Mixed strategies for matrix games
## Zero-sum matrix games
**Game rules**:
* Player 1 makes a choice (or move) $k \in \{1, ..., n\}$
* Player 2 makes a choice $l \in \{1, ..., m\}$
* Player 1 then makes a payment $P_{kl}$ to player 2
    * $P \in \textbf{R}^{n \times m}$ is the payoff matrix for the game

**Strategies used for each player**: mixed strategies
* Mix strategies: each player makes his choice randomly and independently of the other player's choice
* Probability distributions for random choices:
    * $\text{Pr}(k = i) = u_i$ $\forall i \in [1, n]$
    * $\text{Pr}(l = i) = v_i$ $\forall i \in [1, m]$

**The expected payoff from player 1 to player 2**: $u^T P v$
* Player 1's goal: minimize the expected payment via $u$
* Player 2's goal: maximize the expected payment via $v$

## Analysis 
**Analysis from player 1's perspective**:
* Assumptions: player 2 knows the strategy $u$ of player 1
* Observations:
    * Player 2 will choose $v$ to maximize $u^T P v$
        * Resulted expected payoff: $\sup\{u^T P v|v \succeq 0, \textbf{1}^T v = 1\} = \max_{i = 1, ..., m} (P^T u)_i$
    * From above, the best thing player 1 can do is to choose $u$ that solve the problem:
    
    $\hspace{1.0cm} \text{minimize}$ $\max_{i = 1, ..., m} (P^T u)_i$
    
    $\hspace{1.0cm} \text{subject to}$ $u \succeq 0,$ $\textbf{1}^T u = 1$
* The optimal value of player 1's problem: $p_1^*$

**Analysis from player 2's perspective**:
* Assumptions: player 1 knows the strategy $v$ of player 2
* Observations:
    * Player 1 will choose $u$ to minimize $u^T P v$
        * Resulted expected payoff: $\inf\{u^T P v|u \succeq 0, \textbf{1}^T u = 1\} = \min_{i = 1, ..., n} (P v)_i$
    * The best thing player 2 can do is to choose $v$ that solve the problem:
    
    $\hspace{1.0cm} \text{maximize}$ $\min_{i = 1..n} (P v)_i$
    
    $\hspace{1.0cm} \text{subject to}$ $v \succeq 0,$ $\textbf{1}^T v = 1$
* The optimal value of player 2's problem: $p_2^*$

**Observations**: $p_1^* \geq p_2^*$
* Prove: direct prove
    * No matter what $p_2^*$ is, $p_1^*$ is always the supermum of $u^T P v$ where $u$ is known in advance

    $\hspace{1.0cm} \rightarrow p_1^* \geq p_2^*$
* The advantage conferred on a player, by knowing the opponent's strategy: $p_1^* - p_2^* \geq 0$

**Analysis using duality**:
* Observations:
    * The problem of player 2 is the Lagrange dual problem of player 1 and vice versa
    * Strong duality holds in the case of these problems
* Conclusion: $p_1^* = p_2^*$

$\hspace{1.0cm} \rightarrow$ There's no advantage to knowing opponent's strategy

---

# BONUS
* Relative interior of a set $D$:
    * Assumptions:
        * $D \in \textbf{R}^n$ is a set of points
    * Notation: $\textbf{relint } D$
    * Relative interior and interior:
        * Interior:  $x \in \textbf{int } D$ if we can draw a small open ball around it which is itself contained in $D$
        * Relative interior: the interior of $D$ w.r.t its affine hull
    * Example of relative interior: consider a set $D$, whose dimension is $m < n$
        * $D$ is flat in $\textbf{R}^n$, hence $\textbf{int } D = \emptyset$
        * $D$ is solid in $\textbf{R}^m$, hence $\textbf{int } D \neq \emptyset$ if we consider $\textbf{R}^m$

        $\hspace{1.0cm} \rightarrow \textbf{relint } D = \textbf{int } D$ when we consider $\textbf{int } D$ in $\textbf{R}^m$