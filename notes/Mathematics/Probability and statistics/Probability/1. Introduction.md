<!-- TOC titleSize:1 tabSpaces:2 depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 skip:0 title:1 charForUnorderedList:* -->
# Table of Contents
- [Table of Contents](#table-of-contents)
- [Introduction](#introduction)
- [Interpretations of probability](#interpretations-of-probability)
  - [Introduction](#introduction-1)
  - [The frequency interpretation of probability](#the-frequency-interpretation-of-probability)
  - [The classical interpretation of probability](#the-classical-interpretation-of-probability)
  - [The subjective (or personal) interpretation of probability](#the-subjective-or-personal-interpretation-of-probability)
  - [The subjective nature of science](#the-subjective-nature-of-science)
- [Experiments and events](#experiments-and-events)
  - [Types of experiments](#types-of-experiments)
  - [The mathematical theory of probability](#the-mathematical-theory-of-probability)
- [Formulation of probability](#formulation-of-probability)
  - [Sample spaces and events](#sample-spaces-and-events)
  - [Probability](#probability)
- [Technical appendix](#technical-appendix)
  - [Probability assignment](#probability-assignment)
  - [Measure theory](#measure-theory)
- [BONUS](#bonus)
- [NEW WORD](#new-word)
<!-- /TOC -->

# Introduction
**History of probability theory**: 
* The theory started by Blaise Pascal (1623-1662) and Pierre Fermat (1601-1665), who derived exact probabilities for certain gambling problems involving dice

>**NOTE**: Some of the problems that they solved had been outstanding for about 300 years

* Numerical probability of various dice combinations had been calculated previously by Girolamo Cardano (1501-1576) and Galileo Galilei (1564-1642)
* The theory of probability has been developed steadily since 17th century and has been widely applied in diverse fields of study

**Applications**: 
* Traditional fields: probability theory is an important tool in most areas of engineering, science, and management.
* Active fields: Many research workers are actively engaged in the discovery and establishment of new applications of probability in fields such as medicine, meteorology, photography from satellites, marketing, earthquake prediction, human behavior, the design of computer systems, finance, genetics, and law.

# Interpretations of probability
## Introduction
**The interpretation of probability**: there's no scientific interpretation of probabilities is accepted by statisticians, philosophers, and other authorities

$\hspace{1.0cm} \rightarrow$ The true meaning of probability is still a highly controversial subject and is involved in many discussions related to the foundations of statistics

## The frequency interpretation of probability
**The frequency interpretation**: given some specific outcome of a process, which is repeated a large number of times under similar conditions

$\hspace{1.0cm} \rightarrow$ The probability of the outcome is the relative frequency with which that outcome would be obtained

**Drawbacks**: 
* The condition mentioned in the interpretation are too vague to serve as the basis for a scientific definition of probability
    * There's no definite indication of an actual number that would be considered "a large number"
    * The conditions aren't described precisely to carry out the process "under similar conditions"

    >**NOTE**: the conditions under which the process is carried out mustn't be completely identical for each time since the outcomes would then be the same

    $\hspace{1.0cm} \rightarrow$ The process must have some "random" features

    * There's no limit is specified for the permissible variation from some probability value (e.g. $0.5$)
* The interpretation applies only to a problem, in which there can be, at least in principle, a large number of similar repititions of a certain process

## The classical interpretation of probability
**Equally likely outcomes**: if two outcomes are equally likely to occur

$\hspace{1.0cm} \rightarrow$ They must have the same probability

**The classical interpretation**: if the outcome of some process must be one of $n$ different equally likely outcomes

$\hspace{1.0cm} \rightarrow$ The probability of each outcome is $\frac{1}{n}$

**Drawbacks**: arose when we want to develop a formal definition of probability
* The concept of equally likely outcomes is essentially based on the concept of probability which we're trying to define
* No systematic method is given for assigning probabilities to outcomes which aren't assumed to be equally likely

## The subjective (or personal) interpretation of probability
**The subject interpretation**: the probability that a person assigns to a possible outcome of some process representing his own judgement of the likelihood that the outcome will be obtained

>**NOTE**: it's appropriate to speak of a certain person's subjective probability of an outcome, rather than to speak of the true probability of that outcome

**Formalization**: if people's judgments of the relative likelihoods of various combinations of outcomes satisfy certain conditions of consistency

$\hspace{1.0cm} \rightarrow$ Their subjective probabilities of the different possible events can be uniquely determined

**Drawbacks**:
* Unless a person is simply willing to adopt a collection of judgments known to be consistent 

$\hspace{1.0cm} \rightarrow$ The requirement that a person's judgment of the relative likelihoods of an infinite number of events be completely consistent and free from contradictions doesn't seem to be humanly attainable
* The subjective interpretation provides no objective basis for two or more scientists working together to reach a common evaluation of the state of knowledge in some scientific area of common interest

## The subjective nature of science
**The subjective nature of science**: recognition of subjective interpretation of probability has the salutary effect of emphazing some of the subjective aspects of science
* A particular scientist's evaluation of the probability of some uncertain outcome must be ultimately be that's person's own evaluation based on all the evidence available

$\hspace{1.0cm} \rightarrow$ The evaluation may well be based in part on each of the interpretations above

>**NOTE**: the final assignment of numerical probabilities is the responsibility of the scientist himself

* The subjective nature of science is also revealed in
    * The actual problem which a particular scientist chooses to study from a class of problems that might have been chosen
    * Experiments that are selected in carrying out the study
    * The conclusions drawn from the experimental data

**Dependencies of the theory of probability from interpretations**: the mathematical theory of probability is developed and presented is independent from the interpretations of "probability"

$\hspace{1.0cm} \rightarrow$ This theory is correct and can be usefully applied, regardless of which interpretation of probability is used

# Experiments and events
## Types of experiments
**Experiments and event**:
* Experiment: any process, real or hypothetical in which the possible outcomes can be identified ahead of time
* Event: a well-defined set of possible outcomes of the experiment

>**NOTE**: not every set of possible outcomes will be called an event

**The probability of an event**: how likely which the outcome of the experiment is in the event
* Usage: 
    * Most useful when applied to a real experiment in which the outcome isn't known in advance
    * When applied in hypothetical experiments which provide useful tools for modeling real experiments

**A common type of hypothetical experiment**: repeating a well-defined task infinitely often under similar conditions

## The mathematical theory of probability
**Assignment of probabilities**: once probabilities have been assigned to some simple outcomes in an experiment

$\hspace{1.0cm} \rightarrow$ There's complete agreement among all authorities that the mathematical theory of probability provides the appropriate methodology for the further study of these probabilities

**Two fundamental problems in probability textbooks**:
* Methods for determining the probabilities of certain events from the specified probabilities of each possible outcome of an experiment
* Methods for revising the probabilities of events when additional relevant information is obtained

# Formulation of probability
## Sample spaces and events
**Sample space**: the set $\Omega$ of possible outcomes of an experiment

**Sample outcome (or realization)**: a point $\omega$ in $\Omega$

**Events**: subsets of $\Omega$
* Null event: event which is always false
    * Notation: $\emptyset$
* True event: event which is always true
    * Notation: $\Omega$

## Probability
**Probability axioms**:
* $P(A) \geq 0$ $\forall A$
* $P(\Omega) = 1$
* If $A_1, A_2, ...$ are disjoint then $P(\bigcup_i A_i) = \sum_i P(A_i)$

**Probability**: 
* Probability of $A$: a real number $P(A)$ assigned to every event $A$ which satisfies the probability axioms
* Probability distribution (or probability measure): $P$

# Technical appendix
## Probability assignment
**Assignment of probabilities**: it's not feasible to assign probabilities to all subsets of a sample space $\Omega$
* Bad solution: restrict the class of valid measures
* Good solution: restrict attention to a set of events called $\sigma$-algebra (or $\sigma$-field)

**Probability space**: $(\Omega, {\cal{A}}, P)$ is a probability space

>**NOTE**: the set of events must be a $\sigma$-algebra
* Explain: otherwise, they cannot be assigned a probability

## Measure theory
**A measure on a set**: a systematic way to assign a number to each suitable subset of the set
* Formal: 
    * Assumptions:
        * $f: X \to [0, \infty)$ is a function
        * ${\cal{X}}$ is where $f$ is defined on 
        * $X$ is the set of certain subsets of ${\cal{X}}$, which form a $\sigma$-algebra over $\cal{X}$
    * Conclusion: $f$ is a measure if
        * $f(x) \geq 0$ $\forall x \in X$
        * $f(\emptyset) = 0$
        * $f(\bigcup_k x_k) = \sum_k f(x_k)$ where $\{x_k\}_k$ are pairwise disjoint sets in $X$
* Interpretation: a measure on a set is assigning sizes to subsets of the set

**$\sigma$-algebra (or $\sigma$-field)**: 
* Definition: a class $\cal{A}$ satisfying
    * $\emptyset \in {\cal{A}}$
    * If $A_1, A_2, ... \in {\cal{A}}$ then $\bigcup_i A_i \in {\cal{A}}$
    * $A \in {\cal{A}}$ implies $A^c \in {\cal{A}}$
* Motivation:
    * "Algebra": closure under set operations
    * From measure theory: $\sigma$-algebra are closed under operations which one would expect for measurable sets
        * The complement of a measurable set is a measurable set
        * The countable union of measurable sets is a measurable set
* Properties:
    * $\Omega \in {\cal{F}}$
    * $A_1, A_2 \in {\cal{A}}$ implies $A_1 \cap A_2 \in {\cal{A}}$
        * Explain: $A_1 \cap A_2 =  [A_1^c \cup A_2^c]^c$
* Applications: the collections of subsets, for which a given measure is defined, is necessarily a $\sigma$-algebra

**Measurability**: the sets in a $\sigma$-field ${\cal{A}}$ are measurable 
* Measurable sets: members of ${\cal{A}}$
* Measurable space: $(\Omega, {\cal{A}})$ is a measurable space
    * Explain: $\Omega$ and a $\sigma$-algebra defined on it
    * Other notation: $(\Omega, {\cal{A}}, f)$ where $f$ is the measure function
        * Example: probability space is a measurable space with a probability measure
* Measurable map: a random variable $X$ is a measurable map $X: \Omega \to \textbf{R}$
    * Explain: $\{\omega:X(\omega) \leq x\} \in {\cal{A}}$ $\forall x$

---

# BONUS
* Best tool to visualize probability rules: Venn diagram
* Indicator function of event $A$: $I_A(\omega) = I(\omega \in A) = \begin{cases} 1 & \omega \in A \\ 0 & \omega \notin A \end{cases}$
* Monotone sets:
    * Monotone increasing sequence of sets: $\{A_i\}$ where $A_i \subset A_{i+1}$
        * Limit: $\lim_{n \to \infty} A_n = \bigcup_{i=1}^\infty A_i$
    * Monotone decreasing sequence of sets: $\{A_i\}$ where $A_i \supset A_{i+1}$
        * Limit: $\lim_{n \to \infty} A_n = \bigcap_{i=1}^\infty A_i$
* Borel $\sigma$-field: the smallest $\sigma$-field which contains all the open subsets of the real line

# NEW WORD
* Subjective (adj): chủ quan
* Salutary (adj): bổ ích