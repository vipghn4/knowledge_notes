<!-- TOC titleSize:1 tabSpaces:2 depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 skip:0 title:1 charForUnorderedList:* -->
# Table of Contents
- [Table of Contents](#table-of-contents)
- [Estimating the CDF and statistical functionals](#estimating-the-cdf-and-statistical-functionals)
  - [Empirical distribution function](#empirical-distribution-function)
  - [Statistical functionals](#statistical-functionals)
- [Technical appendix](#technical-appendix)
- [BONUS](#bonus)
<!-- /TOC -->

<!--8. Estimating the CDF and statistical functionals-->
# Estimating the CDF and statistical functionals
## Empirical distribution function
**Empirical distribution function**:
* Assumptions:
    * $X_1, ..., X_n \sim F$ are i.i.d
* Empirical distribution function $\hat{F}_n$: the CDF which puts mass $\frac{1}{n}$ at each data point $X_i$
    * Formal: $\hat{F}_n(x) = \frac{\sum_i I(X_i \leq x)}{n}$ where $I(X_i \leq x) = \begin{cases} 1 & X_i \leq x \\ 0 & X_i > x\end{cases}$ 

**Characteristics of $\hat{F}_n$**:
* Observations: for any fixed $x$, $I(X_i \leq x) \sim \text{Bernoulli}(F(x))$,

$\hspace{1.0cm} \rightarrow \sum_i I(X_i \leq x) \sim \text{Binomial}(n, F(x))$
* Conclusion: for any fixed $x$,
    * $E[\hat{F}_n(x)] = F(x)$
    * $\text{Var}[\hat{F}_n(x)] = \frac{F(x) (1 - F(x))}{n}$

**Convergence of $\hat{F}_n$**:
* MSE of $\hat{F}_n$: $\text{MSE} = \frac{F(x) (1 - F(x))}{n} \to 0$ for any fixed $x$
    * Consequence: for any fixed $x$, $\hat{F}_n(x) \overset{p}{\to} F(x)$
* Glivenko-Cantelli theorem: $\sup_x [\hat{F}_n(x) - F(x)] \overset{p}{\to} 0$
    * Explain: $\hat{F}_n$ converges uniformly to $F(x)$

## Statistical functionals
**Statistical functional $T(F)$**: any function of CDF $F$

**Linear functional**:
* Definition:
    * Continuous case: $\int r(x) dF(x)$
    * Discrete case: $\sum_j r(x_j) f(x_j)$
* Plug-in estimator for linear functional $T(F) = \int r(x) d F(x)$: $T(\hat{F}_n) = \frac{1}{n} \sum_i r(X_i)$

**Distribution of $T(\hat{F}_n)$**: ${\cal{N}}(T(F), \hat{\text{se}}^2)$ (approximately in many cases)
* Explain: in many cases, $T(\hat{F}_n)$ is a linear functional 
* Consequence: the normal-based confidence interval for $T(F)$ is $T(\hat{F}_n) \pm z_{\alpha/2} \hat{\text{se}}$

# Technical appendix
**Dvoretzky-Kiefer-Wolfowitz (DKW) inequality**: 
* Assumptions:
    * $X_1, ..., X_n$ are i.i.d from $F$
* Conclusion: for any $\epsilon > 0$, $P(\sup_x |F(x) - \hat{F}_n(x)| > \epsilon) \leq 2 e^{-2 n \epsilon^2}$
    * Explain: due to Hoeffding's inequality for Bernoulli case (i.e. $\hat{F}_n(x) \sim \text{Bernoulli}(F(x))$ for any fixed $x$)
* Usage: construct a confidence set

**A $1 - \alpha$ non-parametric confidence band (i.e. $P(F \in C_n) \geq 1 - \alpha$) for $F$**: $C_n = (L(x), U(x))$ where
* $L(x) = \max \{\hat{F}_n(x) - \epsilon_n, 0\}$
* $U(x) = \min \{\hat{F}_n(x) + \epsilon_n, 1\}$
* $\epsilon = \sqrt{\frac{1}{2n} \log \frac{2}{\alpha}}$

---

# BONUS
* Plug-in estimator of $\theta = T(F)$: $\hat{\theta}_n = T(\hat{F}_n)$
    * Explain: just plug $\hat{F}_n$ in for the unknown $F$
* Confidence band: another name for confidence set