<!-- TOC titleSize:1 tabSpaces:2 depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 skip:0 title:1 charForUnorderedList:* -->
# Table of Contents
- [Table of Contents](#table-of-contents)
- [Bayesian inference](#bayesian-inference)
  - [The Bayesian method](#the-bayesian-method)
  - [Large sample properties of Bayes' procedures](#large-sample-properties-of-bayes-procedures)
  - [Flat priors, improper priors, and non-informative priors](#flat-priors-improper-priors-and-non-informative-priors)
<!-- /TOC -->

# Bayesian inference
## The Bayesian method
**Pipeline**:
* Step 1: choose a prior $f(\theta)$ for $\theta$, which expresses our degree of beliefs about $\theta$
* Step 2: choose a statistical model $f(x|\theta)$ which reflects about beliefs about $x$ given $\theta$

>**NOTE**: $f(x|\theta)$ is used for Bayesian inference, while $f(x; \theta)$ is used for frequentist

* Step 3: compute the posterior $f(\theta|X_1, ..., X_n)$ after observing $X_1, ..., X_n$ using Bayes' rule

**Applications of simulation in computation**:
* Approximate posterior by simulation:
    * Step 1: draw $\theta_1, ..., \theta_B \sim p(\theta|x^n)$
    * Step 2: use a histogram of $\theta_1, ..., \theta_B$ to approximate the posterior $p(\theta|x^n)$
* Computing marginal distribution of $\theta_i$: $f(\theta_1|x^n) = \int f(\theta_1, ..., \theta_p|x^n) d\theta_2 ... d\theta_p$
    * Problem: in practice, computing the integral might be infeasible
    * Solution: use simulation
        * Explain: draw randomly $\theta^1, ..., \theta^B \sim f(\theta|x^n)$

## Large sample properties of Bayes' procedures
**Theorem**:
* Assumptions:
    * $\hat{\theta}$ is the MLE
    * $\hat{\text{se}} = \frac{1}{\sqrt{n I(\hat{\theta}_n)}}$
    * $C = (\hat{\theta}_n - z_{\alpha/2} \hat{\text{se}}, \hat{\theta}_n + z_{\alpha/2} \hat{\text{se}})$the asymptotic frequentist $1-\alpha$ confidence interval
* Conclusion: under appropriate regularity conditions

$\hspace{1.0cm} \rightarrow$ $f(\theta|x^n)$ is approximately ${\cal{N}}(\hat{\theta}, \hat{\text{se}}^2)$
* Consequences:
    * $\bar{\theta}_n \approx \hat{\theta}_n$
    * $C$ is an approximate $1-\alpha$ Bayesian posterior interval (i.e. $P(\theta \in C|X^n) \to 1-\alpha$)

## Flat priors, improper priors, and non-informative priors
**Big question in Bayesian inference**: where do we get the prior $f(\theta)$

**Flat prior**: $f(\theta) \propto \text{constant}$
* Transformation invariance: using flat prior for $\theta$ doesn't imply flat prior for $g(\theta)$ 
* Application: when we cannot model our belief

**Improper prior**: $\int f(\theta) d\theta = \infty$

**Jeffreys' prior**: $f(\theta) \propto I(\theta)^{1/2}$ where $I(\theta)$ is the Fisher information function
* Transformation invariant: Jeffreys' prior is transformation-invariant
* Multiple-parameter case: $f(\theta) \propto \sqrt{\det I(\theta)}$