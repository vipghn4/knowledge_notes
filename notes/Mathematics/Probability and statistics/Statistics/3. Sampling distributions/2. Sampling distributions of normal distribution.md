<!-- TOC titleSize:1 tabSpaces:2 depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 skip:0 title:1 charForUnorderedList:* -->
# Table of Contents
- [Table of Contents](#table-of-contents)
- [The chi-square distributions](#the-chi-square-distributions)
- [The $t$ distributions](#the-t-distributions)
<!-- /TOC -->

# The chi-square distributions
**The family of chi-square ($\chi^2$) distributions**: a sub-collection of the family of gamma distributions
* Usage: sampling distribution of variance estimators (based on random samples) from a normal distribution

**Motivation**:
* Assumptions:
    * $X_1, ..., X_n$ form a random sample from the normal distribution 
        * Parameters: known mean $\mu$ and unknown variance $\sigma^2$
    * $\hat{\sigma_0^2} = \frac{1}{n} \sum_i (X_i - \mu)^2$ is the MLE of $\sigma^2$
* Conclusion: chi-square distributions are used to derive the distributions of $\hat{\sigma_0^2}$ and $\frac{\hat{\sigma_0^2}}{\sigma^2}$

**$\chi^2$ distributions with $m$ degrees of freedom**: the gamma distribution with parameter $\alpha = m/2$ and $\beta = 1/2$, where $m$ is some positive number
* p.m.f: $f(x) = \begin{cases} \frac{1}{2^{m/2} \Gamma(m/2)} x^{(m/2)-1} e^{-x/2} & x > 0 \\ 0 & x \leq 0\end{cases}$
* Degrees of freedom:
    * Preference: $m$ should be positive integers

**Characteristics**:
* Mean: $E(X) = m$
* Variance: $\text{Var}(X) = 2m$
* Moment generating function: $\psi(t) = (\frac{1}{1 - 2t})^{m/2}$ for $t < \frac{1}{2}$

**Relationship to other distributions**:
* Chi-square to chi-square: if $X_i \sim \text{Chi-square}(m_i)$ then $\sum_i X_i \sim \text{Chi-square}(\sum_i m_i)$
* Standard normal to chi-square: if $X \sim {\cal{N}}(0, 1)$ then $X^2 \sim \text{Chi-square}(1)$
    * Corollary: if $X_i \sim {\cal{N}}(0, 1)$ then $\sum_i X_i^2 \sim \text{Chi-square}(m)$

# The $t$ distributions
**The family of $t$ distributions**: closely related to random samples from a normal distribution
* Usage: widely used in important problems of statistical inference

**Motivation**:
* Assumptions:
    * $X_1, ..., X_n$ form a normal distribution with mean $\mu$ and variance $\sigma^2$
    * $\sigma' = \sqrt{\frac{1}{n-1} \sum_i (X_i - \bar{X}_n)^2}$ is the corrected sample variance
* Conclusion:
    * $Z = \frac{\bar{X}_n - \mu}{\sigma / n^{1/2}} \sim \cal{N}(0, 1)$ if $\sigma$ is known
    * $Z = \frac{\bar{X}_n - \mu}{\sigma' / n^{1/2}} \sim \text{Student-t}(n-1)$ if $\sigma$ is unknown

**$t$-distribution with $m$ degrees of freedom**:
* Assumptions:
    * $Y \sim {Chi-square}(m)$
    * $Z \sim {\cal{N}}(0, 1)$
* Conclusion: $X = \frac{Z}{\sqrt{Y/m}}$ has the $t$-distribution with $m$ degrees of freedom
* p.m.f: $f(x) = \frac{\Gamma(\frac{m+1}{2})}{(m \pi)^{1/2} \Gamma(\frac{m}{2})} (1 + \frac{x^2}{m})^{-(m+1)/2}$

**Characteristics**:
* Mean: $E(X) = 0$ $\forall m > 1$
* Variance: $\text{Var}(X) = \frac{m}{m-2}$ $\forall m > 2$
* Moment generating function: not exists
* Moments: 
    * $E(|X|^k) < \infty$ $\forall k < m$
    * $E(|X|^k) \to \infty$ $\forall k \geq m$

**Relationships to other distributions**:
* Normal distribution to $t$-distribution: see the motivation part
    * Tricks: replacing $\sigma$ (unknown) by $\sigma'$ (corrected), instead of $\hat{\sigma}$ (uncorrected), will remove the dependence between $Z = \frac{\bar{X}_n - \mu}{\sigma / n^{1/2}}$ and $\sigma$
    * Plausibility: 
        * Observations:
            * $\sigma' = (\frac{n}{n-1})^{1/2} \hat{\sigma}$
            
            $\hspace{1.0cm} \rightarrow \lim_{n \to \infty} \sigma' = \hat{\sigma}$
            * From above, using $\sigma'$ won't greatly change the standard normality of $Z$
        * Conclusion: the $t$-distribution with $n-1$ degrees of freedom should be close to standard Gaussian as $n \to \infty$
* $t$-distribution to Cauchy distribution: Cauchy distribution is $t$-distribution with $1$ degree of freedom
* $t$-distribution to standard Gaussian: $t$-distribution converges to standard Gaussian as $n \to \infty$