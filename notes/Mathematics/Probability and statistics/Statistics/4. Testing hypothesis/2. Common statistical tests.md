<!-- TOC titleSize:1 tabSpaces:2 depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 skip:0 title:1 charForUnorderedList:* -->
# Table of Contents
- [Table of Contents](#table-of-contents)
  - [The Wald test](#the-wald-test)
  - [Pearson's $\chi^2$ test for multinomial data](#pearsons-chi2-test-for-multinomial-data)
  - [The permutation test](#the-permutation-test)
  - [Multiple testing](#multiple-testing)
- [Appendix](#appendix)
  - [The Neyman-Pearson lemma](#the-neyman-pearson-lemma)
  - [The Student-t test](#the-student-t-test)
  - [Likelihood ratio test](#likelihood-ratio-test)
- [BONUS](#bonus)
<!-- /TOC -->

## The Wald test
**Hypotheses**: $H_0: \theta = \theta_0$ and $H_1: \theta \neq \theta_0$

**The Wald test**:
* Assumptions:
    * $\theta$ is a scalar parameter
    * $\hat{\theta}$ is an estimate of $\theta$
        * $\frac{\hat{\theta} - \theta_0}{\hat{\text{se}}} \to {\cal{N}}(0, 1)$ (in distribution) (i.e. asymptotically normal)

        >**NOTE**: be careful that $\hat{\theta}$ is assymptotically normal about $\theta_0$, not about the true $\theta$

        * $W = \frac{\hat{\theta} - \theta_0}{\hat{\text{se}}}$
    * $\hat{\text{se}}$ is the estimated standard error of $\hat{\theta}$
* Tested hypothese: $H_0: \theta = \theta_0$ and $H_1: \theta \neq \theta_0$
* The size $\alpha$ Wald test: reject $H_0$ then $|W| > z_{\alpha/2}$
    * Explain: under $H_0$, $P_{\theta_0}(|W| > z_{\alpha/2}) \to \alpha$ as $n \to \infty$

    $\hspace{1.0cm} \rightarrow$ The test size is $\alpha$

**Power of Wald test**:
* Assumptions: 
    * $\theta_* \neq \theta_0$ is the true value of $\theta$
    * $\Phi(\cdot)$ is the cdf of ${\cal{N}}(0, 1)$
    * $W^* = \frac{\theta_0 - \theta_*}{\hat{\text{se}}}$
* The power of Wald test: $\beta(\theta_*) \approx 1 - \Phi(W^* + z_{\alpha/2}) + \Phi(W^* - z_{\alpha/2})$
    * Explain: in fact, $\beta(\theta_*) = 1 - F(W^* + z_{\alpha/2}) + F(W^* - z_{\alpha/2})$ where $F$ is the c.d.f of $\theta$ (if we treat $\theta$ as a random variable)
* Corollary:
    * $\beta(\theta_*)$ is large if $\theta_*$ is far from $\theta_0$
    * $\beta(\theta_*)$ is large if $n$ is large
        * Explain: $\hat{\text{se}} \to 0$ as $n \to \infty$

**Wald test and confidence interval**: 
* Assumptions:
    * $\hat{\theta}$ is an estimate of $\theta$
    * $H_0: \theta = \theta_0$ and $H_1: \theta \neq \theta_0$ are hypotheses
    * $C = (\hat{\theta} - \hat{\text{se}} z_{\alpha/2}, \hat{\theta} + \hat{\text{se}} z_{\alpha/2})$
* Observation: the size $\alpha$ Wald test rejects $H_0$ if and only if $\theta_0 \notin C$
* Conclusion: testing $H_0$ is equivalent to checking whether $\theta_0$ is in the confidence interval

**Applications**: compare two values
* Compare two prediction algorithms
    * Assumptions:
        * $X \sim \text{Binomial}(m, p_1)$ is the number of errors of algorithm 1
        * $Y \sim \text{Binomial}(n, p_2)$ is the number of errors of algorithm 2
    * Naive comparison strategy: test whether $p_1 = p_2$
    * Paired comparsion: 
        * Assumptions:
            * $X_i = 1$ if algorithm 1 is correct on test case $i$, otherwise $0$
            * $Y_i = 1$ if algorithm 2 is correct on test case $i$, otherwise $0$
            * $\delta = E(D_i)$ where $D_i = X_i - Y_i$
        * Strategy: test $H_0: \delta = 0$ and $H_1: \delta \neq 0$
* Compare two means
    * Assumptions:
        * $X_1, ..., X_m$ form a random sample from a distribution with mean $\mu_1$
        * $Y_1, ..., Y_n$ form a random sample from a distribution with mean $\mu_2$
        * $\delta = \mu_1 - \mu_2$
    * Task: test $H_0: \delta = 0$ and $H_1: \delta \neq 0$

## Pearson's $\chi^2$ test for multinomial data
**Hypotheses**: $H_0: \textbf{p} = \textbf{p}_0$ and $H_1: \textbf{p} \neq \textbf{p}_0$ where $\textbf{p}, \textbf{p}_0 \in \textbf{R}^k$ are probability vectors

**Pearson's $\chi^2$ test statistic**:
* Assumptions:
    * $X = (X_1, ..., X_k)$ has multinomial distribution with p.f $f(x_1, ..., x_k; p)$
    * $\hat{\textbf{p}}$ is the MLE of $\textbf{p}$ (i.e. $\hat{\textbf{p}}_k = \frac{n_k}{n}$)
    * $\textbf{p}_0$ is a probability vector
    * Tested hypotheses: $H_0: \textbf{p} = \textbf{p}_0$ and $H_1: \textbf{p} \neq \textbf{p}_0$
* Pearson's $\chi^2$ statistic: $T = \sum_j \frac{(X_j - n p_{0j})^2}{n p_{0}}$

**Theorem**: under $H_0$, $T \to \text{Chi-square}(k-1)$ (in distribution)
* Consequences:
    * The level $\alpha$ test: reject $H_0$ if $T > \chi^2_{k-1, \alpha}$
        * $\chi^2_{k, \alpha} = F^{-1}(1-\alpha)$
        * $F$ is the c.d.f of $\text{Chi-square}(k)$
    * p-value: $P(\chi^2_k > t)$ where $t$ is the observed $T$

## The permutation test
**Hypotheses**:
* Assumptions:
    * $X_1, ..., X_m \sim F_X$
    * $Y_1, ..., Y_n \sim F_Y$
* Tested hypotheses: $H_0: F_X = F_Y$ and $H_1: F_X \neq F_Y$

**Naive idea of the permutation test**:
* Assumptions:
    * $N = m + n$
    * $T(X_1, ..., X_m, Y_1, ..., Y_n)$ is some test statistic
        * $T_1, ..., T_{N!}$ are values of $T$ for all $N!$ permutations of $X_1, ..., X_m, Y_1, ..., Y_n$
        * $T_\text{obs}$ is the observed $T$
    * $P_0$ is a distribution over $T_1, ..., T_{N!}$
        * $P_0(T_i) = \frac{1}{N!}$
* Test: reject $H_0$ when $T$ is large
    * p-value: $P_0(T > t_\text{obs}) = \frac{1}{N!} \sum_i I(T_i > t_\text{obj})$
* Permutation distribution of $T$: $P_0$

**The permutation test**:
* Motivating problem: it's not practical to evaluate all $N!$ permutations
    * Solution: approximate the algorithm by random sample from $T_1, ..., T_{N!}$
* Procedure:
    * Step 1: compute $t_\text{obs}$
    * Step 2: randomly permute the data
    * Step 3: compute $T$ using the permuted data
    * Step 4: repeat step 2 - 3 for $B$ times to obtain $T_1, ..., T_B$
    * Step 5: approximate p-value by $\frac{1}{B} \sum_i I(T_i > t_\text{obj})$

**Applications**: for small samples
* Explain: in large samples, the permutation test usually gives similar results to a test, which is based on large sample theory

## Multiple testing
**Problem**: 
* Assumptions:
    * For $i=1,...,m$, conduct a test:
        * $H_{0, i}$ and $H_{1, i}$ are hypotheses
        * $P_i$ is p-value for this test
* Problem: if each test has level $\alpha$
    * The chance of a false  rejection of each $H_{0, i}$ is $\alpha$
    * The chance of at least one false rejection is much higher
        * Explain: $P(\text{at least one false rejection}) = 1 - (1 - \alpha)^m$

**The Bonferroni method**: given p-values $P_1, ..., P_m$, reject $H_{0, i}$ if $P_i < \alpha/m$
* Idea: control the probability of a single false rejection
* Probability of type I eror:
    * Assumptions:
        * $R_i$ is the event that test $i$ results in type I error
    * Conclusion:
        * Upper bound on $P(\bigcup_i R_i)$: $P(\bigcup_i R_i) < \alpha$ 
            * Explain: $P(\bigcup_i R_i) \leq \sum_i P(R_i) < \alpha$ 
        * Limit of $P(\bigcup_i R_i)$: $P(\bigcup_i R_i) \to 1 - \exp(-\alpha)$
            * Explain: $1 - (1 - \frac{\alpha}{m})^m \to 1 - \exp(-\alpha)$ as $m \to \infty$
* Drawback: $H_{0, i}$ is only rejected when $P_i < \alpha/m$ (i.e. we impose a very strong prior that $H_{0, i}$ is true)
    * Consequence: low power when there are many tests
    * Solution: control the FDR

**The Benjamini-Hochberg (BH) method**:
* Idea: control the fraction of false discoveries (more reasonable than Bonferroni's)
* Assumptions:
    * $P_{(1)} < ... < P_{(m)}$ are ordered p-values
    * $C_m = \begin{cases} 1 & P_{(1)}, ..., P_{(m)} \text{ are independent} \\ \sum_{i=1}^m 1/i & \text{otherwise}\end{cases}$
    * $l_i = \frac{i}{C_m m} \alpha$ and $R = \max\{i: P_{(i)} < l_i\}$
    * $t = P_{(R)}$
* Test: reject all $H_{0, i}$, for which $P_i \leq t$
* BH rejection threshold: $t$
* FDR: $\text{FDR} \leq \frac{m_0}{m} \alpha \leq \alpha$ regardless of
    * How many nulls are true
    * The distribution of the p-values when the null is false

**Applications**: data mining

# Appendix
## The Neyman-Pearson lemma
**Neyman-Pearson lemma**:
* Assumptions:
    * $H_0: \theta = \theta_0$ and $H_1: \theta = \theta_1$ are hypotheses
    * $T = \frac{{\cal{L}}(\theta_1)}{{\cal{L}}(\theta_0)}$
        * ${\cal{L}}(\theta) = \prod_i f(x_i; \theta)$ is the likelihood function
    * $k$ is a chosen number so that $P_{\theta_0}(T > k) = \alpha$
* Most powerful test with size $\alpha$: reject $H_0$ when $T > k$
    * "Most powerful": among all tests with size $\alpha$, this test maximizes $\beta(\theta_1)$

## The Student-t test
**Hypotheses**: 
* Assumptions:
    * $X_1, ..., X_n \sim {\cal{N}}(\mu, \sigma^2)$
        * $\theta = (\mu, \sigma^2)$ is the parameter vector
    * $T = \frac{\bar{X}_n - \mu_0}{S_n/\sqrt{n}}$ where $S_n^2$ is the sample variance
* Tested hypotheses: $H_0: \mu = \mu_0$ and $H_1: \mu \neq \mu_0$ where $\mu$

**Test procedure**:
* Observations:
    * For large $n$ and under $H_0$, $T \to {\cal{N}}(0, 1)$ (in distribution)
    * Under $H_0$, $T \sim \text{Student-t}(n-1)$
* Level-$\alpha$ t-test: reject $H_0$ when $|T| < t_{n-1, \alpha/2}$

**Applications**: when the sample size is small

## Likelihood ratio test
**Hypotheses**: 
* Assumptions:
    * $\theta = (\theta_1, ..., \theta_q, \theta_{q+1}, ..., \theta_r)$
* Tested hypotheses: $H_0: (\theta_{q+1}, ..., \theta_r) = (\theta_{0, q+1}, ..., \theta_{0, r})$ and $H_1: (\theta_{q+1}, ..., \theta_r) \neq (\theta_{0, q+1}, ..., \theta_{0, r})$

**Likelihood ratio statistic**:
* Assumptions: 
    * $\hat{\theta}$ is the MLE of $\theta$
    * $\hat{\theta}_0$ is the MLE of $\theta$ under $H_0$
* Conclusion:
    * Likelihood ratio statistic: $\lambda = 2 \log \frac{\sup_{\theta \in \Theta} {\cal{L}}(\theta)}{\sup_{\theta \in \Theta_0} {\cal{L}}(\theta)} = 2 \log \frac{{\cal{L}}(\hat{\theta})}{{\cal{L}}(\hat{\theta}_0)}$
    * Lieklihood ratio test: reject $H_0$ when $\lambda(x^n) > \chi^2_{r-q, \alpha}$

**Level of significance**: $\alpha$ (asymptotically) 
* Explain: under $H_0$, $2 \log \lambda(x^n) \to chi^2_{r-q}$

---

# BONUS
* False discovery rate (FDR):
    * Assumptions:
        * $V$ is the number of false null rejections
        * $R$ is the number of null rejections
    * False discovery proportion: $\text{FPD} = \begin{cases} V/R & R > 0 \\ 0 & R = 0\end{cases}$
        * Intuition: proportion of null rejections which are incorrect
    * False discovery rate: $\text{FDR} = E(\text{FDP})$