<!-- TOC titleSize:1 tabSpaces:2 depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 skip:0 title:1 charForUnorderedList:* -->
# Table of Contents
- [Table of Contents](#table-of-contents)
- [Hypothesis testing and p-values](#hypothesis-testing-and-p-values)
  - [Definitions and terminologies](#definitions-and-terminologies)
    - [Hypotheses](#hypotheses)
    - [Rejection region](#rejection-region)
    - [Hypothesis testing](#hypothesis-testing)
    - [p-values](#p-values)
  - [Problems with definitions and terminologies](#problems-with-definitions-and-terminologies)
  - [Definition of rejection](#definition-of-rejection)
  - [Definition of significance](#definition-of-significance)
  - [Choosing test procedure](#choosing-test-procedure)
  - [Tests and confidence sets](#tests-and-confidence-sets)
- [BONUS](#bonus)
- [NEW WORD](#new-word)
<!-- /TOC -->

# Hypothesis testing and p-values
## Definitions and terminologies
### Hypotheses
**Null hypothesis and alternative hypothesis**:
* Null hypothesis: $H_0: \theta \in \Theta_0$
    * Meaning: the hypothesis to be tested (i.e. whether to accept or reject)
* Alternative hypothesis: $H_1: \theta \in \Theta_1$
    * Meaning: the hypothesis to alternate $H_0$ in case $H_0$ is rejected

**Types of hypothesis**:
* Simple hypothesis $H_i$: $|\Theta_i| = 1$
    * Example: $\theta = \theta_i$
* Composite hypothesis $H_i$: $|\Theta_i| > 1$ 
    * Example: $\theta > \theta_i$ or $\theta < \theta_i$

### Rejection region
**Rejection region $R$**:
* Definition:
    * $X \in R \implies$ reject $H_0$
    * $X \notin R \implies$ retain (do not reject) $H_0$
* Usual form: $R = \{x:T(x) > c\}$
    * Test statistic: $T$
    * Critical value: $c$

**Power function of a test with rejection region $R$**: $\beta(\theta) = P_\theta(X \in R)$
* Interpretation: the probability of rejecting $H_0$, given the true parameter is $\theta$
* Ideal power function: $\beta(\theta) = \begin{cases} 0 & \theta \in \Theta_0 \\ 1 &\theta \in \Theta_1\end{cases}$

**Statistical power**:
* Power of a test: $\beta(\theta \in \Theta_1)$
    * Interpretation: the probability of "true negative"
* Usages:
    * Determine the minimum sample size
    * Compare different tests

**Statistical size**:
* Size of a test: $\alpha = \sup_{\theta \in \Theta_0} \beta(\theta)$
    * Interpretation: the maximum probability, over $\theta \in \Theta_0$, of "false positive"
* Significant level of a test: a test has level $\alpha$ if its size isn't greater than $\alpha$
    * Interpretation: an upper bound for false positive rate

### Hypothesis testing
**Hypothesis testing problem formulation**: find an appropriate test statistic and an appropriate critical value to test $H_0$
* Idea: we retain $H_0$ unless there is strong evidence to reject $H_0$

>**NOTE**: often, estimation and confidence intervals are better tools

$\hspace{1.0cm} \rightarrow$ Use hypothesis testing only when we want to test a well-defined hypothesis

* Objective: find the most powerful tests

>**NOTE**: this is hard, most powerful tests don't even exist in many cases

**Test (or test procedure)**: a procedure for deciding whether $H_0$ or $H_1$ is true

**Types of test**:
* One-sided test: 
    * $H_0: \theta \leq \theta_0$ and $H_1: \theta > \theta_0$
    * (or) $H_0: \theta \geq \theta_0$ and $H_1: \theta < \theta_0$
* Two-sided test (most common): $H_0: \theta = \theta_0$ and $H_1: \theta \neq \theta_0$

**Hypothesis testing errors**:
* Type I error: rejecting $H_0$ when $H_0$ is true
    * Other name: false positive
* Type II error: rejecting $H_1$ when $H_1$ is true
    * Other name: false negative

**Common tests**:
* The Wald test
* The $\chi^2$ test
* The permutation test
* The likelihood ratio test 

### p-values
**Problem**: reporting "reject $H_0$" or "retain $H_0$" is not very informative
* Solution: report, for every level of significant $\alpha$, whether the test rejects $H_0$

**p-value**: the smallest level $\alpha$, at which the test rejects $H_0$
* Assumptions:
    * $R_\alpha$ is rejection region of a size $\alpha$ test 
* Conclusion: $\text{p-value} = \{\alpha:T(X^n) \in R_\alpha\}$

>**NOTE**: $\text{p-value} \neq P(H_0|X^n)$

**Interpretation**: if our test is to reject $H_0$ if and only if $T(X^n) \geq c_\alpha$

$\hspace{1.0cm} \rightarrow \text{p-value} = \sup_{\theta \in \Theta_0} P_\theta[T(X^n) \geq T(x^n)]$

* Informal: p-value is the probability, under $H_0$, of observing $T(X^n)$ equal or more extreme than $T(x^n)$

**Meaning of p-value**: p-value is a measure of the evidence against $H_0$
* Explain: the smaller p-value, the stronger evidence against $H_0$
* Usual scientific evidence scale:
    * $< 0.01$: very strong evidence against $H_0$
    * $0.01 - 0.05$: strong evidence against $H_0$
    * $0.05 - 0.1$: weak evidence against $H_0$
    * $> 0.1$: little or no evidence against $H_0$
* Reasons for large p-value:
    * $H_0$ is true
    * (or) $H_0$ is false, but the test has low power

**Properties**:
* (important) if $T(X)$ has a continuous distribution, under $H_0: \theta = \theta_0$, $\text{p-value} \sim \text{Uniform}(0, 1)$

**Reporting a hypothesis testing result**:
* Assumptions:
    * $\text{p-value} \leq p$
* Report: the result is statistically significant at $p \times 100 \%$ percent level
    * Meaning: $H_0$ would be rejected if we used a size $\alpha = 0.05$ test

>**NOTE**: a result might be statistically significant but the size of effect might be small

$\hspace{1.0cm} \rightarrow$ It's wise to report a confidence interval as well

## Problems with definitions and terminologies
## Definition of rejection
**Asymetry between $H_0$ and $H_1$**: 
* Asymetry in terminology regarding to choosing between hypothese: both choices are stated relative to $H_0$
    * Explain: we decide to reject $H_0$, or not reject $H_0$
* History:
    * When hypothesis testing was first being developed

    $\hspace{1.0cm} \rightarrow$ There was controversy over whether $H_1$ should be formulated
    * Focus centered on $H_0$, and whether or not to reject them

**The operation meaning of rejection**: never been defined clearly
* "do not reject $H_0$": 
    * Not mean we should accept $H_0$ as true in any sense
    * Not mean we are necessarily more confidence that $H_0$ is true than that it's false
* "reject $H_0$":
    * Not mean we are more confident that $H_0$ is false than it's true

**Roots of problem**: hypothesis testing is set up as if it were a statistical decision problem without loss function (or utility function)

$\hspace{1.0cm} \rightarrow$ We don't weight the relative likelihoods of $H_0$ and $H_1$ against the costs (or benefits) of choosing them

>**NOTE**: many, but not all, of the popular testing procedures have interpretations in the framework of decision problems

## Definition of significance
**Definition of significance level in some materials**: 
* Level of significance for a test: the probability of type I error 
* Drawbacks:
    * If $H_0$ is simple: this definition can be easily understood
        * Explain: $\beta(\theta)$ is well-defined since $|\Theta_0| = 1$
    * If $H_0$ is composite: this definition is ill-defined
        * Explain: $\beta(\theta)$ is different for each $\theta \in \Theta_0$

**Definition of significance level in this materials**: each test has one size but infinitely many levels of significance
* Special cases:
    * A test may have well-defined significance level $\alpha_0$ but its size cannot be computed

    $\hspace{1.0cm} \rightarrow$ We can call it a level $\alpha_0$ test, wihtout being able to compute its size exactly


## Choosing test procedure
**Objective of test choosing**:
* Probability of errors:
    * Type I error: $\sum_{\theta \in \Theta_0} \beta(\theta)$
    * Type II error: $\sum_{\theta \in \Theta_1} [1 - \beta(\theta)]$
* Objective: 
    * $\beta(\theta)$ is large for $\theta \in \Theta_1$
    * $\beta(\theta)$ is small for $\theta \in \Theta_0$

**Balancing error rate between type I and type II**:
* Observations: if we choose test $\delta$ to make $\beta(\theta)$ small for $\theta \in \Theta_0$, $\beta(\theta)$ will usually be small for $\theta \in \Theta_1$ as well

$\hspace{1.0cm} \rightarrow$ We need to balance the two error rates
* Solution 1: choose $\alpha_0 \in (0, 1)$, require $\beta(\theta) \leq \alpha_0$ $\forall \theta \in \Theta_0$, and maximize $\beta(\theta)$ over $\theta \in \Theta_1$
    * Statistical interpretation: choose a test whose size isn't  greater than some level of significant $\alpha_0$
* Solution 2: minimize a linear combination of different probabilities of error
* Solution 3: introduce assymetry in the treatment of $H_0$ and $H_1$ (e.g. choose which hypothesis to be the null)
    * Explain: some type of error is more costly in some sense
    * Example: arrange $H_0$ and $H_1$ so that type I error is the error most to be avoided

**Making a test have a specific significant level**:
* Assumptions:
    * The test $\delta$ is:
        * Reject $H_0$ if $T(X) \geq c$
        * Retain $H_0$ if $T(X) < c$
    * $\alpha_0$ is the desired level of significant
* Objective: $\sup_{\theta \in \Theta_0} P_\theta(T(X) \geq c) \leq \alpha_0$
* Conclusion: we should make $c$ as small as possible
    * Explain: we want to maxminimze $P_\theta(T(X) \geq c)$ for $\theta \in \Theta_1$

**Composition of tests**: 
* Assumptions:
    * For each $i \in [1, n]$
        * $H_{0, i}$ is a null hypothesis
        * $\delta_i$ is a level $\alpha_{0, i}$ test of $H_{0, i}$
    * $H_0: \{H_{0, i}\}_i$ are true
    * $\delta$ is a test, which rejects $H_0$ if $\delta_i$ rejects $H_{0, i}$ for some $i$
* Conclusion: $\delta$ is a level $\sum_i \alpha_{0, i}$ test of $H_0$
* Explain: under $H_0$, $\beta(\theta|\delta) = \sum_i \beta(\theta|\delta_i)$

**Evalutate a test procedure**:
* Procedure: compute power function over $\theta \in \Theta_0$ and $\theta \in \Theta_1$
* Desired results:
    * The power is low for $\theta \in \Theta_0$
    * The power is high for $\theta \in \Theta_1$
    * The power gets higher as $\theta$ moves away from $\Theta_0$

## Tests and confidence sets
**Confidence sets from tests**:
* Assumptions:
    * $X_1, ..., X_n$ form a random sampled from a distribution indexed by $\theta$
    * $g(\theta)$ is a function
    * For each possible value $g_0$ of $g(\theta)$,
        * $\begin{cases} H_{0, g_0}: g(\theta) = g_0 \\ H_{1, g_0}: g(\theta) \neq g_0\end{cases}$ are the hypotheses
        * $\delta_{g_0}$ is a level-$\alpha_0$ test
    * $\omega(\textbf{x}) = \{g_0: \delta_{g_0}$ doesn't reject $H_{0, g_0}$ if $\textbf{X} = \textbf{x}\}$ for each $\textbf{x}$
        * Interpretation: $\omega(\textbf{X})$ is a random set, where $P_\theta[g_0 \in \omega(\textbf{X})]$ is indexed by $\theta$
* Conclusion: $P_{\theta_0}[g(\theta_0) \in \omega(\textbf{X})] \geq 1 - \alpha_0$ $\forall \theta_0 \in \Theta$
* Explain: given $\theta = \theta_0$, $P_\theta[g(\theta) \in \omega(\textbf{X})] \geq 1-\alpha_0$ since $H_{0, g(\theta)}$ is true

**Tests from confidence set**:
* Assumptions:
    * $X_1, ..., X_n$ form a random sample from a distribution indexed by $\theta$
    * $g(\theta)$ is a function
    * $\omega(\textbf{X})$ is a coefficient $\gamma$ confidence set for $g(\theta)$
    * For each possible value $g_0$ of $g(\theta)$,
        * $\begin{cases} H_{0, g_0}: g(\theta) = g_0 \\ H_{1, g_0}: g(\theta) \neq g_0\end{cases}$ are the hypotheses
        * $\delta_{g_0}$ is a test, which doesn't reject $H_{0, g_0}$ if and only if $g_0 \in \omega(\textbf{X})$
* Conclusion: $\delta_{g_0}$ is the level $\alpha_0 = 1 - \gamma$ test

---

# BONUS
* Critical region and rejection region: in some materials, there are two definitions
    * Critical region: $S = \{x: H_0$ is rejected $\}$
    * Rejection region: $R = \{T(x): H_0$ is rejected $\}$

# NEW WORD
* Controversy (n): tranh cÃ£i