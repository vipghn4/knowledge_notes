<!-- TOC titleSize:1 tabSpaces:2 depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 skip:0 title:1 charForUnorderedList:* -->
# Table of Contents
- [Table of Contents](#table-of-contents)
- [Bayesian estimators](#bayesian-estimators)
  - [Prior and posterior distributions](#prior-and-posterior-distributions)
    - [Prior distribution](#prior-distribution)
    - [Posterior distribution](#posterior-distribution)
    - [The likelihood function](#the-likelihood-function)
  - [Conjugate prior distributions](#conjugate-prior-distributions)
    - [Conjugate prior distribution](#conjugate-prior-distribution)
    - [Common conjugate family of prior distributions](#common-conjugate-family-of-prior-distributions)
  - [Bayes estimators](#bayes-estimators)
    - [Nature of an estimation problem](#nature-of-an-estimation-problem)
    - [Loss functions](#loss-functions)
    - [Definition of a Bayes estimator](#definition-of-a-bayes-estimator)
    - [Different loss functions](#different-loss-functions)
    - [The Bayes estimate for large samples](#the-bayes-estimate-for-large-samples)
    - [More general parameters and estimators](#more-general-parameters-and-estimators)
- [Appendix](#appendix)
  - [Concepts](#concepts)
  - [Discussions](#discussions)
<!-- /TOC -->

# Bayesian estimators
## Prior and posterior distributions
### Prior distribution
**Prior distribution**. The distribution $\xi(\theta)$ of $\theta$ over the parameter space $\Omega$, before observing other random variables of interest
* *Interpretation*. Summary of domain information and knowledge about where in $\Omega$ the value of $\theta$ should be
* *Prior distribution and marginal distribution*. When we treat the parameter as a random variable

    $\to$ Prior distribution refers to the marginal distribution of the parameter
* *Constructing prior distribution*. Before the experimental data have been collected or observed

    $\to$ The experimenter's past experience and knowledge will lead him to derive a prior distribution of $\theta$
* *Consequence*. The distribution indexed by $\theta$ for other random variables of interest is referred as the conditional distribution for those variables, given $\theta$

**Sensitivity analysis and imnproper priors**.
* *Sensitivity analysis*. Analyze how much impact the prior distribution had on the posterior probability of a single important event
    * *Explain*. How sensitive the posterior distribution is to the change of prior distributions
    * *Procedure*.
        1. Use a large collection of prior distributions for $\theta$
        2. Compare the posterior distributions arising from the priors
    * *Impact of prior distributions*. It is very often that different prior distributions do not make much difference if
        *  We have a lot of data, or
        *  The prior distributions being compared are very spread out, i.e. weak priors
    * *Conclusion*. 
        * The fact that different experimenters may not agree on a prior distribution becomes less important if there are a lot of data
        * If it is not going to matter much which prior distribution is specified
            
            $\to$ Experimenters may be less inclined to spend time specifying a prior distribution
    * *Needs for prior distribution*. If one does not specify some prior distribution

        $\to$ There is no way to calculate a conditional distribution of the parameter given the data
* *Improper priors*. Priors $\xi(\theta)$ so that $\int \xi(\theta) d\theta = \infty$
    * *Motivation*. Capture the idea that the data contain much more information than is available a priori
        * *Explain*. When the data do not contain much information, improper priors may be highly inappropriate
    * *Choosing an improper prior*. Methods for choosing improper prior all lead to similar posterior
        * *Naive method*. Start with a family of conjugate prior distributions (if available)
        * *Observation*. In most cases, if the parametrization of the conjugate family is chosen carefully

            $\to$ The posterior hyperparameters will each equal the corresponding prior hyperparameters plus a statistic
            * *Consquence*. We can set each of the prior hyperparameter by $0$ for convenience
        
        >**NOTE**. One must choose an improper prior so that the posteriors are proper distributions

### Posterior distribution
**Posterior distribution**. The distribution $\xi(\theta|x_1, ..., x_n)$ of $\theta$ over the parameter space $\Omega$, after observing other random variables of interest
* *From prior to posterior*: 
    
    $$\forall \theta \in \Omega,\xi(\theta|\textbf{x}) = \frac{\xi(\theta) \prod_{i=1}^n f(x_i|\theta)}{g_n(\textbf{x})}$$ 
    
    where $g_n$ is the marginal joint p.m.f of $X_1,\dots,X_n$
* *Interpretation*. Posterior distribution is another name for the conditional distribution of the parameter given the data

**Trick**. Since $g_n(\textbf{x})$ is constant

$$\xi(\theta|\textbf{x}) \propto f_n(\textbf{x}|\theta) \xi(\theta)$$

* Solving for $g_n(\textbf{x})$: solve $\int_\Omega \xi(\theta|\textbf{x}) d\theta = 1$
* Uses:
    * Recognize if $f_n(\textbf{x}|\theta) \xi(\theta)$ is equal to one of the available p.m.f or not
    * Drop $g_n(\textbf{x})$ from $f_n(\textbf{x}|\theta)$

**Another way to compute $\xi(\theta|\textbf{x})$**. Compute $\xi(\theta|\textbf{x})$ sequentially by 

$$\xi(\theta|\textbf{x}_{1:i}) \propto f(x_i|\theta) \xi(\theta|\textbf{x}_{1:i-1})$$

**Example**. Consider lifetimes of electronic components
* *Mathematical modeling*.
    * Lifetimes $X_1,X_2,\dots$ of electronic components were modeled as i.i.d exponential random variables with parameters $\theta$

        $\to$ $\theta$ was interpreted as the failure rate of the components
* *Estimator for $\theta$*. $\hat{\theta} = \frac{n}{\sum_{i=1}^n X_i}$
    * *Explain*. $\hat{\theta}$ converges in probability to $\theta$, as $n$ goes to $\infty$
* *Steps to take*.
    1. On the basis of previous experience, take a prior distribution for $\theta$

        $\to$ The prior is then revised to best fit our knowledge about $\theta$
    2. After observing the data, determine the posterior of $\theta$ given the data $X_1,\dots,X_n$
    3. Perform sensitivity analysis, i.e. changing prior distribution of $\theta$

### The likelihood function
**Likelihood function**. $f_n(\textbf{x}|\theta)$ as a function of $\theta$ given $x_1, ..., x_n$

**Determining the posterior p.d.f of $\theta$ without performing integration**.
* *Determination of the posterior of $\theta$ via integration*.

    $$\xi(\theta|\mathbf{x}) = \frac{f_n(\mathbf{x}|\theta) \xi(\theta)}{\int_\Omega f_n(\mathbf{x}|\theta') \xi(\theta') d\theta'}$$

* *Determination of the posterior of $\theta$ without integration*. Based on the relation

    $$\xi(\theta|\mathbf{x}) \propto f_n(\mathbf{x}|\theta)\xi(\theta)$$

    * *Idea*. If we can recognize $f_n(\mathbf{x}|\theta)\xi(\theta)$ as one of the familiar p.d.f, except possibly for a constant factor

        $\to$ We can easily determine the appropriate factor converting $f_n(\mathbf{x}|\theta)\xi(\theta)$ into a proper p.d.f

## Conjugate prior distributions
### Conjugate prior distribution
**Conjugate family of prior distributions**. $\Psi$ is a conjugate family of prior distribution if both $\xi(\theta)$ and $\xi(\theta|\textbf{x})$ belong to $\Psi$, no matter which $\xi(\cdot) \in \Psi$ is chosen
* *Interpretation*. $\Psi$ is closed under sampling from $f(x|\theta)$
* *Usage*. Simplify the procedure of calculating the posterior distribution

**Hyperparameters**.
* *Prior hyperparameters*. Assocaited parameters of the prior distributions
* *Posterior hyperparameters*. Assocaited parameters of the posterior distributions

### Common conjugate family of prior distributions
**Beta distribution**. The family of beta distributions is a conjugate family of prior distributions for samples from a Bernoulli distribution
* *Assumptions*.
    * $X_1,\dots,X_n$ form a random sample from the Bernoulli distribution with parameter $\theta\in(0,1)$
    * The prior of $\theta$ is the beta distribution with parameters $\alpha>0,\beta>0$
* *Conclusion*. The posterior distribution of $\theta$ given $X_i=x_i (i=1,\dots,n)$ is the beta distribution with parameters

    $$\alpha+\sum_{i=1}^n x_i,\quad \beta+n-\sum_{i=1}^n x_i$$

**Gamma distribution**. The family of gamma distributions is a conjugate family of prior distributions for samples from a Poisson distribution
* *Assumptions*.
    * $X_1,\dots,X_n$ form a random sample from the Poisson distribution with unknown mean $\theta>0$
    * The prior distribution of $\theta$ is the gamma distribution with parameters $\alpha>0,\beta>0$
* *Conclusion*. The posterior distribution of $\theta$ given $X_i=x_i(i=1,\dots,n)$ is the gamma distribution with parameters

    $$\alpha+\sum_{i=1}^n x_i,\quad \beta+n$$

**Normal distribution**. The family of normal distributions is a conjugate family of prior distributions for samples from a normal distribution
* *Assumptions*.
    * $X_1,\dots,X_n$ form a random sample from the normal distribution with unknown mean $\theta$ and known variance $\sigma^2>0$
    * The prior distribution of $\theta$ is the normal distribution with mean $\mu_0$ and variance $v_0^2$
* *Conclusion*. The posterior distribution of $\theta$ given $X_i=x_i(i=1,\dots,n)$ is the normal distribution with parameters

    $$\mu_1 = \frac{\sigma^2\mu_0 + n v_0^2\bar{x}_n}{\sigma^2 + nv_0^2}$$

    and

    $$v_1^2 = \frac{\sigma^2 v_0^2}{\sigma^2 + nv_0^2}$$

**Exponential distribution**. The family of gamma distributions is a conjugate family of prior distributions for samples from a exponential distribution
* *Assumptions*.
    * $X_1,\dots,X_n$ form a random sample from the exponential distribution with parameter $\theta>0$
    * The prior distribution of $\theta$ is the gamma distribution with parameters $\alpha>0,\beta>0$
* *Conclusion*. The posterior distribution of $\theta$ given $X_i=x_i(i=1,\dots,n)$ is the gamma distribution with parameters

    $$\alpha+n,\quad \beta+\sum_{i=1}^n x_i$$

## Bayes estimators
### Nature of an estimation problem
**Estimator**.
* *Assumptions*.
    * $X_1, \dots, X_n$ are observable data whose joint distribution is indexed by $\theta$
    * $\theta \in \Omega$ where $\Omega$ is a subset of real line
* *Conclusion*.
    * *An estimator of $\theta$*. $\delta(X_1, \dots, X_n)$, i.e. a function of random variables $X_1, \dots, X_n$
    * *The estimate of $\theta$*. $\delta(x_1, \dots, x_n)$, i.e. observed value of $\delta(X_1, \dots, X_n)$

**Constraints on $\delta$**. Since $\theta\in\Omega$

$\to$ It seems reasonable that every possible value of $\delta(X_1, ..., X_n)$ must belong to $\Omega$
* *Discussion*. We shall not require this restriction, i.e. 
    * If $\delta(x_1, ..., x_n) \notin \Omega$
        
        $\to$ One will need to decide whether that seems appropriate or not
    * Every estimator which takes values only inside $\Omega$ has other even less desirable properties

### Loss functions
**Criterion for good estimator**. A good estimator $\delta$ should yield an estimate of $\theta$, which is close to the actual value of $\theta$

$\to$ It is highly probable that $|\delta(\mathbf{X}) - \theta|$ will be close to $0$

**Loss function**. Measure the loss or cost to the statistician, given the true value of the parameter and his estimate
* *Assumptions*.
    * $\theta \in \Omega$ is the parameter to estimate
        * $\xi(\theta)$ is the prior p.m.f of $\theta$ on $\Omega$
    * $a$ is a real number
* *Loss function*. A real-valued function $L(\theta, a)$
    * *Expected loss*. $E[L(\theta, a)] = \int_\Omega L(\theta, a) \xi(\theta) d \theta$
* *Interpretation*. If the parameter equals $\theta$ and the estimate equals $a$

    $\to$ The statistician loses $L(\theta, a)$

**Target of estimation**. Minimize $E[L(\theta, a)]$

### Definition of a Bayes estimator
**Bayes estimator**.
* *Bayes estimator of $\theta$*. $\delta^*$, where $\delta^*(\textbf{x})$ minimizes $E[L(\theta, a)|\textbf{x}]$ for each possible $\textbf{x}$, where

    $$E[L(\theta, a)|\mathbf{x}] = \int_\Omega L(\theta,a)\xi(\theta|\mathbf{x})d\theta$$

    * *Another interpretation*. 
        
        $$E[L(\theta, \delta^*(\textbf{x}))|\mathbf{x}] = \min_a E[L(\theta, a)|\textbf{x}]$$

* Bayes estimate of $\theta$: $\delta^*(\textbf{x})$

**Existence of Bayes estimator**. There are situations in which no $\delta^*$ satisfies

### Different loss functions
**Squared error loss function**. $L(\theta,a)=(\theta-a)^2$
* *Bayes estimator$*. $\delta^*(\mathbf{X})=E(\theta|\mathbf{X})$

**Absolute error loss function**. $L(\theta,a)=|\theta-a|$
* *Bayes estimator*. $\delta^*(\mathbf{X})$ equals to a median of the posterior of $\theta$

### The Bayes estimate for large samples
**Properties**.
* *Effect of different prior distributions*. When the number of observations in the sample is so large

    $\to$ Bayes estimates w.r.t different priors are almost the same
    * *Explain*. Since the posterior is not sensitive to prior, given a large amount of data
        
        $\to$ This can be proven by considering $\log f(\theta|\mathbf{X})$ as

        $$\log f(\theta|\mathbf{X}) = \sum_{i=1}^n f(X_i|\theta) + \log f(\theta) + \text{constant}$$

* *Consistency of the Bayes estimator*. When large number of observations are taken

    $\to$ The Bayes estimator will converge in probability to the unknown value of $\theta$ as $n \to \infty$
    * *Formal*.

        $$\lim_{n\to\infty} P(|\hat{\theta} - \theta|>\epsilon)=0$$
    
    * *Explain*. In case of MSE loss, this is due to the central limit theorem

        >**NOTE**. Further proof depends on the choice of loss function

>**NOTE**. For a wide class of loss functions, the Bayes estimators of $\theta$ will form a consistent sequence of estimators as $n \to \infty$

>**NOTE**. If conjugate prior distribution (if available) is assigned to $\theta$ and the squared error loss is used, the Bayes estimators will form a consistent sequence of estimators

**Limitations**.
* Loss function is required and also a prior distribution for the parameter
* $\theta$ maybe a vector of all unknowns
    * *Explain*. This requires multivariate prior for $\theta$ and multivariate loss $L(\theta, \textbf{a})$

	>**NOTE**. Even when the statistician wants to estimate only one or two components of $\theta$, he still needs to assign multivariate prior to the entire $\theta$

### More general parameters and estimators
**Generalizations**.
* Estimate multi-dimensional parameters
* Estimate functions of the parameters

# Appendix
## Concepts
**Observable and hypothetically observable random variables**.
* *Observable random variables*. Variables, which we are essentially certain that we could observe if we devoted sufficient effort to observe it
* *Hypothetically observable random variables*. Variables which require infinite resources to observe
    * *Example*. $\lim_{n \to \infty} \bar{X}_n$

**Consistent estimator**. A sequence of estimators which converges in probability to the unknown value of $\theta$, as $n \to \infty$

**"Prior" and "posterior"**. Derived from the Latin words for "former" and "coming after"

**Loss functions and utility**. A loss function is like the negative of a utility

$\to$ One can convert other loss functions into utilities
* *Consequence*. Minimizing the expected loss is equivalent to maximizing expected utility

## Discussions
**Bayesian estimator and MLE**. Consider the Bayes's rule

$$p(\theta|\mathbf{X})=\frac{p(\mathbf{X}|\theta) p(\theta)}{p(\mathbf{X})}$$

* *MLE*. Seek a point value $\hat{\theta}$ for $\theta$ to maximize the likelihood $p(\mathbf{X}|\theta)$ 

    $\to$ The factor $\frac{p(\theta)}{p(\mathbf{X})}$ is treated as constant, i.e. our prior beliefs $p(\theta)$ cannot be injected
* *Bayes estimator*. Fully calculate the posterior $p(\theta|\mathbf{X})$
    
    $\to$ $\theta$ is treated as a random variable
    * *Idea*. Put in prior distribution and get out posterior distribution, rather than a point estimator as in MLE
    * *Consequence*. We need to deal with the evidence, i.e. probability of evidence

        $$p(\mathbf{X}) = \int_\Omega f(\mathbf{X}|\theta) p(\theta) d\theta$$

* *Reference*. https://stats.stackexchange.com/questions/74082/what-is-the-difference-in-bayesian-estimate-and-maximum-likelihood-estimate

**Loss function and MLE**.
* *Loss function*. A measurement of model misfit as a function of the model parameters
    
    $\to$ Loss functions are more general than solely MLE
* *MLE*. A specific type of probability model estimation, where the loss function is the (log) likelihood
    
    $\to$ MLE is one way to justify loss functions for probability models

**Machine learning and classical statistics**.
* *Machine leanring*. Many people do not talk about assumptions, e.g. residual to be Gaussian, too much
    
    $\to$ People view the problem as a deterministic problem, where  a large amount of data is given, and we want to minimize the loss
* *Classical statistics*. Usually the data is not too many, and people talk about the probabilistic interpretation of the model, where there are many probabilistic assumptions, e.g. residual to be Gaussian
    
    $\to$ With probabilistic assumptions, the likelihood can be calculated and the loss function can be negative likelihood instead of minimizing misclassification rate