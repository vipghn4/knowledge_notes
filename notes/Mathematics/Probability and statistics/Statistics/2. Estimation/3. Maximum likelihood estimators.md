<!-- TOC titleSize:1 tabSpaces:2 depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 skip:0 title:1 charForUnorderedList:* -->
# Table of Contents
- [Table of Contents](#table-of-contents)
- [Maximum likelihood estimators](#maximum-likelihood-estimators)
  - [Maximum likelihood estimators](#maximum-likelihood-estimators-1)
    - [Introduction](#introduction)
    - [Definition of a maximum likelihood estimator](#definition-of-a-maximum-likelihood-estimator)
    - [Limitations](#limitations)
  - [Properties of maximum likelihood estimators](#properties-of-maximum-likelihood-estimators)
    - [Invariance](#invariance)
    - [Consistency](#consistency)
    - [Numerical computation](#numerical-computation)
    - [Method of moments](#method-of-moments)
    - [MLEs and Bayes estimators](#mles-and-bayes-estimators)
- [Appendix](#appendix)
  - [Concepts](#concepts)
<!-- /TOC -->

# Maximum likelihood estimators
## Maximum likelihood estimators
### Introduction
**History**. Introduced by R. A. Fisher in 1912

**Desirable properties**. MLE is the most widely used method of estimation in statistics
* Strong intuitive appeal
* Often yield a reasonable estimator of $\theta$
* If the sample is large, the method will typically yield an excellent estimatof of $\theta$

**Terminologies**. Since MLE do not involve the specification of a prior distribution of $\theta$

$\to$ Some different terminology is used to dsecribe the statistical models, to which the procedures are applied
* *Bayesian perspective*. $X_1, ..., X_n$ are i.i.d with p.m.f $f(x|\theta)$ conditional on $\theta$
* *Frequentist perspective*. $X_1, ..., X_n$ form a random sample from a distribution with p.m.f $f(x|\theta)$ where $\theta$ is unknown

### Definition of a maximum likelihood estimator
**Idea**.
* *Observations*. Given observed vector $\textbf{x}$ from a discrete distriubtion
    * We would certainly not consider any $\theta \in \Omega$ for which it is impossible to obtain $\textbf{x}$
    * If $f(\textbf{x}|\theta)$ is very high for $\theta = \theta_0$ and is very small for other $\theta \in \Omega$

        $\to$ We would naturally estimate $\theta$ to be $\theta_0$, unless we had strong prior information which outweighted the evidence in the sample and pointed toward some other value

* *Conclusion*. We will consider 
    
    $$\theta^* = \arg \max_\theta f_n(\textbf{x}|\theta)$$
    
    and use it as an estimate of $\theta$
* *Fisher information*. This is aligned with Fisher information, which is the curvature of $\log f(X|\theta)$

    $\to$ The higher Fisher information, the more reasonable to use $\theta_0$ as an estimator of $\theta$

**Maximum likelihood estimator (MLE)**.
* *Maximum likelihood estimator of $\theta$*. 
    
    $$\hat{\theta} = \delta(\textbf{x}) = \arg \max_\theta f_n(\textbf{x}|\theta)$$
    
    for each observed vector $\textbf{x}$
* *Maximum estimate of $\theta$*. $\hat{\delta}(\textbf{x})$ when $\textbf{X} = \textbf{x}$ is observed

**Notes**:.
* The MLE is required to be an element of the parameter space $\Omega$
* For certain observed $\textbf{x}$, the maximum value of $f_n(\textbf{x}|\theta)$ may not actually be attained for any $\theta \in \Omega$

    $\to$ In this case, MLE is defined separately for each different $\textbf{x}$

* For certain observed $\textbf{x}$, the maximum value of $f_n(\textbf{x}|\theta)$ may actually be attained at more than one point in $\Omega$

    $\to$ In this case, MLE can be chosen among those optimal points

### Limitations
**Underestimate and overestimate**. MLE sometimes surely underestimates or overestimates the parameter

**Existence**. MLE does not always exists
* *Explain*. For certain observed vectors $\mathbf{x}$, the maximum value of $f_n(\mathbf{x}|\theta)$ may not be attained for any $\theta\in\Omega$

    $\to$ In such a case, the MLE is not uniquely defined
    * *Solution*. Any one of the points can be chosen as the value of $\hat{\theta}$
* *Solution*. Choose an appropriate parametrization of the distribution

    >**NOTE**. This difficulty cannot always be avoided

* *Example*. Consider the likelihood function of a uniform distribution

    $$f(x|\theta) = \begin{cases}\frac{1}{\theta} & 0<x<\theta\\0&\text{otherwise}\end{cases}$$

    * *MLE of $\theta$*.

        $$\hat{\theta}=\arg\max_{\theta>\max_{i=1,\dots,n}x_i} \frac{1}{\theta^n}$$
    
        $\to$ $\theta$ can be chosen arbitrarily close to $\max\{x_1,\dots,x_n\}$, but cannot be chosen to this value
    * *Consequence*. The MLE of $\theta$ does not exist
    * *Solution*. Model the distribution as

        $$f(x|\theta) = \begin{cases}\frac{1}{\theta} & 0\leq x\leq\theta\\0&\text{otherwise}\end{cases}$$

**Maximum likelihood versus maximum posterior**. MLE isn't necessarily the value of the parameter that appears to be most likely given the data
* *Explain*. We maximize $f_n(\textbf{x}|\theta)$, not $f(\theta|\textbf{x})$

    $\to$ It is not legitimate to interpret the MLE as the most likely value of $\theta$, after having seen the data
    * *Consequence*. Treating the MLE as if it were the most likely value of $\theta$ is equivalent to ignoring the prior information about $\theta$
    * *Solution*. Use posterior distribution, i.e. Bayes estimator
* *When to use MLE*.
    * When we have a lot of data
    * When there is very little prior information

## Properties of maximum likelihood estimators
**Brief**. In this section, we study the following properties
* The relationship between the MLE of a parameter and the MLE of a function of the parameter
* The need for computational algorithms
* The behavior of the MLE, as the sample size increases
* The lack of dependence of the MLE on the sampling plan

### Invariance
**Invariance**. If $\hat{\theta}$ is the MLE of $\theta$ and $g(\cdot)$ is one-to-one then $g(\hat{\theta})$ is the MLE of $g(\theta)$

**MLE of a function**. The invariance above can be extended to functions, which are not one-to-one
* *Assumptions*.
    * $g: \Omega \to G$ is defined as $g(\theta)$
    * $G_t = \{\theta|g(\theta) = t\}$, i.e. $g: G_t \to \{t\}$ for all $t \in G$
    * $L^*(t) = \max_{\theta \in G_t} \log f_n(\textbf{x}|\theta)$, i.e. maximum likelihood over all $\theta \in G_t$
* *MLE of $g(\theta)$*. $\hat{t}$, where 
    
    $$L^*(\hat{t}) = \max_{t \in G} L^*(t)$$

* *Theorem*. If $\hat{\theta}$ is an MLE of $\theta$, then the MLE of $g(\theta)$ is $g(\hat{\theta})$
    * *Explain*. 
        * $\hat{t}$ is obtained by
            1. Group $\theta\in\Omega$ by $g(\theta)$, i.e. partition $\Omega$ into $\{G_t:t\in G\}$
            2. For each partition $G_t$, pick the conditional maximum likelihood estimator $\theta_t$ for $\theta$
            3. Pick the maximum likelihood estimator for $g(\theta)$ by

                $$\hat{t} = \arg\max_{t\in G} \log_n f_n(\mathbf{x}|\theta_t)$$
        * The resulting $\hat{t}$ is hence correspond to $\hat{\theta}$, hence $\hat{t}=g(\hat{\theta})$

### Consistency
**Consistency**.
* *Assumptions*. For every $n \geq n_0$ for some certain $n_0$, there exists a unique MLE of $\theta$
* *Conclusion*. Under certain conditions, which are typically satisfied in practical problems, the sequence of MLEs is a consistent sequence
    * *Interpretation*. The sequence of MLE converges in probability to the unknown value of $\theta$ as $n \to \infty$
* *Formal*.

    $$\lim_{n\to\infty} P(|\hat{\theta} - \theta|>\epsilon)=0$$

* *Intuition*. As $n\to\infty$, maximizing $f_n(\mathbf{x}|\theta)$ means maximizing $E[\log f(X|\theta)]$

    $\to$ $\hat{\theta}$ will converge to $\theta$ if convergence of $f_n(\mathbf{x}|\theta)$ implies convergence of $\hat{\theta}$, and

    $$|\{\theta':E[\log f(X|\theta')] = E[\log f(X|\theta)]\}|=1$$

**Bias from Bayes estimator**. For a given prior and a sufficiently large $n$, Bayes estimator of $\theta$ is also a consistent sequence of estimators

$\to$ Bayes estimator and MLE of $\theta$ wil typically very close to each other, and be very close to the true $\theta$

### Numerical computation
**Problem**. In many problems, we cannot express the MLE of $\theta$ in closed form

**Solutions**. Use iterative optimization algorithms 
* Newton's method
* Method of moments
* EM algorithm
* Gradient descent

**Newton's method**. An iterative optimization algorithm to find MLEs
* *Assumptions*. $f(\theta)$ is a real-valued function of a real variable
* *Task*. Solve $f'(\theta) = 0$ for $\theta$
* *Newton's method*.
    * *Initialization*. $\theta = \theta_0$
    * *Iteration*. 
        
        $$\theta_i = \theta_{i-1} - \frac{f(\theta_{i-1})}{f'(\theta_{i-1})}$$
    
* *Failures*. When $\frac{f'(\theta_{i-1})}{f(\theta_{i-1})} \to 0$ between $\theta_0$ and the actual solution to $f(\theta) = 0$

### Method of moments
**Brief**. Method of moments is an intuitive method for estimating parameters when other, more attractive, methods may be too difficult

**Method of moments**. Used to obtain an initial guess for iterative optimization algorithms
* *Assumptions*.
    * $X_1, ..., X_n$ form a random sample indexed by $\theta \in \textbf{R}^k$
    * $\mu(\theta) = (\mu_1(\theta), ..., \mu_k(\theta))$ is supposed to be a one-to-one function of $\theta$
        * $\mu_j(\theta) = E(X_1^j|\theta)$ for $j = 1, ..., k$
    * $m_j = \frac{1}{n} \sum_i X_i^j$ is the $j$-th sample moment
* *Method of moments* $\theta = \mu^{-1}(m_1, ..., m_k)$
    
    $\to$ We solve $m_j = \mu_j(\theta)$ $\forall j$ for $\theta$
* *Consistency*. The sequence of method of moments estimators is a consistent sequence of estimators of $\theta$
    * *Explain*. Sample moments converge to true moments in probability due to the law of large numbers

**EM algorithm**. Solve data missing problem when computing MLEs
* *Assumptions*.
    * $X = (x_a, X_m)$ is the dataset
    * $x_a$ is the available data
    * $X_m$ is the missing data, which are treated as random variables
        * $f_m(X_m)$ is the distribution of $X_m$
    * $f_n(X|\theta)$ is the likelihood function
* *Algorithm*.
    * *Initialization*. $\theta = \theta^{(0)}$
    * *Iteration*.
        * *E-step*. Compupte $f_m(X_m|x_a; \theta^{(j)})$
        * *M-step*. 
            
            $$\theta^{(j+1)} = \arg \max_\theta E_{X_m}[\log f_n(X|\theta)]$$

* *Convergence*. 
    * $\log f_n(\textbf{x}|\theta)$ increases with each iteration of the EM algorithm
    * The algorithm converges to a local maximum of $f_n(\textbf{x}|\theta)$

### MLEs and Bayes estimators
**General idea**. Both MLEs and Bayes estimators depend on the likelihood function but they use likelihood function in different ways

>**NOTE**. In many problems, they will be very similar

**Distribution of MLE and Bayes estimator**.
* *Assumptions*.
    * $\hat{\theta}$ is the MLE of $\theta$
    * $V_n(\theta)$ is a sequence of random variables which converges to some $v_\infty(\theta)$ as $n \to \infty$
* *Convergence of $f(x|\theta)$*. When $f(x|\theta)$, as a function of $\theta$, satisfies certain smoothness conditions

    $\to\lim_{n \to \infty} f_n(\textbf{x}|\theta) \propto \exp[-\frac{1}{2 V_n(\theta)/n} (\theta - \hat{\theta})^2]$
    * *Conclusion*. As $n \to \infty$, $f_n(\textbf{x}|\theta)$ has a sharp peak at $\theta = \hat{\theta}$
    * *Distribution of the MLE given $\theta$*. Approximately normal with mean $\theta$ and variance $v_\infty(\theta) / n$
* *Convergence of Bayes estimator*: If the prior of $\theta$ is relatively flat compared to the very peak $f(x|\theta)$
    
    $\to$ The posterior will look a lot like the likelihood multiplied by a normalizing constant
    * *Consequence*. $E(\theta|\textbf{x}) \approx \hat{\theta}$
    * *Posterior distribution of $\theta$*. Approximately normal with mean $\hat{\theta}$ and variance $V_n(\hat{\theta})/n$
* *Convergence failures*. When $n$ is not very large, or $f(x|\theta)$ is not smooth

    $\to$ The posterior distributions and distributions of MLEs are not normal as discussed above

# Appendix
## Concepts
**Missing data**. Miss observations which we had planned or hoped to observe but were not observed

**Sampling plans**.
* *Task*. Take observations from a distribution with p.m.f $f(x|\theta)$ to gain information about $\theta$
* *Naive approach*. Take a random sample of pre-determined size
* *Proposed approach*.
    1. Observe a few amount of data to estimate the observation cost
    2. Decide to continue or stop collecting data
    3. In case of continue collecting data, stop collecting data if
        * We think that we have enough information to obtain a good estimate of $\theta$, or
        * We cannot afford to collect more data
* *Theorem*. 
    * *Assumptions*. 
        * The sample size $n$ is a random variable
        * The decision of continue sampling or not, after $n$ observations, is a function of $n$ observed examples
    * *Conclusion*. If the decision to continue collecting data is based solely on the observations, not $\theta$

        $\to$ The MLE is independent of the sampling plan
    * *Explain*. The only way in which the MLE can depend on the sampling plan is through the likelihood function