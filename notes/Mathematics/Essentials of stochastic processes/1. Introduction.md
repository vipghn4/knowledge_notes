<!-- TOC titleSize:1 tabSpaces:2 depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 skip:0 title:1 charForUnorderedList:* -->
# Table of Contents
- [Table of Contents](#table-of-contents)
- [Introduction](#introduction)
  - [Definition and basic properties](#definition-and-basic-properties)
- [Appendix](#appendix)
  - [Reference](#reference)
<!-- /TOC -->

# Introduction
**Quotes by the author**.

>As it is possible to drive a car without knowing about the working of the internal combustion engine, it is also possible to apply the theory of Markov chains without knowing the details of the proofs

>Readers who want to master the subject will have to do more than a few of the twenty dozen carefully chosen exercises

## Definition and basic properties
**Measure and distribution**.
* *State-space*. A countable set $I$, with each $i\in I$ referred as a state
* *Measure*. $\lambda=\{\lambda_i:i\in I\}$ is a measure on $I$ if

    $$\forall i\in I,0\leq \lambda_i<\infty$$

* *Distribution*. If the total mass $\sum_{i\in I}\lambda_i$ equals $1$, we refer to $\lambda$ as a distribution

**Stochastic matrix**. A matrix $P$ is stochastic if every row $\{p(i,j):j\in I\}$ is a distribution

$\to$ Rules for a Markov chain is defined in terms of $P$

# Appendix
## Reference
* https://www.statslab.cam.ac.uk/~james/Markov/s11.pdf