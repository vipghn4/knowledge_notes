---
title: 8. Testing strategies
tags: Software engineering
---

<!-- TOC titleSize:1 tabSpaces:2 depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 skip:0 title:1 charForUnorderedList:* -->
# Table of Contents
* [8. Testing strategies](#8-testing-strategies)
  * [QA should find nothing](#qa-should-find-nothing)
    * [QA if part of the team](#qa-if-part-of-the-team)
    * [QA as specifiers](#qa-as-specifiers)
    * [QA as characterizers](#qa-as-characterizers)
  * [The test automation pyramid](#the-test-automation-pyramid)
    * [Types of tests](#types-of-tests)
* [Appendix](#appendix)
  * [Discussions](#discussions)
<!-- /TOC -->

# 8. Testing strategies
## QA should find nothing
**Principle**. Despit of having a separate QA group, the goal of the development group is that QA find nothing wrong

### QA if part of the team
**Principle**. QA and development should be working together to ensure the quality of the system
* *Best role for QA part of the team*. Act as specifiers and characterizers

### QA as specifiers
**Principle**. QA should work with business to create the automated acceptance tests, which become the true specification and requirements document for the system
* *Jobs of QA*. Iteratively
    1. Gather requirements from business
    2. Translate them into tests
    3. Describe to developers how the system would behave

**Conclusion**. The business writes the happy-path tests, while QA writes the corner, boundary, unhappy-path tests

### QA as characterizers
**Principle**. QA should
1. Use the discipline of exploratory testing to characterize the true behavior of the running system
2. Report the behavior back to development and business

>**NOTE**. QA is not interpreting the requirements. They are identifying the actual behaviors of the system

## The test automation pyramid
**Principle**.
* Professional developers employ the discipline of TDD to create unit tests
* Professional development teams use acceptance tests to specify their system, and CI to prevent regression

**Test automation pyramid**. A graphical depiction of the kinds of tests required by a professional development team

<div style="text-align:center">
    <img src="/media/vfM5AEF.png">
    <figcaption>Test automation pyramid</figcaption>
</div>

### Types of tests
**Unit tests**. Tests written by programmers, for programmers, in the programming language of the system
* *Purpose*. Specify the system at the lowest level
* *When to write*. Before writing production code, as a way to specify what they are about to write
* *When to execute*. As part of CI to ensure that the intent of the programmers' is upheld

**Component tests**. Some acceptance tests written against individual components of the system
* *System component*. Encapsulate the business rules

    $\to$ Testsfor these components are the acceptance tests for the business rules
* *Component test architecture*. Component test wraps a component, i.e.
    * Component test passes input data into the component
    * Component test gathers output data from the component
    * Component test tests that the output matches the input

    >**NOTE**. Other system components are decoupled from the test using appropriate mocking and test-doubling techniques

* *Who to write*. QA and business with assistance from development
    * *Purpose*. The business should be able to read and interpret the tests, if not author them
* *What to test*. Component tests are directed towards happy-path situation, and very obvious corner, boundary, and alternate-path cases

**Integration tests**. Assemble groups of components and test how well they communicate with each other. Other system components are decoupled as usualy with appropriate mocks and test-doubles

>**NOTE**. Integration tests only have meaning for larger systems having many components

* *Purpose*. Ensure that the architectural structure of the system is sound

    $\to$ We may see performance and throughput tests
* *Who to write*. System architects, or lead designers, of the system
* *When to execute*. Not as part of the CI suite, since they often have longer runtimes

    $\to$ These tests are run periodically, e.g. nightly, weekly, etc., as deemed necessary by their authors

**System tests**. Ultimate integration tests, which against the entire integrated system
* *Description*. These tests do not test business rules directly. They test that the system has been wired together correctly and its parts interoperate according to plan

    $\to$ We expect to see throughput and performance tests in this suite
* *Purpose*. Ensure that the system construction is correct, not to ensure correct system behavior
* *Who to write*. System architects and technical leads
* *When to execute*. Relatively infrequently, depending on the siutation. But more frequently is better

**Manual exploratory tests**. Where humans try out the finished product
* *Purpose*. Explore the system for unexpected behaviors while confirming expected behaviors

>**NOTE**. There is not written test plan for these tests. Humans will freely interact with the software

# Appendix
## Discussions
**Happy and unhappy path tests**.
* *Happy path*. What users are supposed to do when using an application
* *Unhappy path*. What users can do to break the syste
