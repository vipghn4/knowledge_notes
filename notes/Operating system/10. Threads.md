---
title: 10. Threads
tags: Operating system
---

<!-- TOC titleSize:1 tabSpaces:2 depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 skip:0 title:1 charForUnorderedList:* -->
# Table of Contents
- [Table of Contents](#table-of-contents)
- [10. Threads](#10-threads)
  - [Overview](#overview)
    - [Motivation](#motivation)
    - [Benefits](#benefits)
    - [Multicore programming](#multicore-programming)
  - [Multithreading models](#multithreading-models)
    - [Many-to-one model](#many-to-one-model)
    - [One-to-one model](#one-to-one-model)
    - [Many-to-many model](#many-to-many-model)
  - [Thread libraries](#thread-libraries)
    - [Pthreads](#pthreads)
    - [Object-oriented thread creation with Java](#object-oriented-thread-creation-with-java)
  - [Threading issues](#threading-issues)
    - [`fork()` and `exec()` system calls](#fork-and-exec-system-calls)
    - [Cancellation](#cancellation)
    - [Signal handling](#signal-handling)
    - [Thread pools](#thread-pools)
    - [Thread-specific data](#thread-specific-data)
    - [Scheduler activations](#scheduler-activations)
- [Appendix](#appendix)
  - [Concepts](#concepts)
<!-- /TOC -->

# 10. Threads
## Overview
**Threads**. A basic unit of CPU utilization
* *Components*.
    * *Private components*. A thread ID, a program counter (PC), a register set, and a stack
    * *Shared components with other threads in the process*. Code section, data section, and other OS resources, e.g. open files and signals

### Motivation

<div style="text-align:center">
    <img src="/media/cmzYM00.png">
    <figcaption>Single-threaded and multithreaded processes</figcaption>
</div>

**Threads and concurrent tasks**. In certain situations, a single application have to perform several similar tasks

$\to$ If the application can perform only one task at a time, we may have to wait for a very long time for all tasks to be finished
* *Approach 1*. The popular idea before threads became popular
    * *Description*. Have the application run as a single process, which perform tasks

        $\to$ When a task pops up, the application creates a separate process to perform the task
    * *Cons*. Process creation is time consuming and resource intensive

        $\to$ If the new process performs the same tasks as the existing one, then we are incurring an overhead
* *Approach 2*. Have a process with multiple threads

    $\to$ When a task pops up, the application will create a new thread to perform the task and resume accepting additional tasks

    <div style="text-align:center">
        <img src="/media/pJpMtkx.png">
        <figcaption>Single-threaded and multithreaded processes</figcaption>
    </div>

**Threads and RPC systems**. Typically, RPC servers are multithreaded

$\to$ When a server receives a message, it services the message using a separate thread
* *Consequence*. The server can handle several concurrent requests

**Threads and OS kernels**. Most OS kernels are now multithreaded, i.e. several threads operate in the kernel, and each thread performs a specific task

### Benefits
**Responsiveness**. Multithreading an interactive application may allow a program to continue running, even if part of it is blocked or is performing a lengthy operation

$\to$ This increases responsiveness to the user

**Resource sharing**. Threads share the memory and the resources of the process, to which they belong, by default

$\to$ This allows an application to have several different threads within the same address space

**Economy**. Allocating memory and resources for proces creation is costly

$\to$ It is more economical to create and context-switch threads, since they share the resources of the process, to which they belong

**Scalability**. In multiprocessor architecture, where threads may be running in parallel on different processors

$\to$ The benefits of multithreading can be greatly increased

### Multicore programming
**Multicore system**. There are multiple computing cores on a single chip, where each core appears as a separate processor to the OS
* *Multithreaded programming and multicore systems*. Provide a mechanism for more efficient use of multiple cores and improved concurrency
    * *Explain*. On a multicore system, threads can run in parallel
* *Consequence*. System designers and application programmers should make better use of multiple computing cores
    * *OS designer's job*. Write scheduling algorithms using multiple processing cores to allow the parallel execution
    * *Application programmers*. Modify existing program and design new programs, which are multithreaded, to take advantage of multicore systems

**Challenges in multicore programming**.
* *Dividing activities*. Examine applications to find areas, which can be divided into separate, concurrent tasks
* *Balance*. Ensure the tasks perform equal work of equal value
* *Data splitting*. The data acccessed and manipulated by the tasks must be divided to run on separate cores
* *Data dependency*. The data accessed by the tasks must be examined for dependencies between two or more tasks
* *Testing and debugging*. When a program is running in parallel on multiple cores

    $\to$ There are many different execution paths

## Multithreading models
**Problem**. A relationship must exist between user threads and kernel threads, i.e.
* User threads are supported above the kernel, and are managed without kernel support
* Kernel threads are supported and managed directly by the OS

### Many-to-one model

<div style="text-align:center">
    <img src="/media/7JUiG8n.png">
    <figcaption>Many-to-one model</figcaption>
</div>

**Idea**. Map many user-level threads to one kernel thread
* *Pros*. Thread management is done by the thread library in user space

    $\to$ This is efficient
* *Cons*.
    * The entire process will block if a thread makes a blocking system call
    * Only one thread can access the kernel at a time

        $\to$ Multiple threads are unable to run in parallel on multiprocessors

### One-to-one model

<div style="text-align:center">
    <img src="/media/dAQ2bWc.png">
    <figcaption>One-to-one model</figcaption>
</div>

**Idea**. Map each user thread to a kernel thread
* *Pros*.
    * Provide more concurrency than many-to-one model
    * Allow multiple threads to run in parallel on multiprocessors
* *Cons*. Creating a user thread requires creating the corresponding kernel thread

    $\to$ Most implementations of this model restrict the number of threads supported by the system, since the overhead of creating kernel threads can burden the performance of the application

### Many-to-many model

<div style="text-align:center">
    <img src="/media/sNEuQGl.png">
    <figcaption>Many-to-many model</figcaption>
</div>

**Idea**. Multiplex many user-level threads to a smaller or equal number of kernel threads
* *Motivation*. In one-to-one model, true concurrency is not gained since the kernel can schedule only one thread at a time

    $\to$ One-to-one model offers greater concurrency, but the developers has to be careful not to create too many threads within an application
* *Pros*.
    * Developers can create as many user threads as necessary, and the corresponding kernel threads can run in parallel on a multiprocessor
    * When a thread performs a blocking system call, the kernel can schedule another thread for execution

**Two-level model**. A popular variation of many-to-many model
* *Idea*.
    * Multiplex many user-level threads to a smaller or equal number of kernel threads
    * Allow a user-level thread to be bound to a kernel thread

## Thread libraries
**Thread library**. Provide the programmer with an API for creating and managing threads
* *Primary ways of implementing a thread library*.
    * *Approach 1*. Provide a library entirely in user space with no kernel support

        $\to$ All code and data structures for the library exist in user space
        * *Consequence*. Invoking a function in the library results in a local function call in user space, not a system call
    * *Apporach 2*. Implement a kernel-level library supported directly by the OS

        $\to$ Code and data structures for the library exist in kernel space
        * *Consequence*. Invoking a function in the library typically results in a system call to the kernel

### Pthreads
**Pthreads**. The POSIX standard  defining an API for thread creation and synchronization

>**NOTE**. This is a specification for thread behavior, not an implementation

>**NOTE**. POSIX threads are available in C, i.e. `pthread.h`

### Object-oriented thread creation with Java
**Approach 1**. Create a new class, which is derived from the `Thread` class and override its `run()` method

**Approach 2**. (More commonly used). Define a class which implements the `Runnable` interface, i.e.

```java=
public interface Runnable{
    public abstract void run();
}
```

$\to$ Whe a class implements `Runnable`, it must define a `run()` method, i.e. what runs as a separate thread

**Thread creation**. Creating a `Thread` object does not specifically create the new thread

$\to$ It is the `start()` method which creates the new thread
* *`start()` method behavior*.
    1. Allocate memory and initialize a new thread
    2. Call the `run()` method, making the thread eligible to be run by the OS

## Threading issues
### `fork()` and `exec()` system calls
**`fork()`**. (Recall) Used to create a separate, duplicate process, i.e. like fork in Github
* *`fork()` in multithreading*. If one thread in a program calls `fork()`, does the new process duplicate all threads, or is the new process single-thread?
    * *Answer*. Some UNIX systems have chosen to have two versions of `fork()`

**`exec()`**. If a thread invokes `exec()` system call, the program specified in the parameter to `exec()` will replace the entire process, including all threads

### Cancellation
**Thread cancenllation**. Terminating a thread before it has completed
* *Target thread*. The thread that is to be canceled

**Scenarios of target thread cancellation**.
* *Asynchronous cancellation*. One thread immediately terminates the target thread
* *Deferred cancellation*. The target thread periodically checks whether it should terminate

    $\to$ This allows the target thread an opportunity to terminate itself in an orderly fashion

**Difficulties**. When resources have been allocated to a canceled thread, or when a thread is canceled while in the midst of updating shared data

$\to$ This can be troublesome with asynchronous cancellation

>**NOTE**. Often, the OS will reclaim system resources from a canceled thread, but will not reclaim all resources
>$\to$ Cancelling a thread asynchronously may not free a necessary system-wide resource

### Signal handling
**Signal**. Used in UNIX systems to notify a process that a particular event, e..g illegal memory access, has occurred
* *Signal processing pattern*.
    1. A signal is generated by the occurrence of a particular event
    2. A generated signal is delivered to a process
    3. Once delivered, the signal must be handled
* *Signal handlers*.
    * *Default signal handler*. Run by the kernel when handling a signal
    * *User-defined signal handler*. Override the default signal handler
* *Achronous signal*.
    * *Synchronous signal*. Signal delivered to the same process that performed the operation that caused the signal
    * *Asynchronous signal*. Signal is generated by an event external to the running process

**Signal handling problems in multithreading**. Where, then, should a signal be delivered
* *Methods for delivering a signal*. Depend on the type of signal generated
    * Deliver the signal to the thread, to which the signal applies

        >**NOTE**. Synchronous signals must be delivered this way

    * Deliver the signal to every thread in the process
    * Deliver the signal to certain threads in the process
    * Assign a specific thread to receive all signals for the process
* *Solution*. UNIX allows a thread to specify which signals it will accept and which it will block

    >**NOTE**. Signals need to be handled only once
    >$\to$ A signal is typically delivered to the first thread found, which is not blocking it

### Thread pools
**Motivation**. Creating a seprate thread is superior to creating a seprate process, but multithreaded systems also have potential problems, i.e.
* The amount of time required to create the thread prior to serving the request, and the time required to terminate the thread
* If we allow all concurrent requests to be serviced in a new thread

    $\to$ We have not placed a bound on the number of threads concurrently active in the system

**General idea**. Create a number of threads at process startup and place them into a pool, where they sit and wait for work

$\to$ When a server receives a request, it awakens a thread from the pool, and passes it the request for service

**Benefits**.
1. Servicing a request with an existing thread is usually faster than waiting to create a new one
2. A thread pool limits the number of threads existing at any one point

**Number of threads in a pool**. Depending on the number of CPUs in the system, the amount of physical memory, and the expected number of concurrent client requests

>**NOTE**. More sophisticated thread-pool architectures can dynamically adjust the number of threads in the pool, according to usage patterns

### Thread-specific data
**Problem**. Threads belonging to a process share the data of the process

$\to$ Sometimes, each thread may need its own copy of certain data, i.e. thread-specific data

### Scheduler activations
**Problem**. Communication between the kernel and the thread library
* *Solution*. Place an intermediate data structure, called lightweight process, between the user and kernel threads

<div style="text-align:center">
    <img src="/media/eYBUOt1.png">
    <figcaption>Lightweight process (LWP)</figcaption>
</div>

* *LWP*.
    * *To user-thread library*. LWP appears to be a virtual processor, on which the application can schedule a user thread to run
    * *To kernel thread*. Each LWP is attached to a kernel thread

        $\to$ It is kernel threads that the OS schedules to run on physical processors

**Scheduler activation**. A scheme for communication between user-thread library and the kernel
1. The kernel provides the application with a set of virtual processors, i.e. LWPs
2. The application can schedule user threads onto an available virtual processor

**Upcall**. The kernel must inform the application about certain events, i.e. upcall
* *Upcall handler*. Upcalls are handled by the thread library with an upcall handler

    >**NOTE**. Upcall handlers must run on a virtual processor

# Appendix
## Concepts
**Heavyweight process**. A process containing a single thread of control onl

**User-level threads and kernel-level threads**.
* *User-level threads*. User level threads are mostly at the application level where an application creates these threads to sustain its execution in the main memory
    
    >**NOTE**. Unless required, these thread work in isolation with kernel threads

    * *Cost of creation and execution*. These are easier to create since they do not have to refer many registers and context switching is much faster than a kernel level thread
* *Kernel-level threads*. These threads are mostly independent of the ongoing processes and are executed by the operating system

    $\to$ These threads are required by the Operating System for tasks like memory management, process management, etc.
    * *Cost of creation and execution*. Since these threads maintain, execute and report the processes required by the operating system
        
        $\to$ Kernel level threads are more expensive to create and manage and context switching of these threads are slow

    >**NOTE**. Most of the kernel level threads can not be preempted by the user level threads

* *Relationships between two levels of threads*. Kernel-level threads can be understood as servers serving for requests from user-level threads
    1. If a user thread needs something, it will call into the kernel, which marks that thread as sleeping
    2. Later, the swap thread finds the data, so it marks the user thread as runnable
    3. Later still, the "user thread" returns from the kernel back to userland as if nothing happened

**Context switching cost**.
* *Kernel threads*. A context switch between kernel threads belonging to the same process requires only the registers, program counter, and stack to be changed
    
    $\to$ The overall memory management information does not need to be switched since both of the threads share the same address space
    * *Consequence*. Context switching between two kernel threads is slightly faster than switching between two processes
    * *System calls and context switching*. Kernel threads can still be somewhat expensive because system calls are required to switch between threads
* *User threads*. The cost of a context switch between threads can be made even lower since the OS itself does not need to be involved–no extra system calls are required