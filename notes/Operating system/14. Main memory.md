---
title: 14. Main memory
tags: Operating system
---

<!-- TOC titleSize:1 tabSpaces:2 depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 skip:0 title:1 charForUnorderedList:* -->
# Table of Contents
- [Table of Contents](#table-of-contents)
- [14. Main memory](#14-main-memory)
  - [Swapping](#swapping)
  - [Contiguous memory allocation](#contiguous-memory-allocation)
    - [Memory mapping and protection](#memory-mapping-and-protection)
    - [Memory allocation](#memory-allocation)
    - [Fragmentation](#fragmentation)
  - [Paging](#paging)
    - [Basic method](#basic-method)
    - [Hardware support](#hardware-support)
    - [Protection](#protection)
    - [Shared pages](#shared-pages)
  - [Structure of the page table](#structure-of-the-page-table)
  - [Segmentation](#segmentation)
    - [Basic method](#basic-method-1)
    - [Hardware](#hardware)
<!-- /TOC -->

# 14. Main memory
## Swapping
**Swapping**. A process must be in memory to be executed, but it can be swapped temporarily out of memory to a backing store and then brought back into memory for continued execution

<div style="text-align:center">
    <img src="/media/FMxuqlJ.png">
    <figcaption>Swapping of two processes using a disk as a backing store</figcaption>
</div>

**Swapping policies**.
* *Swapping policy for round-robin scheduling algorithm*. Whenever a process finished execution

    $\to$ It is swapped out, and another process is swapped into the memory space, which has been freed
* *Swapping policy for priority-based scheduling algorithms*. Also called *roll out, roll in*
    * If a higher-priority process arrives and wants service

        $\to$ The memory manager can swap out the lower-priority process, then load and execute the higher-priority one
    * When the higher-priority proces finishes

        $\to$ The lower-prioty process can be swapped back in and continued

**Swapping locations**. Normally, a process, which is swapped out, will be swapped back into the same memory space it occupied previously

$\to$ This restriction is dictated by the method of address binding, i.e.
* If binding is done at assembly or load time

    $\to$ The process cannot be easily moved to a different location
* If execution-time binding is being used

    $\to$ A process can be swapped into a different memotry space
    * *Explain*. The physical addresses are computed during execution

**Back store**. Commonly a fast disk
* *Requirements*.
    * Large enough to accommodate copies of all memory images for all users
    * There must be direct access to these memory images
* *Ready queue*. The system maintains a ready queue consisting of all processes, whose memory images are on the backing store, or in memory, and are ready to run
* *Process execution*. Whenever the CPU scheduler decides to execute a process
    1. The CPU scheduler calls the dispatcher
    2. The dispatcher checks to see whether the next process in the queue is in memory. If it is not, and if there is no free memory region
        $\to$ The dispatcher swaps out a process currently in memory and swaps in the desired process
    3. The dispatcher then reloads registers and transfers control to the selected process

**Context-switch time in a swapping system**. Fairly high speed
* *Transfer time*. The major part of the swap time is transfer time, which is directly proportional to the amount of memory swapped

    >**NOTE**. It would be useful to know exactly how much memory a user process is using, rather than how much it might be using
    >$\to$ We would need to swap only what is actually used. reducing swap time
    >* *Consequence*. The user must keep the system informed of any changes in memory requirements
    >    $\to$ A process with dynamic memory requirements will need to issue system calls to inform the OS of its changing memory needs
* *Other factors constraining the swapping time*.
    * *Idle processes*. If we want to swap a process, we must ensure that it is completely idle

        $\to$ Of particular concern is any pending I/O, i.e. a process may be waiting for an I/O operation when we want to swap that process to free up memory
        * *Problem*. If the I/O is asynchronously accessing the user memory for I/O buffers

            $\to$ The process cannot be swapped
            * *Explain*. If we were to swap out process $P_1$ and swap in process $P_2$

                $\to$ The I/O operation might then attempt to use memory, which now belongs to process $P_2$
        * *Solutions*.
            * *Solution 1*. Never swap a process with pending I/O
            * *Solution 2*. Execute I/O operations only into OS buffers

                $\to$ Transfer between OS buffers and process memory then occur only when the process is swapped in
    * *Time and space complexity of swapping*. Currently standard swapping is used in few systems
        * *Explain*. It requires too much swapping time and provides too little execution time to be a reasonable memory-management solution
        * *Solution*. Use modified versions of swapping
            * *Example*. In UNIX,
                * Swapping is normally disabled but will start if many processes are running and are using a threshold amount of memory
                * Swapping is halted when the load on the system is reduced

## Contiguous memory allocation
**Problem**. The main memory must accommodate both the OS and the user processes

$\to$ We need to allocate main memory in the most efficient way possible

**Memory partitions**. The memory is usually divided into two partitions, i.e. one for resident OS and one for the user processes
* *Location of OS memory*. In either low memory or high memory, depending mainly on the location of the interrupt vector

    >**NOTE**. The interrupt vector is often in low memory
    >$\to$ Programmers usually place the OS in low memory as well

**Contiguous memory allocation**. Each process is contained in a single contiguous section of memory

### Memory mapping and protection
**Key idea**. Use relocation and limit registers
* *Benefits*.
    * We can protectthe OS and the user's programs and data from being modified by the running process
    * We can effectively allow the OS's size to change dynamically
        * *Example*. Transient OS code comes and goes as needed, requiring the OS to be dynamically sized

**Process execution**.
1. The CPU scheduler selects a process for execution
2. The dispatcher loads the relocation and limit registers with the correct values as part of the context switch

### Memory allocation
**Multiple-partition method**. Divide memory into several fixed-sized partitions, each of which may contain exactly one process

$\to$ The degree of multiprogramming is bound by the number of partitions
* *Partition allocation and deallocation*.
    * *Allocation*. When a partition is free

        $\to$ A process is selected from the input queue and is loaded into the free partition
    * *Deallocation*. When a process terminates

        $\to$ The partition becomes available for another process

>**NOTE**. This process is no longer in use

**Variable-partition method**. The OS keeps a table indicating which parts of memory are available and which are occupied
* *Hole*. A block of available memory
    * Initially, all memory is available for user processes, and is considered one large hole
    * Eventually, the main memory will contain a set of holes of various sizes
* *Memory allocation and deallocation*.
    1. A process enters the system and is put into an input queue
    2. The OS takes into account the memory requirements of each process, and the amount of available memory space

        $\to$ It then determines which processes are allocated memory
    3. The process is allocated space, loaded into memory, and it can then complete for CPU time
    4. When the process terminates

        $\to$ It releases its memory, which the OS may then fill with another process from the input queue

>**NOTE**. When there is no available hole large enough to hold the upcoming process in the input queue
>$\to$ The OS can wait until a large hole is available, or skip down the input queue to see whether the smaller memory requirements of some other process can be met

* *Hole searching*. When a process arrives and needs memory

    $\to$ The system searchers the set of holes for a hole, which is large enough for the process

    >**NOTE**. If the hole is too large
    >$\to$ It is split into two parts, one for the arriving process, and one to return to the set of holes

    >**NOTE**. If the new hole created when a process terminates is adjacent to other holes
    >$\to$ These adjacent holes are merged to form one larger hole

**Dynamic storage-allocation problem**. Concern how to satisfy a request of size $n$ from a list of free holes
* *First-fit solution*. Allocate the first hole, which is big enough
* *Best-fit solution*. Allocate the smallest hole, which is big enough
* *Worst-fit solution*. Allocate the largest hole

>**NOTE**. Worst-fit solution turns out to work better since it does not suffer from external fragmentation like first-fit or best-fit solutions

### Fragmentation
**External fragmentation**. When there is enough total memory space to satisfy a request but the available spaces are not contiguous

    $\to$ Storage is fragmented into a large number of small holes
* *Allocation strategies and external fragmentation*. Both the first-fit and best-fit strategies for memory allocation suffer from external fragmentation
    * *Explain*. Processes are loaded and removed from memory

        $\to$ The free memory space is broken into little pieces

**Internal fragmentation**. When there is a hole large enough to hold a process, but the space left after allocating the process is too small

    $\to$ The overhead to keep track of the small hole will be substantially larger than the hole itself, i.e. unused memory inside a partition
* *General solution*. Break the physical memory into fixed-sized blocks and allocate memory in units based on block size

    >**NOTE**. With this approach, the memory allocated to a process may be slightly larger than the requested memory

**Compaction**. A solution to the problem of external fragmentation
* *Goal*. Shuffle the memory contents so as to place all free memory together in one large block
* *Possibility*. Compaction is not always possible
    * If relocation is static and is done at assembly or load time

        $\to$ Compaction cannot be done
    * Compaction is possible only if relocation is dynamic and is done at execution time
        * *Explain*. If addresses are relocated dynamically

            $\to$ Relocation requires only moving the program and data, then changing the base register to reflect the new base address
* *Compaction cost*. The simplest compaction algorithm is to move all processes toward one end of memory

    $\to$ All holes move in the other direction, producing one large hole of available memory

    >**NOTE**. This scheme can be expensive

>**NOTE**. Another possible solution to the external-fragmentation is to permit the logical address space of processes to be noncontiguous
>$\to$ This allows a process to be allocated physical memory

## Paging
**Paging**. A memory-management scheme permiting the physical address space of a process to be noncontiguous
* *Benefits*
    * Avoid external fragmentation and the need for compaction
    * Solve the considerable problem of fitting memory chunks of varying sizes onto the backing store
        * *Problem root*. When some code fragments or data residing in main memory need to swapped out

            $\to$ Space must be found on the backing store

            >**NOTE**. The backing store has the same fragmentation problems

* *Paging support*.
    * *Traditional designs*. Support for paging has been handled by hardware
    * *Recent designs*. Implemented paging by closely integrating the hardware and the OS

### Basic method
**Idea**.
1. Break physical memory into fixed-sized blocks, called *frames*
2. Break logical memory into blocks of the same size, called *pages*
3. Break the backing store into fixed-sized blocks, which are of the same size as the memory frames
4. When a process is to be executed

    $\to$ Its pages are loaded into any available memory frames from their sources, i.e. a file system or the backing store

**Implementation**.

<div style="text-align:center">
    <img src="/media/p9MpGgd.png">
    <figcaption>Paging hardware</figcaption>
</div>

* *Address representation*. Every address generated by the CPU is divided into two parts
    * A page number $p$, which is used as an index into a page table
    * A page offset $d$, which is combined with base address from page table to define physical memory address, which is sent to the memory unit
* *Page table*. Contain the base address of each page in physical memory

<div style="text-align:center">
    <img src="/media/biEnwoW.png">
    <figcaption>Paging model of logical and physical memory</figcaption>
</div>

* *Page size*. Like the frame size. Defined by the hardware
    * *Typical values*. A power of $2$, varying between $512$ bytes and $16$ MB per page, depending on the computer architecture
        * *Explain*. Make the translation of logical address into a page number and page offset particularly easy

        <div style="text-align:center">
            <img src="/media/GvTwEfp.png">
            <figcaption>Page address representation</figcaption>
        </div>

        * *Example*. If the size of logical address space is $2^m$ and a page size is $2^n$ addressing units, i.e. bytes or words, then
            * The higher-order $m-n$ bits of a logical address designate the page number
            * The lower-order $n$ bits designate the page offset

**Fragmentation and paging**.
* *External fragmentation*. When we use a paging scheme

    $\to$ We have no external fragmentation
    * *Explain*. Any frame can be allocated to a process needing it
* *Internal fragmentation*. When we use a paging scheme

    $\to$ We may have some internal fragmentation
    * *Explain*. Frames are allocated as units

        $\to$ If the memory requirements of a process do not coincide with page boundaries, the last allocated frame may not be completely full
    * *Consequence*. Small page sizes are desirable
    * *Bad effects of small page size*.
        * Introduce overhead, which is reduced as the page size increases, in each page-table entry
        * Disk I/O is more efficient when the amount data being transferred is larger

        >**NOTE**. Generally, page sizes have grown over time, as processes, data sets, and main memory have become larger

**Page loading**.
* *Process execution*. When a process arrives in the system to be executed,
    1. Its size, expressed in pages, is examined
    2. Each page of the process needs one frame
    3. If $n$ frames are available, where $n$ is the number of required pages

        $\to$ They are allocated to the arriving process
* *Individual page loading*.
    1. The first page of the process is loaded into one of the allocated frames
    2. The frame number of put in the page table for this process
    3. The next page is loaded into another frame, and its frame number is put into the page table

**Separation between the user's view of memory and the actual physical memory**.
* *User program*. View memory as one single space containing only this one program

    $\to$ In fact, the user program is scattered throughout physical memory, which also holds other programs
* *Address-translation hardware*. The difference between the user's view of memory and the actual physical memory is reconciled by the address-translation hardware
    * *Usage*. Translate logical addresses into physical addresses

        >**NOTE**. This mapping is hidden from the user and is controlled by the OS

        >**NOTE**. There is no way to address memory outside of its page table, and the table includes only those pages which the process owns
        >$\to$ The user process, by definition, is unable to access memory it does not own

**Frame table**. The OS must be aware of the allocation details of physical memory, which is generally kept in a data structure called a frame table
* *Structure*. Have one entry for each physical page frame, indicating
    * Whether the latter is free or allocated
    * If it is allocated, then it is allocated to which page of which process or processes

<div style="text-align:center">
    <img src="/media/pLHXfrT.png">
    <figcaption>Free frames before and after allocation</figcaption>
</div>

**Page table and processes**. The OS must be aware that user processes operate in user space, and all logical addresses must be mapped to produce physical addresses

$\to$ If a user makes a system call and provides an address as a paramter, the address must be mapped to produce the correct physical address
* *Page table for processes*. The OS maintains a copy of the page table for each process
    * *Usage*.
        * Translate logical addresses to physical addresses whenever the OS must carry out address mapping manually
        * Used by the CPU dispatcher to define the hardware page table when a process is to be allocated the CPU

            $\to$ Paging increases the context-switch time

### Hardware support
**Page table storage**. Each OS has its own methods for storing page tables
* *Idea*. Most OSes allocate a page table for each process, i.e. a pointer to the page table is stored with the other register values, e.g. instruction counter, in the process control block

    $\to$ When the dispatcher is told to start a process, it must reload the user registers and define the correct hardware page-table values from the stored user page table

**Hardware implementation of page table**. Can be done in several ways
* *Simplest way*. The page table if implemented as a set of dedicated registers
    * *Register speed*. These registers should be built with very high-speed logic to make the paging-address translation efficient
        * *Explain*. Every access to memory must go through the paging map, thus efficiency is a major consideration
    * *Register loading*. The CPU dispatcher reloads these registers, just as it reloads the other registers
    * *Instruction privilege*. Instructions to load or modify the page-table registers are privileged

        $\to$ Only the OS can change the memory map
    * *Usage*. Used when the page table is reasonably small, e.g. 256 entries, since the registers are scarce
* *Page-table base register (PTBR)*. Most contemporary computers allow the page table to be very large
    * *Idea*. The page table is kept in main memory, and a PTBR points to the page table

        $\to$ Changing page tables requires changing only this register, substantially reducing context-switch time
    * *Drawbacks*. The time required to access a user memory location is large
        * *Explain*. If we want to access location $i$
            1. We must first index into the page table, using the value in the PTBR offset by the page number for $i$

                $\to$ This task requires a memory access
            2. We are then provided with the frame number, which is combined with the page offset to produce the actual address

                $\to$ We can then access the desired place in memory
        * *Consequence*. Two memory accesses are required to access a byte, i.e. one for the page-table entry, and one for the byte
            
            $\to$ Memory access is slowed by a factor of 2, which is intolerable under most situations
* *Translation look-aside buffer (TLB)*. Standard solution to the problem of PTBR
    * *Idea*. Use a special, small, fast-lookup hardware cache, called a translation look-aside buffer, which is associated, high-speed memory
        * *TLB entries*. Each entry consists of two parts, i.e. a key (or tag) and a value
        * *Element access*. When the TLB is presented with an item, the item is compared with all keys simultaneously

            $\to$ If the item is found, the corresponding value field is returned

            >**NOTE**. This is similar to associative-mapped cache

        * *Pros and cons*. The search is fast, but the hardware is expensive
        * *Typical number of entries in a TLB*. Small, i.e. often numbering between 64 and 1024
    * *TLB used with page tables*. The TLB contains only a few of the page-table entries

        <div style="text-align:center">
            <img src="https://i.imgur.com/yQLzHVi.png">
            <figcaption>TLB used with page table</figcaption>
        </div>

        1. When a logical address is generated by the CPU, its page number is presented to the TLB
        2. If the page number is found, its frame number is immediately available and is used to access memory
        3. If the page table is not in the TLB, i.e. TLB miss, a memory reference to the page table must be made

            $\to$ When the frame number is obtained, we can use it to access memory, and add the page number and frame number to the TLB for later references
        4. If the TLB is already full of entries, the OS must select one for replacement, e.g. LRU, random, etc.
            * *Wired down entries*. Some TLBs allow certain entries to be wired down, i.e. they cannot be removed from the TLB
                * *Example*. TLB entries for kernel code are wired down
    * *Address-space identifiers (ASIDs)*. Some TLBs store address-space identifiers in each TLB entry
        * *ASID*. An ASID uniquely identifies each process and is used to provide address-space protection for that process
        * *Mechanism for address-space protection*.
            1. When the TLB attempts to resolve virtual page numbers, it ensures that the ASID for the currently running process matches the ASID associated with the virtual page
            2. If the ASIDs do not match, the attempt is treated as a TLB miss
        * *ASID for different processes*. An ASID allows the TLB to contain entries for several different processes simultanenously
            * *Explain*. Without ASIDs, everytime a new page table is selected, e.g. with each context switch

                $\to$ The TLB must be flushed, or erased, to ensure that the next executing process does not use the wrong translation information
    * *Hit ratio*. The percentage of times a particular page number is found in the TLB
    * *Effective memory-access time*. $\text{effective\_access\_time}=\text{hit\_ratio} \times \text{cache\_hit\_time} + (1 - \text{hit\_ratio}) \times \text{cache\_miss\_time}$

### Protection
**Memory protection in a paged environment**. Accomplished by protection bits associated with each frame, which are normally kept in the page table

**Protection bit**. Can define a page to be read-write or read-only
* *Mechanism*.
    1. Every reference to memory goes through the page table to find the correct frame number
    2. At the same time that the physical address is being computed, the protection bits can be checked to verify that no writes are being made to a read-only page

        $\to$ An attempt to write to a read-only page causes a hardware trap to the OS, or memory-protection violation
* *Expansion to a finer level of protection*. 
    * We can create hardware to provide read-only, read-write, or execute-only protection
    * We can allow any combination of access modes, by providing separate protection bits for each kind of access

        $\to$ Illegal attempts will be trapped to the OS

**Valid-invalid bit**. One additional bit generally attached to each entry in the page table
* *Valid-invalid bit values*.
    * *Valid*. The associated page is in the process' logical address space, and is thus a legal, or valid, page
    * *Invalid*. The page is not in the process' logical address space

        $\to$ Illegal addresses are trapped by use of the valid-invalid bit
* *Usage*. Set by the OS for each page to allow or disallow access to the page
    * *Example 1*. When a user-space application starts, it will have some of its virtual address space allocated, additional memory needs to be requested from the OS

        $\to$ A lot of the address space of the process is blank, and any attempt to access those addresses should fail, i.e. this is implemented using valid-invalid bit
    * *Example 2*. Valid-invalid bit is used to represent a page, which is valid but not currently backed by a physical page, e.g.  
        * Demand-paged memory, where the address represents part of a memory-mapped file, or a page which has been swapped to secondary storage
        * Most modern OSes support zero-fill memory, i.e. when an application allocates memory, the allocated memory is not backed by physical memory until it is first used

**Page-table length register (PTLR)**. Rarely does a process use all its address range. In fact, many processes use only a small fraction of the address space available to them

$\to$ It would be wasteful in these cases to create a page table with entries for every page in the address range
* *Solution*. Use PTLR to indicate the size of the page table

    $\to$ PTLR is checked against every logical address to verify that the address is in the valid range for the process

### Shared pages
**Sharing common code**. An advantage of paging is the possibility of sharing common code, which is particularly important in a time-sharing environment

<div style="text-align:center">
    <img src="https://i.imgur.com/5rUCvQl.png">
    <figcaption>Sharing of code in a paging environment</figcaption>
</div>

* *Example*. If all users execute a text editor consisting of code and data space

    $\to$ Reentrant code, or pure code, can be shared
* *Reentrant code*. Non-self-modifying code, i.e. it never changes during execution

    $\to$ Two or more processes can be execute the same code at the same time
    * *Explain*. Each process has its own copy of registers and data storage to hold the data for process' execution

        $\to$ The data for two different processes will be different, but only one copy of the code need be kept in physical memory
* *Usage*. Share code of heavily used programs across different processes

>**NOTE**. To be sharable, the code must be reentrant, which must be enforced by the OS, not the correctness of the code

## Structure of the page table


## Segmentation
### Basic method
**Motivation**. Most users do not think of memory as a linear array of bytes, some containing instructions and others containing data

$\to$ They prefer to view memory as a collection of variable-sized segments, with no necessary ordering among segments

**Segments**. Each of the segments is of variable length, which is intrinsically defined by the purpose of the segment in the program

<div style="text-align:center">
    <img src="/media/RNHOShO.png">
    <figcaption>User's view of a program</figcaption>
</div>

* *Segment element identification*. Elements within a segment are identified by their offset from the beginning of the segment
    * *Example*. The first statement of the program, the seventh stack frame entry in the stack, the fifth instruction of `sqrt()`, etc.

**Segmentation**. A memory-management scheme which supports the segmented user view of memory
* *Idea*. A logical address space is a collection of segments, each of which has a name and a length
    * *Segment element addresses*. Specify both the segment name and the offset within the segment

        $\to$ The user specifies each address by two quantities, i.e. a segment name and an offset

        >**NOTE**. Contrast this scheme with the paging scheme, in which the user specifies only a single address, which is partitioned by the hardware into a page number and an offset

* *Logical address format*. `<segment_number, offset>`

**C programs and segments**. A C compiler might create separate segments for the following
* The code
* The global variables
* The heap, from which memory is allocated
* The stacks used by each thread
* The standard C library

>**NOTE**. Libraries linked in during compile time might be assigned separate segments
>$\to$ The loader would take all these segments and assign them segment numbers

### Hardware
>**NOTE**. Under segmentation scheme, the user can now refer to objects in the program by a 2D address
>$\to$ The actual physical memory is still a 1D sequence of bytes

<div style="text-align:center">
    <img src="/media/2GlJv0r.png">
    <figcaption>Segmentation hardware</figcaption>
</div>

**2D user-defined addresses to 1D physical addresses mapping**.
* *Segmentable*. Hold the mapping from user-defined 2D addresses to physical 1D addresses
    * *Entry*. Each entry has a segment base and a segment limit
        * *Segment base*. Contain the starting physical address, where the segment resides in memory
        * *Segment limit*. Specify the length of the segment
* *Logical address format*. Consist of a segment number $s$ and an offset into the corresponding segment $d$
    * *Segment number*. Used as an index to the segment table
    * *Offset*. Must be between 0 and the segment limit

        $\to$ Otherwise, we trap to the OS

<div style="text-align:center">
    <img src="/media/WfPgmkN.png">
    <figcaption>Example of segmentation</figcaption>
</div
