---
title: 1. Introduction and review about computer system
tags: Operating system
---

<!-- TOC titleSize:1 tabSpaces:2 depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 skip:0 title:1 charForUnorderedList:* -->
# Table of Contents
- [Table of Contents](#table-of-contents)
- [I/O systems](#io-systems)
  - [Overview](#overview)
  - [I/O hardware](#io-hardware)
    - [Polling](#polling)
    - [Interrupts](#interrupts)
    - [Direct memory access](#direct-memory-access)
  - [Application I/O interface](#application-io-interface)
    - [Block and character devices](#block-and-character-devices)
- [Appendix](#appendix)
  - [Concepts](#concepts)
<!-- /TOC -->

# I/O systems
## Overview
**I/O subsystem**. Since I/O devices vary so widely in their function and speed, varied methods are required to control them

$\to$ This subsystem separates the rest of the kernel from the complexities of mananaging I/O devices

**I/O device technology trends**. There are two conflict trends
* *Option 1*. Increasing stnadardization of software and hardware interfaces

    $\to$ This helps us to incorporate improved device generations into existing computers and operating systems
* *Option 2*. Increasingly broad variety of I/O devices, where new devices are so unlike previous devices

    $\to$ This is a challenge to incorporate them into our computers and OSes
    * *Solution*. Use a combination of hardware and software techniques
        * *Hardware*. The basic I/O hardware elements, e.g. ports, buses, and device controllers, accommodate a wide variety of I/O devices
        * *Software*. To encapsulate the details and oddities of different devices, the kernel of an OS is structured to use device-driver modules

**Device driver**. A uniform device-access interface to the I/O subsystem

## I/O hardware
**Types of hardware devices**. Most devices fit into the general categories of
* Storage devices, e.g. disks, tape, etc.
* Transmission devices, e.g. network cards, modems, etc.
* Human-interface devices, e.g. screen, keyboard, mouse, etc.
* Other specialized devices, e.g. those in the steering of military fighter jet, or a space shuttle

**Device-computer communication**. A device communicates with a computer system by sending signals over cable, or even through the air
* *Port*. A connection point, via which the device communicates with the machine
    * *Example*. A serial port
* *Bus*. If devices use a common set of wires, the connection is called a bus
    * *Bus*. A set of wires, and rigidly defined protocol specifying a set of messages which can be sent on the wires
    * *Message format*. In terms of the electronics, the messages are conveyed by patterns of electrical voltages applied to the wires with defined timings
* *Daisy chain*. When device A has a cable plugging into device B, and device B has cable plugging into device C, and device C plugs into a port on the computer
    * *Daisy chain as a bus*. A daisy chain usually operates as a bus

**Types of buses**. Buses are used widely in computer architecture, and vary in their signaling methods, speed, throughput, and connection methods

<div style="text-align:center">
    <img src="https://i.imgur.com/LJmJvf2.png">
    <figcaption>A typical PC bus structure</figcaption>
</div>

* *PCI bus*. The common PC system bus connecting the processor-memory subsystem to the fast devices
* *Expansion bus*. Connect relatively slow devices, e.g. the keyboard and serial and USB ports
* *SCSI bus*. Plugged into a SCSI controller, which connects the disks
* *Other common buses*. 
    * PCI-X, with throughput up to 4.3 GB
    * PCI Express (PCIe), with throughput up to 16 GB
    * HyperTransport, with throughput up to 20 GB

**Controller**. A collection of electronics, which can operate on a port, a bus, or a device
* *Example*. 
    * A serial-port controller, i.e a single chip, or portion of a chip, in the computer, which controls the signals on the wires of a serial port
    * A SCSI bus controller, i.e. implemented as a separate circuit board, or a host adapter, plugging into the computer
        * *Explain*. The SCSI protocol is complex
        * *SCSI controller structure*. Contain a processor, microcode, and some private memory to enable processing the SCSI protocol messages
    * Device built-in controllers, e.g. disk drive has a circuit board attached to one side, acting as a disk controller
        * *Purpose*. Implement the disk side of the protocol for some kind of connection, e.g. SCSI or ATA
        * *Structure*. Have a microcode, and a processor to do many tasks
* *Interaction with the main processor*. The controller has one or more registers for data and control signals

    $\to$ The processor communicates with the controller by reading and writing bit patterns in these registers
    * *Option 1*. Use a special I/O instructions specifying the transfer of a byte or word to an I/O port address

        $\to$ The I/O instruction triggers bus lines to select the proper device and to move bits into or out of a device register
    * *Option 2*. The device controller can support memory-mapped I/O
        * *Idea*. The device-control registers are mapped into the address space of the processor

            $\to$ The CPU executes I/O requests using the standard data-transfer instructions to read and write the device-control registers
    * *Hybird option*. Some systems use both options above
        * *Explain*. Use I/O instructions to control some devices, and memory-mapped I/O to control others
* *Communication with GPUs*. The graphics controller has I/O ports for basic control operations, but the controller has a large memory-mapped region to hold screen contents
    * *Rendering screen image*.
        1. The proces sends output to the screen by writing data into the memory-mapped region
        2. The controller generates the screen image based on the contents of this memory
    * *Pros*. Writing millions of bytes to the graphics memory is faster then issuing millions of I/O instructions
    * *Cons*. Due to a common type of software fault is a write through an incorrect pointer to an unintended region of memory

        $\to$ A memory-mapped device register is vulnerable to accidental modification
        * *Solution*. Use protected memory

**I/O port registers**. An I/O port typically consists of four registers
* *Data-in register*. Read by the host to get input
* *Data-out register*. Written by the host to send output
* *Status register*. Contain bits, which can be read by the host

    $\to$ These bits indicate states, e.g. whether the current command has completed
* *Control register*. Can be written by the host to start a command, or to change the mode of a device

### Polling
**Basic handshaking of interaction protocol between the host and a controller**.
* *Scenario*. Assume that two bits are used to coordinate the procedure-consumer relationship between the controller and the host
* *Status register*. The controller indicates its state through the busy bit in the status register, i.e.
    * The controller sets the busy bit when it is busy working
    * The controller clears the busy it when it is ready to accept the next command
* *Command register*. The host signals its wishes via the command-ready bit in the command register
  * *Explain*. The host sets the command-ready bit when a command is available for the controller to execute
* *Handshaking procedure for coordination*. The host writes output through a port, coordinating with the controller by handshaking as follows
    1. The host repeatedly reads the busy bit, until that bit becomes clear
    2. The host sets the write bit in the command register, and writes a byte into the data-out register
    3. The host sets the command-ready bit
    4. When the controller notices that the command-ready bit is set

        $\to$ It sets the busy bit
    5. The controller reads the command register, and see the `write` command

        $\to$ It reads the data-out register to get the byte, and does the I/O to the devic
    6. The controller clears the command-ready bit, clears the error bit in the status register, to indicate that the device I/O succeeded

        $\to$ The controller then clears the busy bit to indicate that it is finished

**Busy-waiting or polling**. The action of the host reading the status register over and over, until the busy bit becomes clear
* *Problem*. If the controller and device are fast, this method is reasonable, otherwise, the host should probably switch to another task
    * *Question*. How does the host know when the controller has become idle
        * *Explain*. For some devices, the host must service the device quickly, or data will be lost
* *CPU-instruction cycles sufficient to poll a device*.
    * *Read instruction*. To read a device regsiter
    * *Logical-and instruction*. To extract a status bit
    * *Branch instruction*. To branch out if the busy-bit is not zero
* *Solution*. Arrange for the hardware controller to notify the CPU, when the device becomes ready for service, rather than to require the CPU to poll repeatedly for an I/O completion
* *Interrupt*. The hardware mechanism enabling a device to notify the CPU

### Interrupts
**Basic interrupt mechanism**.
* *Interrupt-request line*. The CPU hardware has an interrupt-request line, which the CPU sense after executing every instruction
* *Interrupt handling* When the CPU detects that a controller has asserted a signal on the interrupt-request line

    $\to$ It performs a state save, and jumps to the interrupt-handler routine at a fixed address in memory
* *Interrupt-handler routine*. 

    <div style="text-align:center">
        <img src="https://i.imgur.com/dfeX0On.png">
        <figcaption>Interrupt-driven I/O cycle</figcaption>
    </div>

    1. Determine the cause of the interrupt
    2. Perform the necessary processing
    3. Perform a state restore
    4. Execut a `return from interrupt` instruction to return the CPU to the execution state, prior to the interrupt
* *Terminology for the procedure above*. We say that 
    1. The device controller raises an interrupt by asserting a signal on the interrupt request line
    2. The CPU catches the interrupt, and dispatches it to the interrupt handler
    3. The CPU dispatches it to the interrupt handler
    4. The handler clears the interrupt by servicing the device

**Modern OS's interrupt mechanism**. 
* *Requirements*. We need a more sophisticated interrupt-handling features, i.e.
    * The ability to defer interrupt handling during critical processing
    * An efficient way to dispatch to the proper interrupt handler for a device, without first polling all the devices to see which one raised the interrupt
    * Multi-level interrupts, i.e. for the OS to distinguish between high- and low-priority interrupts

        $\to$ The OS can repsond with the appropriate degree of urgency
* *Interrupt-controller hardware*. Features above are provided by the CPU, and by the interrupt-controller hardware

**Types of interrupt request lines**.
* *Nonmaskable interrupt*. Reserved for events like unrecoverable memory errors
* *Maskable interrupt*. Can be turned off by the CPU, before the execution of critical instruction sequences, which must not be interrupted

    $\to$ This line is used by device controllers to request service

**Interrupt vector**. The interrupt mechanism accepts an address, i.e. a number selecting specific interrupt-handling routine from a small set
* *Interrupt vector*. In most architectures, this address is an offset in a table called the interrupt vector

    $\to$ This vector contains the memory addresses of specialized interrupt handlers
* *Purpose of vectorized interrupt mechanism*. Reduce the need for a single interrupt handler to search all possible sources of interrupts to determine which one needs service
* *Interrupt chaining*. In practice, computers have more devices, hence interrupt handlers, than they have address elements in the interrupt vector

    $\to$ We need interrupt chaining, i.e. each element in the interrupt vector points to the head of a list of interrupt handlers
    * *Interrupt handling*. When an interrupt is raised, the handlers on the corresponding list are called one by one

        $\to$ Until one is found that can service the request
    * *Consequence*. This structure is a compromise between the overhead of a huge interrupt table, and the inefficiency of dispatching to a single interrupt handler

**Interrupt priority**. 
* Enable the CPU to defer the handling of low-priority interrupts, without masking off all interrupts
* Make it possible for a high-priority interrupt to preempty the execution of a low-priority interrupt

**OS-interrupt interaction**. 
* *Boot time*. The OS probes the hardware buses to determine what devices are present and installs the correpsonding interrupt handlers into the interrupt vector
* *I/O time*. The various device controllers raise interrupts when they are ready for service

    $\to$ These interrupts signify that output has completed, or that input data are available, or a failure has been detected
* *Exception time*. The interrupt mechanism is also used to handle a wide variety of exceptions, e.g. dividing by zero, accessing a protected or nonexistent memory address, etc.

**Common point of events triggering interrupts**. They are occurrences which induce the CPU to execute an urgent, self-contained routine
* *Interrupts for privileged routine in the kernel*. An OS has other good uses for an efficient hardware and software mechanism, which saves a small amount of processor state, and then calls a priviledged routine in the kernel
    * *Example 1*. Many OSes use the interrupt mechanism for virtual memory paging, i.e.
        1. A page fault is an exception raising an interrupt, which suspends the current process and jumps to the page-fault handler in the kernel
        2. The handler saves the state of the process, moves the process to the wait queue
        3. The handler then performs page-cache management, schedules an I/O operation to fetch the page
        4. The handler then schedules another process to resume execution, then returns from the interrupt
    * *Example 2*. A program usually uses library calls to issue ssystem calls, i.e.
        1. The library routines check the arguments given by the application, build a data structure to convey the argument to the kernel
        2. The library routines then execute a special instruction, called a software interrupt, or trap

            $\to$ This instruction has an operand identifying the desired kernel service
        3. When a process executes the trap instruction, the interrupt hardware saves the state of the user code, switches to supervisor mode
        4. The interrupt hardware then dispatches to the kernel routine implementing the requested service
            * *Interrupt priority of trap*. Relatively low compared to those assigned to device interrupts
* *Interrupts for the management of flow of control within the kernel*. Consider the processing required to complete a disk read
    * *Actions to take to complete a disk read*.
        1. Copy data from kernel space to user buffer

            $\to$ This is tine-consuming but not urgent, i.e. it should not block other high-priority interrupt handling
        2. Start the next pending I/O for the disk drive

            $\to$ This step has higher priority, i.e. if the disks are to be used efficiently, we need to start the next I/O, as soon as the previous one completes
     * *Consequence*. A pair of interrupt handlers implements the kernel code, which completes a disk read

        $\to$ The high-priority handler records the I/O status, clears the device interrupt, starts the next pending I/O, and raises a low-priority interrupt to complete the work

**Thread kernel architecture and interrupt implementation**. 
* *Threaded kernel architecture*. Well suited to 
    * Implement multiple interrupt priorities
    * Enforce the precedence of interrupt handling, over background processing in kernel and application routines
* *Example - Solaris kernel*. In Solaris, interrupt handlers are executed as kernel threads, which are reserved a range of high priorities
    * *Benefits* 
        * These priorities give interrupt handlers precedence over application code and kernel housekeeping
        * These priorities implement the priority relationships among interrupt handlers
            * *Explain*. The priorities cause the Solaris thread scheduler to preempt low-priority interrupt handlers in favor of higher-priority ones
        * The threaded implementation enables multiprocessor hardware to run several interrupt handlers concurrently

### Direct memory access
**Motivation**. For a device doing large transfers, e.g. a disk drive, it seems wasteful to use expensive general-purpose processor to watch status bits, and to feed data into a controller register onbe by at a time
* *Solution*. Many computers avoid burdening the main CPU with PIO by offloading some of this work to a direct-memory-access (DMA) controller, i.e. a special-purpose processor

**DMA controller**. 
* *DMA transfer procedure*.
    1. To initiate a DMA transfer, the host writes a DMA command block into memory
        * *DMA command block*. Contain 
            * A pointer to the source of a transfer
            * A pointer to the destination of the transfer
            * A count of the number of bytes to be transferred
    2. The CPU writes the address of this command block to the DMA controller, then goes on with other work
    3. The DMA controller proceeds to operate the memory bus directly, placing addresses on the bus to perform transfers, without the main CPU's help
* *DMA in PCs*. 
    * A simple DMA controller is a standard component in PCs
    * Bus-mastering I/O boards for the PC usually contain their own high-speed DMA hardware

**DMA controller and device controller handshaking**. Performed via a pair of wires, called DMA-request and DMA-acknowledge

<div style="text-align:center">
    <img src="https://i.imgur.com/GPWRsfb.png">
    <figcaption>Steps in a DMA transfer</figcaption>
</div>

1. The device controller places a signal on the DMA-request wire when a word of data is available for transfer

    $\to$ This signals causes the DMA controller to seize the memory bus, place the desired address on the memory-address wires
    * *Cycle stealing*. When the DMA seizes the memory bus
        
        $\to$ The CPU is momentarily prevented from accessing main memory, although it can still access data items in its primary and secondary caches
        * *Consequence*. The CPU computation can be slow down, however, offloading data-transfer work to DMA controller generally improves the total system performance
2. The DMA controller then places a signal on the DMa-acknowledge wire
3. When the device controller receives the DMA-acknowledge signal
    
    $\to$ It transfers the word of data to memory, and removes the DMA-request signal
4. When the entire transfer is finished, the DMA controller interrupts the CPU

**Direct virtual memory access (DVMA)**. Some computer architectures use physical memory address for DMA, but others perform DVMA, using virtual addresses undergoing translation to physical addresses
* *Benefits*. DVMA can perform a transfer between two memory-mapped devices, without the intervention of the CPU or the use of main memory

## Application I/O interface
**Application I/O interface**. Structuring techniques and interfaces for the OS, which enable I/O devices to be treated in a standard, uniform way

<div style="text-align:center">
    <img src="https://i.imgur.com/gfjnvTW.png">
    <figcaption>A kernel I/O structure</figcaption>
</div>

* *Idea*. Involve abstraction, encapsulation, and software layering, i.e. to abstract the detailed differences in I/O devices by identifying a few general kinds

    $\to$ Each general kind is accessed through a standardized set of functions, i.e. an interface
    * *Consequence*. The differences are encapsulated in kernel modules, called device drivers, which internally are custom-tailored to specific devices, but export one of the standard interfaces

**Device-driver layer**. Used to hide the differences among device controllers from the I/O subsystem of the kernel, 

$\to$ Much as the I/O system calls encapsulate the behavior of devices in a few generic classes hiding hardware differences from applications
* *Benefits of making the I/O subsystem independent of the hardware*. 
    * Simplify the job of the OS developer
    * Benefits the hardware manufacturers, i.e. they can design new devices to be compatible with an existing host controller interface, or write device drivers to interface the new hardware to popular OSes

        $\to$ We can attach new peripherals to a computer, without waiting for the OS vendor to develop support code

>**NOTE**. Each typ eof the OS has its own standards for the device-driver interface

**Types of devices by dimensions`**.
* *Character-stream or block*.
    * *Character-stream device*. Transfer bytes one by one
    * *Block device*. Transfer a block of bytes as a unit
* *Sequential or random access*.
    * *Sequential device*. Transfer data in a fixed order determined by the device
    * *Random access device*. Users can instruct the device to seek to any of the available data storage location
* *Synchronous or asynchronous*.
    * *Synchronous device*. Perform data transfers with predictable response time
    * *Asynchronous device*. Exhibit irregular or unpredictable response times
* *Sharable or dedicated*.
    * *Sharable device*. Can be used concurrently by several processes or threads
    * *Dedicated device*. Cannot
* *Speed of operation*. Device speeds range from a few bytes per second, to a few gigabytes per second
* *Read-write, read-only, and write-only*. Some devices perform both input and output, bot others support only one data-transfer direction

**Major access conventions**. For the purpose of application access, many of the differences above are hidden by the OS, and teh devices are grouped into a few conventional types

$\to$ The resulting styles of device access have been found to be useful and broadly applicable

>**NOTE**. Although the exact system calls may differ across OSes, the device categories are fairly standard

* *Major access conventions*. Block I/O, character-stream I/O, memory-mapped file access, and network sockets
* *Other special system calls to access additional devices*. Time-of-day clock, a timer, graphical display, video, and audio devices

**Escape (back door)**. Most OSes also have an escape, or back door, which transparently passes arbitrary commands from an application to a device driver
* *Example*. `ioctl()` system call in UNIX

### Block and character devices
**Block-device interface**. Capture call the aspects necessary for accessing disk drives, and other block-oriented devices
* *Required functions*. `read()`, `write()`, `seek()` if random-access device
* *Device access*. Applications normally access such a device via a file-system interface`

**I/O modes**.
* *Raw I/O modes*. The OS, as well as special applications like database-management systems, may prefer to access a block device as a simple linear array of blocks

# Appendix
## Concepts
**Programmed I/O (PIO)**. The action of feeding data into a controller register of an I/O port one byte at a time