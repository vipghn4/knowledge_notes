---
title: 1. Introduction and review about computer system
tags: Operating system
---

<!-- TOC titleSize:1 tabSpaces:2 depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 skip:0 title:1 charForUnorderedList:* -->
# Table of Contents
- [Table of Contents](#table-of-contents)
- [I/O systems](#io-systems)
  - [Overview](#overview)
  - [I/O hardware](#io-hardware)
    - [Polling](#polling)
    - [Interrupts](#interrupts)
    - [Direct memory access](#direct-memory-access)
  - [Application I/O interface](#application-io-interface)
    - [Block and character devices](#block-and-character-devices)
    - [Network devices](#network-devices)
    - [Clocks and timers](#clocks-and-timers)
    - [Blocking and non-blocking I/O](#blocking-and-non-blocking-io)
  - [Kernel I/O subsystem](#kernel-io-subsystem)
    - [I/O scheduling](#io-scheduling)
    - [Buffering](#buffering)
    - [Caching](#caching)
    - [Spooling and device reservation](#spooling-and-device-reservation)
    - [Error handling](#error-handling)
    - [I/O protection](#io-protection)
    - [Kernel data structures](#kernel-data-structures)
    - [Kernel I/O subsystem summary](#kernel-io-subsystem-summary)
  - [Transforming I/O requests to hardware operations](#transforming-io-requests-to-hardware-operations)
  - [STREAMS](#streams)
  - [Performance](#performance)
- [Appendix](#appendix)
  - [Concepts](#concepts)
<!-- /TOC -->

# I/O systems
## Overview
**I/O subsystem**. Since I/O devices vary so widely in their function and speed, varied methods are required to control them

$\to$ This subsystem separates the rest of the kernel from the complexities of mananaging I/O devices

**I/O device technology trends**. There are two conflict trends
* *Option 1*. Increasing stnadardization of software and hardware interfaces

    $\to$ This helps us to incorporate improved device generations into existing computers and operating systems
* *Option 2*. Increasingly broad variety of I/O devices, where new devices are so unlike previous devices

    $\to$ This is a challenge to incorporate them into our computers and OSes
    * *Solution*. Use a combination of hardware and software techniques
        * *Hardware*. The basic I/O hardware elements, e.g. ports, buses, and device controllers, accommodate a wide variety of I/O devices
        * *Software*. To encapsulate the details and oddities of different devices, the kernel of an OS is structured to use device-driver modules

**Device driver**. A uniform device-access interface to the I/O subsystem

## I/O hardware
**Types of hardware devices**. Most devices fit into the general categories of
* Storage devices, e.g. disks, tape, etc.
* Transmission devices, e.g. network cards, modems, etc.
* Human-interface devices, e.g. screen, keyboard, mouse, etc.
* Other specialized devices, e.g. those in the steering of military fighter jet, or a space shuttle

**Device-computer communication**. A device communicates with a computer system by sending signals over cable, or even through the air
* *Port*. A connection point, via which the device communicates with the machine
    * *Example*. A serial port
* *Bus*. If devices use a common set of wires, the connection is called a bus
    * *Bus*. A set of wires, and rigidly defined protocol specifying a set of messages which can be sent on the wires
    * *Message format*. In terms of the electronics, the messages are conveyed by patterns of electrical voltages applied to the wires with defined timings
* *Daisy chain*. When device A has a cable plugging into device B, and device B has cable plugging into device C, and device C plugs into a port on the computer
    * *Daisy chain as a bus*. A daisy chain usually operates as a bus

**Types of buses**. Buses are used widely in computer architecture, and vary in their signaling methods, speed, throughput, and connection methods

<div style="text-align:center">
    <img src="https://i.imgur.com/LJmJvf2.png">
    <figcaption>A typical PC bus structure</figcaption>
</div>

* *PCI bus*. The common PC system bus connecting the processor-memory subsystem to the fast devices
* *Expansion bus*. Connect relatively slow devices, e.g. the keyboard and serial and USB ports
* *SCSI bus*. Plugged into a SCSI controller, which connects the disks
* *Other common buses*. 
    * PCI-X, with throughput up to 4.3 GB
    * PCI Express (PCIe), with throughput up to 16 GB
    * HyperTransport, with throughput up to 20 GB

**Controller**. A collection of electronics, which can operate on a port, a bus, or a device
* *Example*. 
    * A serial-port controller, i.e a single chip, or portion of a chip, in the computer, which controls the signals on the wires of a serial port
    * A SCSI bus controller, i.e. implemented as a separate circuit board, or a host adapter, plugging into the computer
        * *Explain*. The SCSI protocol is complex
        * *SCSI controller structure*. Contain a processor, microcode, and some private memory to enable processing the SCSI protocol messages
    * Device built-in controllers, e.g. disk drive has a circuit board attached to one side, acting as a disk controller
        * *Purpose*. Implement the disk side of the protocol for some kind of connection, e.g. SCSI or ATA
        * *Structure*. Have a microcode, and a processor to do many tasks
* *Interaction with the main processor*. The controller has one or more registers for data and control signals

    $\to$ The processor communicates with the controller by reading and writing bit patterns in these registers
    * *Option 1*. Use a special I/O instructions specifying the transfer of a byte or word to an I/O port address

        $\to$ The I/O instruction triggers bus lines to select the proper device and to move bits into or out of a device register
    * *Option 2*. The device controller can support memory-mapped I/O
        * *Idea*. The device-control registers are mapped into the address space of the processor

            $\to$ The CPU executes I/O requests using the standard data-transfer instructions to read and write the device-control registers
    * *Hybird option*. Some systems use both options above
        * *Explain*. Use I/O instructions to control some devices, and memory-mapped I/O to control others
* *Communication with GPUs*. The graphics controller has I/O ports for basic control operations, but the controller has a large memory-mapped region to hold screen contents
    * *Rendering screen image*.
        1. The proces sends output to the screen by writing data into the memory-mapped region
        2. The controller generates the screen image based on the contents of this memory
    * *Pros*. Writing millions of bytes to the graphics memory is faster then issuing millions of I/O instructions
    * *Cons*. Due to a common type of software fault is a write through an incorrect pointer to an unintended region of memory

        $\to$ A memory-mapped device register is vulnerable to accidental modification
        * *Solution*. Use protected memory

**I/O port registers**. An I/O port typically consists of four registers
* *Data-in register*. Read by the host to get input
* *Data-out register*. Written by the host to send output
* *Status register*. Contain bits, which can be read by the host

    $\to$ These bits indicate states, e.g. whether the current command has completed
* *Control register*. Can be written by the host to start a command, or to change the mode of a device

### Polling
**Basic handshaking of interaction protocol between the host and a controller**.
* *Scenario*. Assume that two bits are used to coordinate the procedure-consumer relationship between the controller and the host
* *Status register*. The controller indicates its state through the busy bit in the status register, i.e.
    * The controller sets the busy bit when it is busy working
    * The controller clears the busy it when it is ready to accept the next command
* *Command register*. The host signals its wishes via the command-ready bit in the command register
  * *Explain*. The host sets the command-ready bit when a command is available for the controller to execute
* *Handshaking procedure for coordination*. The host writes output through a port, coordinating with the controller by handshaking as follows
    1. The host repeatedly reads the busy bit, until that bit becomes clear
    2. The host sets the write bit in the command register, and writes a byte into the data-out register
    3. The host sets the command-ready bit
    4. When the controller notices that the command-ready bit is set

        $\to$ It sets the busy bit
    5. The controller reads the command register, and see the `write` command

        $\to$ It reads the data-out register to get the byte, and does the I/O to the devic
    6. The controller clears the command-ready bit, clears the error bit in the status register, to indicate that the device I/O succeeded

        $\to$ The controller then clears the busy bit to indicate that it is finished

**Busy-waiting or polling**. The action of the host reading the status register over and over, until the busy bit becomes clear
* *Problem*. If the controller and device are fast, this method is reasonable, otherwise, the host should probably switch to another task
    * *Question*. How does the host know when the controller has become idle
        * *Explain*. For some devices, the host must service the device quickly, or data will be lost
* *CPU-instruction cycles sufficient to poll a device*.
    * *Read instruction*. To read a device regsiter
    * *Logical-and instruction*. To extract a status bit
    * *Branch instruction*. To branch out if the busy-bit is not zero
* *Solution*. Arrange for the hardware controller to notify the CPU, when the device becomes ready for service, rather than to require the CPU to poll repeatedly for an I/O completion
* *Interrupt*. The hardware mechanism enabling a device to notify the CPU

### Interrupts
**Basic interrupt mechanism**.
* *Interrupt-request line*. The CPU hardware has an interrupt-request line, which the CPU sense after executing every instruction
* *Interrupt handling* When the CPU detects that a controller has asserted a signal on the interrupt-request line

    $\to$ It performs a state save, and jumps to the interrupt-handler routine at a fixed address in memory
* *Interrupt-handler routine*. 

    <div style="text-align:center">
        <img src="https://i.imgur.com/dfeX0On.png">
        <figcaption>Interrupt-driven I/O cycle</figcaption>
    </div>

    1. Determine the cause of the interrupt
    2. Perform the necessary processing
    3. Perform a state restore
    4. Execut a `return from interrupt` instruction to return the CPU to the execution state, prior to the interrupt
* *Terminology for the procedure above*. We say that 
    1. The device controller raises an interrupt by asserting a signal on the interrupt request line
    2. The CPU catches the interrupt, and dispatches it to the interrupt handler
    3. The CPU dispatches it to the interrupt handler
    4. The handler clears the interrupt by servicing the device

**Modern OS's interrupt mechanism**. 
* *Requirements*. We need a more sophisticated interrupt-handling features, i.e.
    * The ability to defer interrupt handling during critical processing
    * An efficient way to dispatch to the proper interrupt handler for a device, without first polling all the devices to see which one raised the interrupt
    * Multi-level interrupts, i.e. for the OS to distinguish between high- and low-priority interrupts

        $\to$ The OS can repsond with the appropriate degree of urgency
* *Interrupt-controller hardware*. Features above are provided by the CPU, and by the interrupt-controller hardware

**Types of interrupt request lines**.
* *Nonmaskable interrupt*. Reserved for events like unrecoverable memory errors
* *Maskable interrupt*. Can be turned off by the CPU, before the execution of critical instruction sequences, which must not be interrupted

    $\to$ This line is used by device controllers to request service

**Interrupt vector**. The interrupt mechanism accepts an address, i.e. a number selecting specific interrupt-handling routine from a small set
* *Interrupt vector*. In most architectures, this address is an offset in a table called the interrupt vector

    $\to$ This vector contains the memory addresses of specialized interrupt handlers
* *Purpose of vectorized interrupt mechanism*. Reduce the need for a single interrupt handler to search all possible sources of interrupts to determine which one needs service
* *Interrupt chaining*. In practice, computers have more devices, hence interrupt handlers, than they have address elements in the interrupt vector

    $\to$ We need interrupt chaining, i.e. each element in the interrupt vector points to the head of a list of interrupt handlers
    * *Interrupt handling*. When an interrupt is raised, the handlers on the corresponding list are called one by one

        $\to$ Until one is found that can service the request
    * *Consequence*. This structure is a compromise between the overhead of a huge interrupt table, and the inefficiency of dispatching to a single interrupt handler

**Interrupt priority**. 
* Enable the CPU to defer the handling of low-priority interrupts, without masking off all interrupts
* Make it possible for a high-priority interrupt to preempty the execution of a low-priority interrupt

**OS-interrupt interaction**. 
* *Boot time*. The OS probes the hardware buses to determine what devices are present and installs the correpsonding interrupt handlers into the interrupt vector
* *I/O time*. The various device controllers raise interrupts when they are ready for service

    $\to$ These interrupts signify that output has completed, or that input data are available, or a failure has been detected
* *Exception time*. The interrupt mechanism is also used to handle a wide variety of exceptions, e.g. dividing by zero, accessing a protected or nonexistent memory address, etc.

**Common point of events triggering interrupts**. They are occurrences which induce the CPU to execute an urgent, self-contained routine
* *Interrupts for privileged routine in the kernel*. An OS has other good uses for an efficient hardware and software mechanism, which saves a small amount of processor state, and then calls a priviledged routine in the kernel
    * *Example 1*. Many OSes use the interrupt mechanism for virtual memory paging, i.e.
        1. A page fault is an exception raising an interrupt, which suspends the current process and jumps to the page-fault handler in the kernel
        2. The handler saves the state of the process, moves the process to the wait queue
        3. The handler then performs page-cache management, schedules an I/O operation to fetch the page
        4. The handler then schedules another process to resume execution, then returns from the interrupt
    * *Example 2*. A program usually uses library calls to issue ssystem calls, i.e.
        1. The library routines check the arguments given by the application, build a data structure to convey the argument to the kernel
        2. The library routines then execute a special instruction, called a software interrupt, or trap

            $\to$ This instruction has an operand identifying the desired kernel service
        3. When a process executes the trap instruction, the interrupt hardware saves the state of the user code, switches to supervisor mode
        4. The interrupt hardware then dispatches to the kernel routine implementing the requested service
            * *Interrupt priority of trap*. Relatively low compared to those assigned to device interrupts
* *Interrupts for the management of flow of control within the kernel*. Consider the processing required to complete a disk read
    * *Actions to take to complete a disk read*.
        1. Copy data from kernel space to user buffer

            $\to$ This is tine-consuming but not urgent, i.e. it should not block other high-priority interrupt handling
        2. Start the next pending I/O for the disk drive

            $\to$ This step has higher priority, i.e. if the disks are to be used efficiently, we need to start the next I/O, as soon as the previous one completes
     * *Consequence*. A pair of interrupt handlers implements the kernel code, which completes a disk read

        $\to$ The high-priority handler records the I/O status, clears the device interrupt, starts the next pending I/O, and raises a low-priority interrupt to complete the work

**Thread kernel architecture and interrupt implementation**. 
* *Threaded kernel architecture*. Well suited to 
    * Implement multiple interrupt priorities
    * Enforce the precedence of interrupt handling, over background processing in kernel and application routines
* *Example - Solaris kernel*. In Solaris, interrupt handlers are executed as kernel threads, which are reserved a range of high priorities
    * *Benefits* 
        * These priorities give interrupt handlers precedence over application code and kernel housekeeping
        * These priorities implement the priority relationships among interrupt handlers
            * *Explain*. The priorities cause the Solaris thread scheduler to preempt low-priority interrupt handlers in favor of higher-priority ones
        * The threaded implementation enables multiprocessor hardware to run several interrupt handlers concurrently

### Direct memory access
**Motivation**. For a device doing large transfers, e.g. a disk drive, it seems wasteful to use expensive general-purpose processor to watch status bits, and to feed data into a controller register onbe by at a time
* *Solution*. Many computers avoid burdening the main CPU with PIO by offloading some of this work to a direct-memory-access (DMA) controller, i.e. a special-purpose processor

**DMA controller**. 
* *DMA transfer procedure*.
    1. To initiate a DMA transfer, the host writes a DMA command block into memory
        * *DMA command block*. Contain 
            * A pointer to the source of a transfer
            * A pointer to the destination of the transfer
            * A count of the number of bytes to be transferred
    2. The CPU writes the address of this command block to the DMA controller, then goes on with other work
    3. The DMA controller proceeds to operate the memory bus directly, placing addresses on the bus to perform transfers, without the main CPU's help
* *DMA in PCs*. 
    * A simple DMA controller is a standard component in PCs
    * Bus-mastering I/O boards for the PC usually contain their own high-speed DMA hardware

**DMA controller and device controller handshaking**. Performed via a pair of wires, called DMA-request and DMA-acknowledge

<div style="text-align:center">
    <img src="https://i.imgur.com/GPWRsfb.png">
    <figcaption>Steps in a DMA transfer</figcaption>
</div>

1. The device controller places a signal on the DMA-request wire when a word of data is available for transfer

    $\to$ This signal causes the DMA controller to seize the memory bus, place the desired address on the memory-address wires
    * *Cycle stealing*. When the DMA seizes the memory bus
        
        $\to$ The CPU is momentarily prevented from accessing main memory, although it can still access data items in its primary and secondary caches
        * *Consequence*. The CPU computation can be slow down, however, offloading data-transfer work to DMA controller generally improves the total system performance
2. The DMA controller then places a signal on the DMA-acknowledge wire
3. When the device controller receives the DMA-acknowledge signal
    
    $\to$ It transfers the word of data to memory, and removes the DMA-request signal
4. When the entire transfer is finished, the DMA controller interrupts the CPU

**Direct virtual memory access (DVMA)**. Some computer architectures use physical memory address for DMA, but others perform DVMA, using virtual addresses undergoing translation to physical addresses
* *Benefits*. DVMA can perform a transfer between two memory-mapped devices, without the intervention of the CPU or the use of main memory

## Application I/O interface
**Application I/O interface**. Structuring techniques and interfaces for the OS, which enable I/O devices to be treated in a standard, uniform way

<div style="text-align:center">
    <img src="https://i.imgur.com/gfjnvTW.png">
    <figcaption>A kernel I/O structure</figcaption>
</div>

* *Idea*. Involve abstraction, encapsulation, and software layering, i.e. to abstract the detailed differences in I/O devices by identifying a few general kinds

    $\to$ Each general kind is accessed through a standardized set of functions, i.e. an interface
    * *Consequence*. The differences are encapsulated in kernel modules, called device drivers, which internally are custom-tailored to specific devices, but export one of the standard interfaces

**Device-driver layer**. Used to hide the differences among device controllers from the I/O subsystem of the kernel, 

$\to$ Much as the I/O system calls encapsulate the behavior of devices in a few generic classes hiding hardware differences from applications
* *Benefits of making the I/O subsystem independent of the hardware*. 
    * Simplify the job of the OS developer
    * Benefits the hardware manufacturers, i.e. they can design new devices to be compatible with an existing host controller interface, or write device drivers to interface the new hardware to popular OSes

        $\to$ We can attach new peripherals to a computer, without waiting for the OS vendor to develop support code

>**NOTE**. Each typ eof the OS has its own standards for the device-driver interface

**Types of devices by dimensions`**.
* *Character-stream or block*.
    * *Character-stream device*. Transfer bytes one by one
    * *Block device*. Transfer a block of bytes as a unit
* *Sequential or random access*.
    * *Sequential device*. Transfer data in a fixed order determined by the device
    * *Random access device*. Users can instruct the device to seek to any of the available data storage location
* *Synchronous or asynchronous*.
    * *Synchronous device*. Perform data transfers with predictable response time
    * *Asynchronous device*. Exhibit irregular or unpredictable response times
* *Sharable or dedicated*.
    * *Sharable device*. Can be used concurrently by several processes or threads
    * *Dedicated device*. Cannot
* *Speed of operation*. Device speeds range from a few bytes per second, to a few gigabytes per second
* *Read-write, read-only, and write-only*. Some devices perform both input and output, bot others support only one data-transfer direction

**Major access conventions**. For the purpose of application access, many of the differences above are hidden by the OS, and teh devices are grouped into a few conventional types

$\to$ The resulting styles of device access have been found to be useful and broadly applicable

>**NOTE**. Although the exact system calls may differ across OSes, the device categories are fairly standard

* *Major access conventions*. Block I/O, character-stream I/O, memory-mapped file access, and network sockets
* *Other special system calls to access additional devices*. Time-of-day clock, a timer, graphical display, video, and audio devices

**Escape (back door)**. Most OSes also have an escape, or back door, which transparently passes arbitrary commands from an application to a device driver
* *Example*. `ioctl()` system call in UNIX

### Block and character devices
**Block-device interface**. Capture call the aspects necessary for accessing disk drives, and other block-oriented devices
* *Required functions*. `read()`, `write()`, `seek()` if random-access device
* *Device access*. Applications normally access such a device via a file-system interface`

**I/O modes**.
* *Raw I/O modes*. The OS, as well as special applications like database-management systems, may prefer to access a block device as a simple linear array of blocks
    * *Duplicate functionality problem*. 
        * If the application performs its own buffering, then using a file system would cause extra, unneeded buffering
        * If an application provides its won locking of file blocks or regions, then any OS locking services would be redundant at least, and contradictory at the worst
    * *Solution*. Raw-device accesss passes control of the device directly to the application, letting the OS step out of the way
        
        $\to$ No OS services are then performed on this device
    * *A common compromise*. The OS allows a mode of operation on a file, which disables buffering and locking, i.e. direct I/O in the UNIX world
* *Memory-mapped I/O*. Memory-mapped file access can be layered on top of block-device drivers
    * *Idea*. Rather than offering `read` and `write` operations, a memory-mapped interface provides access to disk storage via an array of bytes in main memory

        $\to$ The system call mapping a file into memory returns the virtual memory address containing a copy of that file
        * *File modification*. The actual data transfers are performed only when required to satisfy access to the memory image
    * *Benefits*.
        * *Efficiency*. Since the transfers are handled by the same mechanism as that used for demand-paged virtual memory access

            $\to$ Memory-mapped I/O is efficient
        * *Convenience*. Memory mapping is also convenient for programmers, i.e. access to a memory-mapped file is as simple as reading from and writing to memory
    * *Usage*. 
        * OSes offering virtual memory commonly use the mapping interface for kernel services
            * *Example*. To execute a program, the OS maps the executable into memory, then transfers control to the entry address of the executable
        * Commonly used for kernel access to swap space on disk

**Character-stream interface**. A keyboard is an example of a device accessed through a character-stream interface
* *Basic system calls*. `get()` and `put()` one character

    $\to$ On top of this interface, libraries can be built offering line-at-a-time access, with buffering and editing services
    * *Example*. When a user types a backspace, the preceding character is removed from the input stream
* *Usage*. 
    * Convenient for input devices, e.g. keyboards, mice, and modems producing data for input spontaneously, i.e. at times that cannot necessarily predicted by the application
    * Good for output devices, e.g. printers and audio boards, which naturally fit the concept of a linear stream of bytes

### Network devices
**Network I/O interface**. Since the performance and addressing characteristics of network I/O differ significantly from those of disk I/O

$\to$ Most OSes provide a network I/O interface, which is different from the `read()`, `write()`, and `seek()` interface used for disks
* *Network socket interface*. One interface available in many OSes, including UNIX and Windows NT

**Socket for electricity analogy**. Any electrical appliance can be plugged in a socket
* *The system calls in the socket interface*. Enable the application to 
    * Create a socket
    * Connect a local socket to a remote address, i.e. plug this application into a socket created by another application
    * Listen for any remote application to plug into the local socket
    * Send and receive packets over the connection
* *Server implementation support*. To support the implementation of servers, the socket interface provides a function called `select()`, which manages a set of sockets
    * *`select()` call*. Return information aout which sockets have a packet waiting to be received, and which sockets have room to accept a packet to be sent
    * *Benefits*. Eliminate the polling and busy waiting which would otherwise be necessary for network I/O
    * *Consequence*. These functions encapsulate the essential behaviors of networks, greatly facilitating the creation of distributed applications, which can use any underlying network hardware and protocol stack

**Other approaches to interprocess communication and network communication**.
* *Windows NT's approach*. Windows NT provides one interface to the network interface card, and a second interface to the network protocols
* *UNIX*. Have half-duplex pipes, full-duplex FIFOs, full-duplex STREAMS, message queues, and sockets

### Clocks and timers
**Clocks and timers**. Most computers have hardware clocks and timers
* *Basic functions of clocks and timers*.
    * Give the current time
    * Give the elapsed time
    * Set a timer to trigger operation $X$ at time $T$
* *Usage*. Heavily used by the OS, and by the time-sensitive applications

    >**NOTE**. System calls implementing these functions are not standardized across OSes

**Programmable interval timer**. A hardware to measure elapsed time and to trigger operations
* *Functionality*.
    * It can be set to wait a certain amount of time, then generate an interrupt, and
    * It can be set to do this once or repeat the process to generate periodic interrupts
* *Usage*.
    * The scheduler uses this mechanism to generate an interrupt, which will preempt a process at the end of its time slice
    * The disk I/O subsystem uses this mechanism to invoke the periodic flushing of dirty cache buffers to disk
    * The network subsystem uses this mechanism to cancel operations, which are proceeding too slowly due to network congestion or failures
* *Interface for user processes to use timers*. The OS may provide an interface for user processes to use timers 
* *Number of timer requests*. The OS can support more timer requests than the number of timer hardware channels by simulating virtual clocks
    * *Idea*. 
        1. The kernel, or the timer device driver, maintains a list of interrupts wanted by its own routines and by user requests, sorted in earliest-time-first order
        2. The kernel sets the timer for the earliest time
        3. When the timer interupts, the kernel signals the requester and reloads the timer with the next earliest time
    * *Interrupt rate generated by hardware clock*. Between 18 and 60 ticks per second
        
        $\to$ This resolution is coarse, since a modern computer can execute hundreds of millions of instructions per second
    * *The precision of triggers*. Limited by the coarse resolution of the timer, and the overhead of maintaining virtual clocks

        >**NOTE**. If the timer ticks are used to maintain the system time-of-day clock, the system clock can drift
    
**Hardware clock implementation**. In most computers, the hardware clock is constructed from a high-frequency counter
* *Counter value reading*. From a device register, i.e. the counter in this case can be considered a high-resolution clock

### Blocking and non-blocking I/O
**Blocking I/O**. 
* *Idea*.
    1. When an application issues a blocking system call, the execution of the application is suspended

        $\to$ The application is moved from the OS's run queue to wait queue
    2. After the system call completes, the application is moved back to the run queue, where it is eligible to resume execution
    3. When the application resumes execution, it will receive the values returned by the system call
* *Usage*. Most OSes use blocking system calls for the application interface, although physical actions performed by I/O devices are generally asynchronous, i.e. they take a varying or unpredictable amount of time
    * *Explain*. Blocking application code is easier to understand, and nonblocking application code

**Non-blocking I/O**. Some user-level processes need nonblocking I/O
* *Example*. 
    * A user interface receiving keyboard and mouse input, while processing and displaying data on the screen
    * A video application reading frames from a file on disk, while decompressing and displaying the output on the display
* *I/O and execution overlapping*. One way an application writer can overlap execution with I/O is to write a multithreaded application
    
    $\to$ SOme threads can perform blocking system calls, while others continue executing
    * *Usage*. The Solaris developer used this technique to implement a user-level library for asynchronous I/O, freeing the application writer from that task
* *Nonblocking I/O system calls*. Some OSes provide nonblocking I/O system calls, which does not halt the execution of the application for an extended time

    $\to$ Instead, it returns quickly, with a return value indicating how many bytes were transferred

**Asynchronous system call**. An alternative to nonblocking system call
* *Idea*. Return immediately, without waiting for the I/O to complete, thus the application can continue to execute its code

    $\to$ The completion of the I/O at some future time is communicated to the application, through the setting of some variable in the address space of the application, or through the triggering of a signal, or software interrupt, or a callback routine executed outside the linear control flow of the application
* *Difference between nonblocking and asynchronous system calls*.

    <div style="text-align:center">
        <img src="https://i.imgur.com/y5tn9de.png">
        <figcaption>Two I/O methods - (a) synchronous and (b) asynchronous</figcaption>
    </div>

    * *A nonblocking `read()`*. Return immediately with whatever data are available, i.e. the full number of bytes requested, fewer, or none
    * *An asynchronous `read()`*. Request a transfer, which will be performed in its entirety but will complete at some future time

## Kernel I/O subsystem
**Kernel I/O subsystem**. Provide many services related to I/O, e.g. scheduling, buffering, caching, spooling, device reservation, and error handling

### I/O scheduling
**I/O scheduling**. How to determine a good order, in which to execute the I/O requests, i.e. since the order, in which applications issue system calls, rarely is the best choice
* *Prupose*. Improve overall system performance, share device access fairly among processes, and reduce the average waiting time for I/O to complete
* *Implementation*. Scheduling is implemented by maintaining a wait queue of requests for each device
    * *Scheduling steps*. When an application issues a blocking I/O system call
        1. The request is placed on the queue for that device
        2. The I/O scheduler rearranges the order of the queue to improve the overall system efficiency and the average response time experienced by applications
            
            >**NOPTE**. The OS may also try to be fair, i.e. no one application receives especially poor service, or it may give priority service for delay-sensitive requests

* *Asynchronous I/O support by kernel*. To do this, the kernel must be able to keep track of many I/O requests at the same time

    $\to$ The OS may attach the wait queue to a device-status table
    * *Device-status table*. Managed by the kernel, and contain an entry for each I/O device

        <div style="text-align:center">
            <img src="https://i.imgur.com/0ygEXXL.png">
            <figcaption>Device-status table</figcaption>
        </div>

        * *Table entry*. Indicate the device's type, address, and state, i.e. `NOT FUNCTIONING`, `IDLE`, or `BUSY`
        * *Table update*. If the device is busy with a request
            
            $\to$ The type of request and other parameters will be stored in the table entry for that device

**Approaches to improve the efficiency of the computer by the I/O subsystem**.
* *Option 1*. By scheduling I/O operations
* *Option 2*. By using storage space in main memory, or on disk via techniques like buffering, caching, and spooling

### Buffering
**Buffer**. A memory area storing data being transferred between two devices, or between a device and an application
* *Reasons for buffering*.
    * To cope with a speed mismatch between the producer and consumer of a data stream, e.g. double buffering
    * Provide adaptations for devices, which have different data-transfer sizes
        * *Usage*. Common in computer networking, where buffers are used widely for fragmentation and reassembly of messages
    * Support copy semantics for application I/O


**Double buffering**. Consider a modem and a hard disk, which is a thousand times faster than the modem

$\to$ When an entire buffer has arrived, the buffer can be written to disk in a single operation
* *Observation*. The disk write is not instantaneous and the modem still needs a palce to store additional coming data

    $\to$ Two buffers are used
* *Mechanism*. After the modem fills the first buffer, the disk write is requested

    $\to$ The modem starts to fill the second buffer, while the first one is written to disk
    * *Assumption*. By the time the modem has filled the second buffer, the disk write from the first one should have completed

        $\to$ The modem can switch back to the first buffer while the disk writes the second one
* *Conclusion*. Double buffering decouples the producer of data from the consumer, hence relaxing timing requirements between them

**Copy semantics**. Consider an application having a buffer of data, which it wishes to write to disk
* *Data writing procedure*. The application calls the `write()` system call, providing a pointer to the buffer and an integer specifying the number of bytes to write

    $\to$ What happens if the application changes the contents of the buffer, after the system call returns
* *Copy semantics*. With copy semantics, the version of data written to disk is guaranteed to be the version at the time of the application system call, independent of any subsequent changes in the application's buffer
    * *Simple way to guarantee copy semantics*. The `write()` system call copies the application data into a kernel buffer, before returning control to the application
        
        $\to$ The disk write is performed from the kernel buffer, hence subsequent changes to the application buffer have no effect
* *Usage*. Common in OSes, despite the overhead that this operation introduces, because of the clean semantics
* *Improvement*. The same effect can be obtained more efficiently by clever use of virtual memory mapping and copy-on-write page protection

### Caching
**Cache**. A region of fast memory, which holds copies of data

$\to$ Access to the cached copy is more efficient than access to the original
* *Cache and buffer*.
    * *Buffer*. May hold the only existing copy of a data item
    * *Cache*. Hold a copy on faster storage of an item residing elsewhere

**Unified cache and buffer**. Caching and buffering are distinct functions, but sometimes a region of memory can be used for both purposes
* *Example*. 
    * To preserve copy semantics and to enable efficient scheduling of disk I/O

        $\to$ The OS uses buffers in main memory to hold disk data
    * These buffers are also used as a cache, to improve the I/O efficiency for files, which are shared by applications, or being written and reread rapidly
        * *Explain*. When the kernel receives a file I/O request, the kernel accesses the buffer cache to see if that region of the file is available in main memory
            * If it is, a physical disk I/O can be avoided or deferred
            * Disk writes are accumulated in the buffer cache for several seconds

                $\to$ Large transfers are gathered to allow efficient write schedules

### Spooling and device reservation
**Spool**. A buffer holding output for a device, e.g. a printer, and cannot accept interleaved data streams
* *Explain*. Although a printer can serve only one job at a time, several applications may wish to print their output concurrently, without having their output mixed together

    $\to$ The OS solves this problem by intercepting all output to the printer
* *Idea*. Each application's output is spooled to a separate disk file
    1. When an application finishes printing, the spooling system queues the corresponding spool file for output to the printer
    2. The spooling system copies the queued spool files to the printer one at a time
* *Spooling management*. In either case below, the OS provides a control interface enabling users and system administrators to display the queue, remove unwanted jobs before execution, suspend printing while the printer is serviced, etc.
    * *Option 1*. Managed by a system daemon processs
    * *Option 2*. Handled by an in-kernel thread

**Concurrent output coordination**. Some devices, e.g. tape drivers and printers, cannot usefully multiplex the I/O requests of multiple concurrent applications
* *Approaches to handle concurrent output*.
    * *Option 1*. Use spooling
    * *Option 2*. Provide explicit facilities for coordination
        * *Examples*.
            * Some OSes provide support for exclusive device access, i.e. enable a process to allocate an idle device and deallocate the device when no longer needed
            * Some OSes enforce a limit of one open file handle to a device
            * Many OSes provide functions enabling processes to coordinate exclusive access among themselves

### Error handling
**Device and I/O transfer failure**. Due to transient reasons, e.g. overloaded network, or permanent reasons, e.g. defective disk controller
* *Transient failures*. OSes can often compensate effectively for transient failures
    * *Example*. A disk `read()` failure results in a `read()` retry
* *Permanent failures*. OSes are unlikely to recover from such failures

**General rule**. An I/O system call will return one bit of information about the status of the call, signifying either success or failure
* *Hardware error information*. Some hardware can provide highly detailed error information, although many current OSes are not designed to convey this information to the application
    * *Example*. A failure of a SCSI device is reported by the SCSI protocol in three levels of detail
        * *Sense key*. Identify the general nature of failure, e.g. hardware error or illegal request
        * *Additional sense code*. State the category of failure, e.g. a bad command parameter or a self-test failure
        * *Additional sense code qualifier*. Give more detail, e.g. which command parameter was in error, or which hardware subsystem failed its self-test

### I/O protection
**Problem**. A user process may accidentally or purposely attempt to disrupt the normal operation of a system by attempting to issue illegal I/O instructions

$\to$ We need to ensure that such disruptions cannot take place in the system

**I/O instruction execution protection**. Define all I/O instructions to be priviledged instructions

$\to$ Users cannot issue I/O instructions directly, i.e. they must do it through the OS
* *Explain*. To do I/O, 
    1. A user program executes a system call to request that the OS perform I/O on the behalf
    2. The OS, executing in monitor mode, checks that the request is valid and, if it is, does the I/O requested
    3. THe OS then returns to the user

**Memory-mapped and I/O port memory location protection**. Such locations must be protected from user access by the memory-protection system
* *Problem*. The kernel cannot simply deny all user access
    * *Example*. Most graphic games and video editting and playback software need direct access to memory-mapped graphics controller memory to speed the performance of the graphics
* *Solution*. The kernel provide a locking mechanism to allow a section of graphics memory to be allocated to one process at a time

### Kernel data structures
**Problem**. The kernel needs to keep state information about the use of I/O components

$\to$ It does so via a variety of in-kernel data structures, e.g. the open-file table structure

**File system data structures**. UNIX provides file-system access to a variety of entities, e.g. user files, raw devices, etc.
* *Reading from I/O*. Although each of these entities support a `read()` operation, the semantics diffier
    * *Examples*.
        * To read a user file, the kernel needs to probe the buffer cache before deciding whether to perform a disk I/O
        * To read a raw disk, the kernel needs to ensure that the request size is a multiple of the disk sector size, and is aligned on a sector boundary
        * To read a process image, it is merely necessary to copy data from memory
    * *Difference encapsulation*. UNIX encapsulates these differences within a uniform structure by using an object-oriented technique

**Object-oriented methods in difference encapsulation**. Some OSes use object-oriented methods even more extensively
* *Example*. Windows NT uses a message-passing implementation for I/O, i.e.
    * *I/O request*. An I/O request is converted into a message, which is sent through the kernel to the I/O manager, and then to the device driver

        $\to$ Each step may change the message contents
    * *Read-write messages*. 
        * *Write message*. For output, the message contains the data to be written
        * *Read message*. For input, the message contains a buffer to receive data
    * *Pros and cons*.
        * *Pros*. Simplify the structure and design of the I/O system and add flexibility
        * *Cons*. Add overhead, by comparison with procedural techniques using shared data structures

### Kernel I/O subsystem summary
**I/O subsystem**. Coordinate an extensive collection of services, which are available to applications, and to other parts of the kernel
* *Procedures supervised by I/O subsystem*.
    * Management of the namespace for files and devices
    * Access control to files and devices
    * Operation control, e.g. a modem cannot `seek()`
    * File-system space allocation
    * Device allocation
    * Buffering, caching, and spooling
    * I/O scheduling
    * Device-status monitoring, error handling, and failure recovery
    * Device-driver configuration and initialization

## Transforming I/O requests to hardware operations
**Topic of interest**. How the OS connects an application request to a set of network wires, or to a specific disk sector
* *Example*. Consider reading a file from disk, where the application refers to the data by a file name

$\to$ Within a disk, the file system maps from the file name through the file-system directories to obtain the space allocation of the file

**MS-DOS solution**. The first part of an MS-DOS file name, preceding the colon, is a string identifying a specific hardware device, e.g. `C:`
* *Hardware device in MS-DOS*. `C:` represents the primary hard disk built into the OS

    $\to$ `C:` is mapped to a specific port address through a device table
* *Colon separator*. Separate device name space from the file-system name space
    
    $\to$ This separator makes it easy for the OS to associate extra functionality with each device
    * *Example*. It is easy to invoke spooling on any files written to the printer

**UNIX solution**. 
* *Device name space*. If the device name space is incorporated in the regular file-system name space, e.g. UNIX

    $\to$ The normal file-system name services are provided for device name space automatically
    * *Example*. If the file system provides ownership and access control to all file names

        $\to$ Devices have owners and access control
    * *Consequence*. Since files are stored on devices, such an interface provides access to the I/O system at two levels
        * *Explain*. Names can be used to access the devices, or to access the files stored on the devices
* *Mount table*. UNIX has a mountable associating prefixes of path names with specific device names
    * *Path name resolving*. UNIX looks up the name in the mount table to find the longest matching prefix

        $\to$ The corresponding entry in the mount table gives the device name
        * *Explain*. The device name has the form of a name in the file-system name space
    * *Path name lookup*. When UNIX looks up this name in the file-system directory structures

        $\to$ It finds not an inode number, but a `<major,minor>` device number
        * *Major device number*. Identify a device driver, which should be called to handle I/O to this device
        * *Minor device number*. Passed to the device driver to index into a device table
* *Device table*. Entries of this table give the port addresses, or memory-mapped addresses, of the device controller

**Modern OS**. Obtain significant flexibility from the multiple stages of lookup tables in the path between request and a physical device controller
* *Introduction of new devices*. The mechanisms passing requests between applications and drivers are general

    $\to$ We can introduce new devices and drivers into a computer without recompiling the kernel
* *On-demand device loading*. At the boot time, the system probes the hardware buses to determine what devices are present

    $\to$ The system loads in the necessary drivers, either immediately or when first required by an I/O request

**Typical life cycle of a blocking read request**. I/O operation requires many steps, which together consume a tremendous number of CPU cycles
1. A process issues a blocking `read()` system call to a file descriptor of a file, which has been opened previously
2. The system-call code in the kernel checks the parameters for correctness

    $\to$ In case of input, if the data are available in the buffer cache, the data are returned to the process, and the I/O request is completed
3. Otherwise, a physical I/O must be performed, i.e. the process is removed from the run queue and is placed on the wait queue for the device

    $\to$ The I/O request is scheduled
4. Eventually, the I/O subsystem sends the request to the device driver
    * *Request format*. Depending on the OS, the request is sent via a subroutine call, or an in-kernel message
5. The device driver allocates kernel buffer space to receive the data and schedules the I/O

    $\to$ Eventually, the driver sends commands to the device controller by writing into the device-control registers
6. The device controller operates the device hardware to perform the data transfer
7. The driver may poll for status and data, or it may have set up a DMA transfer into kernel memory

    $\to$ In case of DMA transfer, the DMA controller will generate an interrupt when the transfer completes
8. The correct interrupt handler receives the interrupt via the interrupt-vector table, stores any necessary data, signals the device driver, and returns from the interrupt
9. The device driver receives the signal, determines which I/O request has completed, determines the request's status, and signals the kernel I/O subsystem that the request has been completed
10. The kernel transfers data or return codes to the address spae of the requesting process

    $\to$ The kernel then moves the process from the wait queue back to the ready queue
11. The process is unblocked. When the scheduler assigns the process to the CPU

    $\to$ The process resumes execution at the completion of the system call

## STREAMS
**STREAMS**. A mechanism in UNIX System V, which enables an application to assemble pipelines of driver code dynamically    
* *Stream*. A full-duplex connection between a device driver and a user-level process

    <div style="text-align:center">
        <img src="https://i.imgur.com/zYePqg7.png">
        <figcaption>The STREAMS structure</figcaption>
    </div>

    * *Structure*. Consist of the following elements, each of which contains a pair of queues, i.e. a read queue and a write queue
        * A stream head, which interfaces with the user process
        * A driver end, which controls the device
        * Zero or more stream modules between the stream head and the driver end
    * *Message passing*. Used to transfer data between queues
* *Stream modules*. Provide the functionality of STREAMS processing, i.e. they are pushed onto a stream by `ioctl()` system call
    * *Example*. A process can open a serial-port device via a stream, and can push on a module to handle input editing

**Flow control**. Since messages are exchanged between queues in adjacent modules, a queue in one module may overflow an adjacent queue

$\to$ To prevent overflow, a queue may support flow control
* *Queue without flow control*. Accept all messages and immediately send them on to the queue in the adjacent module without buffering them
* *Queue with flow control*. Buffer messages and do not accept messages without sufficient buffer space
    * *Explain*. This involves exchanges of control messages between queues in adjacent modules

**Read and write operations with streams**.
* *Write operation*. 
    1. A user process writes data to a device using either `write()` or `putmsg()` system call
        * *`write()`*. Write raw data to the stream
        * *`putmsg()`*. Allow the user process to specify a message
    2. The sream head copies the data into a message and delivers it to the queue for the next module in line
    3. The copying of messages continues until the message is copied to the driver end, and hence the device
* *Read operation*. The user process reads data from the stream head using either `read()` or `getmsg()` system call
    * *`read()`*. The stream head gets a message from its adjacent queue and returns ordinary data, i.e. an unstructured byte stream, to the process
    * *`getmsg()`*. A message is returned to the process
* *Asynchronous I/O*. STREAMS I/O is asynchronous, i.e. non-blocking, excep when the user process communicates with the stream head
    * *Writing*. When writing to the stream, the user process blocks, assuming the next queue uses flow control, until there is room to copy the message
    * *Reading*. The user process blocks when reading from the stream, until the data are available

**Driver end**. 
* *Queues*. The driver end has a read and write queue
* *Interrupts*. The driver end must respond to interrupts, e.g. one triggered when a frame is ready to be read from a network
* *Data handling*. Unlike the stream head, which may block if it is unable to copy a message to the next queue in line

    $\to$ The driver end must handle all incoming data
* *Flow control*. Drivers must support flow control as well
    * *Overflow handling*. If a device's buffer is full, the device typically resorts to dropping incoming messages

**Benefits of using STREAMS**. Most UNIX variants supports STREAMS, and it is the preferred method for writing protocols and device drivers
* STREAMS provides a framework for a modular and incremental approach to writing device drivers and network protocols

    $\to$ Modules may be used by different streams and hence by different devices
* Rather than treating character-device I/O as an unstructured bye stream

    $\to$ STREAMS allows support for message boundaries and control information when communicating between modules
    * *Message boundary*. The separation between two consecutive messages being sent over a protocol

## Performance
**I/O as a major factor in system performance**. Coping gracefully with all the following demandsis one of the major concerns of a computer architect
* I/O places heavy demands on the CPU to execute device-driver code, and to schedule processes fairly and efficiently as they block and unblock

    $\to$ The resulting context switches stress the CPU and its hardware caches
* I/O exposes any inefficients in interrupt-handling mechanisms in the kernel
* I/O loads down the memory bus during data copies between controllers and physical memory, and during copies between kernel buffers and application data space

**Interrupt handling**. Although modern computers can handle many thousands of interrupts per second

$\to$ Interrupt handling is a relatively expensive task
* *Explain*. Each interrupt causes the system to perform a state change, to execute the interrupt handler, and then to restore state
* *Programmed I/O*. Can be more efficient than interrupt-driven
I/O, if the number of cycles spent in busy waiting is not excessive
    * *Explain*. An I/O completion typically unblocks a process, leading to the full overhead of a context switch

**Network traffic causing high context-switch rate**. Consider a remote login from one machine to another

$\to$ Each character typed on the local machine must be transported to the remote machine

<div style="text-align:center">
    <img src="https://i.imgur.com/jtMf0bO.png">
    <figcaption>Intercomputer communications</figcaption>
</div>

* *Data flow on local machine*.
    1. The character is typed, leading to a keyboard interrupt

        $\to$ The character is passed through the interrupt handler to the device driver, to the kernel, then to the user process
    2. The user process issues a network I/O system call to send the character to the remote machine

        $\to$ The character then flows into the local kernel, through the network layers constructing a network packet, and into the network device driver
    3. The network device driver transfers the packet to the network controller, which sends the character and generates an interrupt

        $\to$ The interrupt is passed back up through the kernel to cause the network I/O system call to complete
* *Data flow on remote machine*.
    1. The network hardware receives the packet, and an interrupt is generated
    2. The character is unpacked from the network protocols and is given to the appropriate network daemon
    3. The network daemon identifies which remote login session is involved and passes the packet to the appropriate subdaemon for that session
    4. Usually, the receiver echoes the character back to the sender, doubling the work
* *ELiminating context switches*.
    * *Solaris solution*. Reimplement the `telnet` daemon using in-kernel threads

        $\to$ This is estimated to increase the maximum number of network logins from a few hundred to a few thousand on large server
    * *Separate front-end processors for terminal I/O*. Used to reduce the interrupt burden on the main CPU, e.g.
        * *Terminal concentrator*. Can multiplex the traffic from hundreds of remote terminals into one port on a large computer
    * *I/O channel*. A dedicaed, special-purpose CPU in mainframes and other high-end systems

        $\to$ Its job is to offload I/O work from the main CPU
        * *Idea*. The channels keep the data flowing smoothly, while the main CPU remains free to process the data

**Principles to improve the efficiency of I/O**.
* Reduce the number of context switches
* Reduce the number of times that data must be copied in memory while
passing between device and application
* Reduce the frequency of interrupts by using large transfers, smart controllers, and polling (if busy waiting can be minimized)
* Increase concurrency by using DMA-knowledgeable controllers or channels to offload simple data copying from the CPU
* Move processing primitives into hardware, to allow their operation in
device controllers to be concurrent with CPU and bus operation
* Balance CPU, memory subsystem, bus, and I/O performance, because an
overload in any one area will cause idleness in others

**Where should the I/O functionality be implemented**.

<div style="text-align:center">
    <img src="https://i.imgur.com/cUsjGNo.png">
    <figcaption>Device functionality progression</figcaption>
</div>

* *I/O in application software*. Initially, we implement experimental I/O algorithms at the application level
    * *Explain*. 
        * Application code is flexible and application bugs are unlikely to cause system crashes
        * By developing code at the application level, we avoid the need to reboot or reload device drivers after every change to the code
    * *Drawback*. An application-level implementation can be inefficient
        * *Explain*.
            * Due to the overhead of context switches
            * Since the application cannot take advantage of internal kernel data structures and kernel functionality
                * *Example*. Efficient in-kernel messaging, threading, and locking
* *I/O in kernel*. When an application-level algorithm has demonstrated its worth, we may reimplement it in the kernel

    $\to$ This can improve performance, but the development effort is more challenging
    * *Explain*. 
        * An OS kernel is a large, complex software system
        * An in-kernel implementation must be thoroughly debugged to avoid data corruption and system crashes
* *I/O in hardware*. The highest performance may be obtained through a specialized implementation in hardware, either in the device or in the controller
    * *Drawback*.
        * The difficulty and expense of making further improvements or of fixing bugs
        * The increased development time, i.e. months rather than days
        * The decreased flexibility

# Appendix
## Concepts
**Programmed I/O (PIO)**. The action of feeding data into a controller register of an I/O port one byte at a time