---
title: 12. Process synchronization
tags: Operating system
---

<!-- TOC titleSize:1 tabSpaces:2 depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 skip:0 title:1 charForUnorderedList:* -->
# Table of Contents
- [Table of Contents](#table-of-contents)
- [12. Process synchronization](#12-process-synchronization)
  - [Background](#background)
  - [The critical-section problem](#the-critical-section-problem)
  - [Peterson's solution](#petersons-solution)
  - [Synchronization hardware](#synchronization-hardware)
  - [Semaphores](#semaphores)
    - [Usage](#usage)
    - [Implementation](#implementation)
<!-- /TOC -->

# 12. Process synchronization
## Background
**Producer-consumer problem with bounded buffer**. Bounded buffer can be used to enable processes to share memory
* *Maximum number of elements at the same time*. At most `BUFFER_SIZE` - 1 at the same time

    $\to$ We want to modify the algorithm to remedy this deficiency
* *Idea*. Add an integer variable `counter`, intialized to `0`

    $\to$ `counter` is incremented everytime we add a new item to the buffer and is decremented every time we remove one item from the buffer
* *Example code*.

    ```cpp
    // Producer code
    while (true) {
        /* produce an item in nextProduced */
        while (counter == BUFFER_SIZE)
            ; /* do nothing */
        buffer[in] = nextProduced;
        in = (in + 1) % BUFFER_SIZE;
        counter++;
    }
    ```

    ```cpp
    // Consumer code
    while (true) {
        while (counter == 0)
            ; /* do nothing */
        nextConsumed = buffer[out];
        out = (out + 1) % BUFFER_SIZE;
        counter--;
        /* consume the item in the nextConsumed */
    }
    ```

* *Drawback*. When the producer and the consumer routines execute concurrently

    $\to$ They may not function correctly since they are both modifying `counter`

**Race condition**. When several processes access and manipulate the same data concurrently and the outcome of the execution depends on the particular order of the accesses
* *Avoidance*. We need to ensure that only one process at a time can manipulate the shared variables

    $\to$ To ensure this, we require that the processes are synchronized in some way

## The critical-section problem
**Critical section**. Consider a system consisting of $n$ processes $[P_0,P_1,\dots,P_{n-1}]$, each of which has a segment of code, in which the process may be changing common variables, updating a table, writing a file, etc.

$\to$ Such section of code is a *critical section*
* *Important feature*. When one process is executing in its critical section, no other process is to be allowed to execute in its critical section
* *Critical section problem*. Design a protocol which the processes can use to cooperate
    * *Idea*. Each process must request permission to enter its critical section
    * *Enrty section*. The section of code implementing enter request
    * *Exit section*. The critical section may be followed by an exit section
    * *Remainder section*. The remaining code
* *General structure of a typical process $P_i$*. 

    ```cpp
    do {
        entry_section(); // important
        critical_section();
        exit_section(); // important
        remainder_section();
    } while (true);
    ```

**Assumptions and requirements for a solution to the critical section problem**.
* *Assumptions*.
    * Each process is executing at a nonzero speed

        >**NOTE**. We can make no assumptions concerning the relative speed of the $n$ processes
    
* *Requirements*.
    * *Mutual exclusion (mutex)*. If process $P_i$ is executing in its critical section, then no other process can be executing in their critical section
    * *Progress*. If no process is executing in its critical section and some processes wish to enter their critical section, then
        * Only those processes which are not executing in their remainder_sections can participate in deciding which will enter its critical section next
        * This selection cannot be postponed indefinitely
    * *Bounded waiting*. There exists a bound, or limit, on the number of times which other processes are allowed to enter their critical section after a process has made a request to enter its critical section, and before that request is granted

**Kernel code race condition**. At a given point in time, many kernel-mode processes may be active in the OS

$\to$ It is up to the kernel developers to ensure that the OS is free from race conditions

**General approaches to handle critical sections**.
* *Preemptive kernels*. Allow a process to be preempted while it is running in kernel mode

    >**NOTE**. Preemptive kernels are especially difficult to design for SMP architectures, i.e. each processor performs all tasks within the OS
    >* *Explain*. In such environments, it is possible for two kernel-mode processes to run simultaneously on different processors

    >**NOTE**. People still favor preemptive kernel over a nonpreemptive one since 
    >* Preemptive kernels are more suitable for real-time programming
    >* Preemptive kernels are more responsive, since there is less risk that a kernel-mode process will run for arbitrarily long

* *Nonpreemptive kernels*. Do not allow a process running in kernel mode to be preempted

    $\to$ A kernel-mode process will run until it exits kernel mode, blocks, or voluntarily yields control of the CPU

    >**NOTE**. A nonpreemptive kernel is essentially free from race conditions on kernel data structures, since only one process is active in the kernel at a time

## Peterson's solution
**Peterson's solution**. A classic software-based solution to the critical section problem
* *Feasibility*. Due to the way modern computer architectures perform basic machine-language instructions, e.g. `load` and `store`

    $\to$ There are no guarantees that Peterson's solution will work correctly on such architectures

    >**NOTE**. We still consider this solution since 
    >* It provides a good algorithmic description of solving the critical section problem
    >* It illustrates some of the complexities involved in design software addressing the requirements of mutex, progress, and bounded waiting

* *Restriction*. There are only two processes which alternate execution between their critical sections and remainder sections
* *Description*. To enter the critical section, $P_i$ will examine if $P_j$ is still wish to enter the critical section too

    $\to$ If $P_j$ wants so, $P_i$ will politely let $P_j$ enter the critical section first
    * *Assumptions*.
        * The processes share two data items
            
            ```cpp
            int turn;
            bool flag[2];
            ```
        
        * `turn` indicates whose turn it is to enter its critical section
            * *Explain*. `turn == i` then process $P_i$ is allowed to execute in its critical section
        * `flag` is used to indicate if a process is ready to enter its critical section
    * *Process entrance*. 
        * To enter the critical section, process $P_i$ sets `flag[i] = true` then sets `turn = j`

            $\to$ This asserts that if other process wishes to enter the critical section, it can do so
        * If both processes try to enter at the same time, `turn` will be set to both `0` and `1` at roughly the same time

            $\to$ Only one of these assignments will last, the other will occur but will be overwritten immediately
        * The eventual value of `turn` determines which of the two processes is allowed to enter its critical section first
* *Process code for process $P_j$*.

    ```cpp
    do {
        flag[i] = true;
        turn = j;
        while (flag[j] && turn == j);
        critical_section();
        flag[i] = false;
        remainder_section();
    } while(true);
    ```

**Correctness of Peterson solution**.
* *Mutex is preserved*. Easily proven
* *The progress requirement is satisfied*. Easily proven
* *The bounded-waiting requirement is met*. $P_i$ will enter the critical section after at most one entry by $P_j$

## Synchronization hardware
**Locking**. Race conditions are prevented by requiring that critical regions be protected by locks

$\to$ A process must acquire a lock before entering a critical section, and it releases the lock when it exits the critical section
* *Example code*.

    ```cpp
    do {
        acquire_lock();
        critical_section();
        release_lock();
        remainder_section()
    } while (true);
    ```

* *Drawback*. The designs of locks can be quite sophisticated

**Critical section problem in uniprocessor environment**. If we could present interrupts from occurring while a shared variable was being modified

$\to$ The critical section problem can be solved simply
* *Explain*. In this manner, we could be sure that the current sequence of instructions would be allowed to execute in order without preemption

    $\to$ No other instructions would be run, thus no unexpected modifications could be made to the shared variables
* *Usage*. Commonly used in nonpreemptive environments kernels
* *Extension to multiprocessor environment*. This solution is not as feasible in a multiprocessor environment
    * *Explain*. Disabling interrupts on a multiprocessor can be time consuming, since the message is passed to all the processors

        $\to$ This message passing delays entry into each critical section, and system efficiency decreases

**Atomic operations**. A solution to critical section in multiprocessor environment
* *Idea*. Provide special hardware instructions allowing us either to test and modify the content of a word or to swap the contents of two words atomically

    $\to$ We can use these atomic instrutions to solve the critical section problem in a relatively simply manner
* *Atomic operations*. An uninterruptible unit
* *Solving critical section problem with atomic operations*. We can solve the critical section problem using two atmoic operations `TestAndSet()` and `Swap()` as abstracted below
* *`TestAndSet()` code*.

    ```cpp
    bool TestAndSet(bool *target) {
        // set *target = true then return the original value of *target
        bool rv = *target;
        *target = true;
        return rv;
    }
    ```

    * *Characteristics of `TestAndSet()`*. This instruction can be executed atomically

        $\to$ If two `TestAndSet()` instructions are executed simultaneously, each on a different CPU, they will be executed sequentially in some arbitrary order
    * *Consequence*. If the machine supports the `TestAndSet()` instruction, then we can implement mutex by declaring a boolean variable `lock = false`
    * *Process code*.

        ```cpp
        do {
            /*
            lock = true indicates that the lock has been acquired and not released
            logic:
                * if lock = true, i.e. acquired by some other process, then do nothing
                * if lock = false, i.e. released, then set lock = true, i.e. acquire lock, then enter critical section
            */
            while (TestAndSet(&lock)) 
                ; // do nothing
            critical_section();
            lock = false;
            remainder_section();
        } while (true);
        ```

* *`Swap()` code*.

    ```cpp
    void Swap(bool *a, bool *b) {
        // swap values of *a and *b
        bool temp = *a;
        *a = *b;
        *b = temp;
    }
    ```

    * *Characteristics of `Swap()`*. This instruction can be executed atomically

        $\to$ If the machine supports the `Swap()` instruction, then mutex can be provided as given in the process code below
    * *Process code*.

        ```cpp
        do {
            /*
            lock = true indicates that the lock has been acquired and not released
            key = true is the placeholder for whether to enter the critical section
                key = false indicates that it is valid to enter the critical section
            logic:
                * if lock = true, i.e. acquired by some other process, then do nothing, since key = true after swap
                * if lock = false, i.e. released, then set lock = true, i.e. acquire lock, then enter critical section
            */
            key = true;
            while (key == true)
                Swap(&lock, &key);
            critical_section();
            lock = false;
            remainder_section();
        } while (true);
        ```

* *Correctness of mutex based on `TestAndSet()` and `Swap()`*. These algorithms satisfy the mutex requirement, but do not satisfy the bounded waiting requirement
    * *Explain*. Since there is no code section to check waiting status of other processes

        $\to$ A single process may keep acquiring and releasing the lock, blocking the execution of other processes for eternity

**Alternative algorithm for `TestAndSet()` to ensure bounded waiting requirements**.
* *Common data structures*. The following structures are initialized to `false`

    ```cpp
    bool waiting[n];
    bool lock;
    ```

* *Bounded-waiting mutex with `TestAndSet()`*.

    ```cpp
    do {
        waiting[i] = true;
        key = true;
        while (waiting[i] && key)
            key = TestAndSet(&lock);
        waiting[i] = false;

        critical_section();

        // set j to the first waiting process from i+1 to i-1 (circular queue)
        j = (i + 1)%n;
        while ((j != i) && !waiting[j])
            j = (j + 1)%n;
        
        // if no waiting process then release lock
        if (j == i) lock = false;
        // if process j is waiting then waiting[j] = false and lock = true remains
        // process j then enter its critical section
        else waiting[j] = false;

        remainder_section();
    } while (true);
    ```

* *Correctness of algorithm*.

**Feasibility**. For hardware designers, implementing atomic `TestAndSet()` instructions on multiprocessors is not a trivial task

## Semaphores
**Semaphores**. A synchronization tool to overcome the complexity of locking hardware implementation
* *Semaphores*. An integer variable which, apart from initialization, is accessed only through two standard atomic operations `wait()` and `signal()`
    * *`wait()`*. Originally termed `P`, i.e. from the Dutch *proberen*, "to test"

        ```cpp
        void wait(S) {
            while (S <= 0)
                ; // do nothing
            S--;
        }
        ```

    * *`signal()`*. Originally called `V`, i.e. from Dutch *verhogen*, "to increment"

        ```cpp
        void signal(S) {
            S++;
        }
        ```
    
    >**NOTE**. All modifications to `S` in `wait()` and `signal()` must be executed indivisibly
    >* *Explain*. When one process modifies the semaphore value, no other process can simultaneously modify that same semaphore value

    >**NOTE**. In `wait()`, the testing of `S`, as well as `S--`, must be executed without interruption

    * *Intuition*. The semaphore indicates the number of slots available for critical section allocation

### Usage
**Types of semaphores**.
* *Counting semaphore*. Range over an unrestricted domain
    * *Usage*. Control access to a given resource consisting of a finite number of instances
    * *Idea*. The semaphore is initialized to the number of resources available
        * Each process wishing to use a resource performs a `wait()` operation on the semaphore
        * When a process releases a resource, it performs a `signal()` operation
* *Binary semaphore (or mutex locks)*. Can range only between 0 and 1
    * *Usage*. Deal with the critical section problem for multiple processes
    * *Idea*. The $n$ processes share a semaphore `mutex` initialized to 1
    * *Process code*.

        ```cpp
        do {
            wait(mutex);
            critical_section();
            signal(mutex);
            remainder_section();
        } while (true);
        ```

>**NOTE**. We can also use semaphores to solve various synchronization problems

### Implementation
**Spinlock semaphores and busy waiting**. The main advantage of the semaphore definition given above, i.e. spinlock semaphore, is that it requires busy waiting
* *Explain*. While a process is in its critical section, any other process trying to enter its critical section must loop continuously in the entry code

    $\to$ This continual looping is a problem in a real multiprogramming system
* *"Spinlock"*. Indicate that the process "spins" while waiting for the lock
    * *Pros*. No context switch may take considerable time

        $\to$ When locks are expected to be held for short times, spinlocks are useful
    * *Usage*. Used on multiprocessor systems, where one thread can spin on one processor, while another thread performs its critical section on another processor

**Modified version of `wait` and `signal` to avoid busy waiting**.
* *Idea*. When a process executes `wait()` and finds that the semaphore value is not positive
    
    $\to$ It must wait by blocking itself
* *Block operation*. Place a process into a waiting queue associated with the semaphore, and the process state is switched to the waiting state

    $\to$ The control is transferred to the CPU scheduler, which selects another process to execute
* *Wake-up operation*. A blocked proces waiting on a semaphore `S` should be restarted when some other process executes `signal()`

    $\to$ This is done by `wakeup()`, which changes the process from the waiting state to ready state, the process is then placed in the ready queue